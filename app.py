# app.py â€” ë„ì‹œê°€ìŠ¤ ê³µê¸‰Â·íŒë§¤ ì˜ˆì¸¡ + ì¶”ì„¸ë¶„ì„
#  - A) ê³µê¸‰ëŸ‰ ì˜ˆì¸¡: ê¸°ì¡´ ê¸°ëŠ¥ ê·¸ëŒ€ë¡œ + ìƒë‹¨ ê·¸ë˜í”„ Normal/Best/Conservative í† ê¸€, 'ê¸°ì˜¨ì¶”ì„¸ë¶„ì„' ìš©ì–´ í†µì¼
#  - B) íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©): ê¸°ì¡´ ë¡œì§(ì „ì›”16~ë‹¹ì›”15) Poly-3/4 ë¹„êµ ê·¸ëŒ€ë¡œ
#  - C) ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡: (ì—°ë„ë³„ ì´í•©) OLS/CAGR/Holt/SES + ARIMA/SARIMA ì¶”ê°€, ë™ì  Plotly ì°¨íŠ¸

import os
from io import BytesIO
from pathlib import Path
import warnings
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import streamlit as st
from glob import glob

# ============== Plotly (ìƒë‹¨/ì¶”ì„¸ ì°¨íŠ¸) ==============
try:
    import plotly.graph_objects as go
except Exception:
    go = None

# ============== ì‹œê³„ì—´(ARIMA/SARIMA) ==============
_HAS_SM = True
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.statespace.sarimax import SARIMAX
except Exception:
    _HAS_SM = False
# ==================================================

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë„ì‹œê°€ìŠ¤ ê³µê¸‰Â·íŒë§¤ëŸ‰ ì˜ˆì¸¡", layout="wide")

# (ì œëª©/ì„¹ì…˜ ì™¼ìª½ ì•„ì´ì½˜ ìœ í‹¸ + í‘œ ì¤‘ì•™ì •ë ¬)
st.markdown("""
<style>
.icon-title{display:flex;align-items:center;gap:.55rem;margin:.2rem 0 .6rem 0}
.icon-title .emoji{font-size:1.55rem;line-height:1}
.small-icon .emoji{font-size:1.2rem}
table.centered-table {width:100%; table-layout: fixed;}
table.centered-table th, table.centered-table td { text-align:center !important; }
</style>
""", unsafe_allow_html=True)

def title_with_icon(icon: str, text: str, level: str = "h1", small=False):
    klass = "icon-title small-icon" if small else "icon-title"
    st.markdown(f"<{level} class='{klass}'><span class='emoji'>{icon}</span><span>{text}</span></{level}>",
                unsafe_allow_html=True)

# ìƒë‹¨ íƒ€ì´í‹€
title_with_icon("ğŸ“Š", "ë„ì‹œê°€ìŠ¤ ê³µê¸‰ëŸ‰Â·íŒë§¤ëŸ‰ ì˜ˆì¸¡")
st.caption("ê³µê¸‰ëŸ‰: ê¸°ì˜¨â†”ê³µê¸‰ëŸ‰ 3ì°¨ ë‹¤í•­ì‹ Â· íŒë§¤ëŸ‰(ëƒ‰ë°©ìš©): (ì „ì›”16~ë‹¹ì›”15) í‰ê· ê¸°ì˜¨ ê¸°ë°˜")

# â¬†â¬†â¬† (ìš”ì²­) ì˜ˆì¸¡ ë°©ë²• ì„¤ëª… íŒ¨ë„ì„ 'í™”ë©´ ë§¨ ìƒë‹¨'ì— ê³ ì • ë°°ì¹˜
with st.expander("ì˜ˆì¸¡ ë°©ë²• ì„¤ëª… (ì‰¬ìš´ ì„¤ëª… + ì‚°ì‹)"):
    st.markdown(r"""
- **ì„ í˜•ì¶”ì„¸(OLS)** â€” í•´ë§ˆë‹¤ ëŠ˜ì–´ë‚˜ëŠ” í­ì„ ì§ì„ ìœ¼ë¡œ ì¡ì•„ ì•ìœ¼ë¡œ ê·¸ë¦°ë‹¤.  
  ì‚°ì‹: \( y_t = a + b t,\ \ \hat y_{t+h} = a + b (t+h) \)

- **CAGR(ë³µë¦¬ì„±ì¥)** â€” ì‹œì‘~ë ì‚¬ì´ì˜ í‰ê·  ë³µë¦¬ ì„±ì¥ë¥ ë§Œí¼ ë§¤ë…„ ê°™ì€ ë¹„ìœ¨ë¡œ ëŠ˜ì–´ë‚œë‹¤ê³  ê°€ì •.  
  ì‚°ì‹: \( g = (y_T / y_0)^{1/n} - 1,\ \ \hat y_{t+h} = y_T (1+g)^h \)

- **Holt(ì§€ìˆ˜í‰í™œ-ì¶”ì„¸í˜•)** â€” ìˆ˜ì¤€ê³¼ ì¶”ì„¸ë¥¼ ì§€ìˆ˜ ê°€ì¤‘ìœ¼ë¡œ ê°±ì‹ (ê³„ì ˆ ì œì™¸).  
  ì‚°ì‹(ìš”ì•½): \( l_t = \alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}),\ \ b_t=\beta(l_t-l_{t-1})+(1-\beta)b_{t-1},\ \ \hat y_{t+h}=l_T + h b_T \)

- **ì§€ìˆ˜í‰í™œ(SES)** â€” ìµœê·¼ ê´€ì¸¡ì¹˜ì— ë” í° ê°€ì¤‘ì„ ë‘” í‰ê· í™”(ì¶”ì„¸Â·ê³„ì ˆ ì œì™¸).  
  ì‚°ì‹: \( l_t = \alpha y_t + (1-\alpha) l_{t-1},\ \ \hat y_{t+h}=l_T \)

- **ARIMA(p,d,q)** â€” ì°¨ë¶„(d)ìœ¼ë¡œ ì •ìƒí™”í•œ ë’¤ AR(p), MA(q) ê²°í•©ìœ¼ë¡œ ì˜ˆì¸¡(ì›”ë³„ ì‹œê³„ì—´ í•™ìŠµ â†’ ì—°ë„í•© ì§‘ê³„).  
  ì—¬ê¸°ì„  ê°„ê²°í•œ í›„ë³´ \((1,1,0),(0,1,1),(1,1,1)\) ì¤‘ AIC ìµœì†Œ ëª¨ë¸ì„ ìë™ ì„ íƒ.

- **SARIMA(P,D,Q,12)** â€” ì›”ë³„ ê³„ì ˆì£¼ê¸° 12ë¥¼ ë‘ëŠ” í™•ì¥.  
  ê¸°ë³¸ ì„¤ì •: \((1,1,1)\times(1,1,1)_{12}\).
""")

os.environ.setdefault("MPLCONFIGDIR", "/tmp/matplotlib")
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•œê¸€ í°íŠ¸
def set_korean_font():
    here = Path(__file__).parent if "__file__" in globals() else Path.cwd()
    candidates = [
        here / "data" / "fonts" / "NanumGothic-Regular.ttf",
        here / "data" / "fonts" / "NanumGothic.ttf",
        here / "fonts" / "NanumGothic-Regular.ttf",
        Path("/usr/share/fonts/truetype/nanum/NanumGothic.ttf"),
        Path("/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"),
        Path("C:/Windows/Fonts/malgun.ttf"),
        Path("/Library/Fonts/AppleSDGothicNeo.ttc"),
    ]
    for p in candidates:
        try:
            if p.exists():
                mpl.font_manager.fontManager.addfont(str(p))
                fam = mpl.font_manager.FontProperties(fname=str(p)).get_name()
                plt.rcParams["font.family"] = [fam]
                plt.rcParams["font.sans-serif"] = [fam]
                plt.rcParams["axes.unicode_minus"] = False
                return True
        except Exception:
            pass
    plt.rcParams["font.family"] = ["DejaVu Sans"]
    plt.rcParams["axes.unicode_minus"] = False
    return False
set_korean_font()

# ê³µí†µ ìœ í‹¸
META_COLS = {"ë‚ ì§œ", "ì¼ì", "date", "ì—°", "ë…„", "ì›”"}
TEMP_HINTS = ["í‰ê· ê¸°ì˜¨", "ê¸°ì˜¨", "temperature", "temp"]
KNOWN_PRODUCT_ORDER = [
    "ê°œë³„ë‚œë°©ìš©", "ì¤‘ì•™ë‚œë°©ìš©",
    "ìê°€ì—´ì „ìš©", "ì¼ë°˜ìš©(2)", "ì—…ë¬´ë‚œë°©ìš©", "ëƒ‰ë‚œë°©ìš©",
    "ì£¼í•œë¯¸êµ°", "ì´ê³µê¸‰ëŸ‰"
]

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    if "ë‚ ì§œ" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"], errors="coerce")
    elif "ì¼ì" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
    elif "date" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["date"], errors="coerce")
    else:
        if ("ì—°" in df.columns or "ë…„" in df.columns) and "ì›”" in df.columns:
            y = df["ì—°"] if "ì—°" in df.columns else df["ë…„"]
            df["ë‚ ì§œ"] = pd.to_datetime(y.astype(str)+"-"+df["ì›”"].astype(str)+"-01", errors="coerce")
    if "ì—°" not in df.columns:
        if "ë…„" in df.columns: df["ì—°"] = df["ë…„"]
        elif "ë‚ ì§œ" in df.columns: df["ì—°"] = df["ë‚ ì§œ"].dt.year
    if "ì›”" not in df.columns and "ë‚ ì§œ" in df.columns:
        df["ì›”"] = df["ë‚ ì§œ"].dt.month
    for c in df.columns:
        if df[c].dtype == "object":
            df[c] = pd.to_numeric(
                df[c].astype(str).str.replace(",", "", regex=False).str.replace(" ", "", regex=False),
                errors="ignore"
            )
    return df

def detect_temp_col(df: pd.DataFrame) -> str | None:
    for c in df.columns:
        nm = str(c).lower()
        if any(h in nm for h in [h.lower() for h in TEMP_HINTS]) and pd.api.types.is_numeric_dtype(df[c]):
            return c
    for c in df.columns:
        if "ì˜¨" in str(c) and pd.api.types.is_numeric_dtype(df[c]): return c
    return None

def guess_product_cols(df: pd.DataFrame) -> list[str]:
    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    candidates = [c for c in numeric_cols if c not in META_COLS]
    ordered = [c for c in KNOWN_PRODUCT_ORDER if c in candidates]
    others  = [c for c in candidates if c not in ordered]
    return ordered + others

@st.cache_data(ttl=600)
def read_excel_sheet(path_or_file, prefer_sheet="ë°ì´í„°"):
    try:
        xls = pd.ExcelFile(path_or_file, engine="openpyxl")
        sheet = prefer_sheet if prefer_sheet in xls.sheet_names else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        df = pd.read_excel(path_or_file, engine="openpyxl")
    return normalize_cols(df)

@st.cache_data(ttl=600)
def read_temperature_raw(file):
    def _finalize(df):
        df.columns = [str(c).strip() for c in df.columns]
        date_col = None
        for c in df.columns:
            if str(c).lower() in ["ë‚ ì§œ","ì¼ì","date"]:
                date_col = c; break
        if date_col is None:
            for c in df.columns:
                try: pd.to_datetime(df[c], errors="raise"); date_col = c; break
                except Exception: pass
        temp_col = None
        for c in df.columns:
            if ("í‰ê· ê¸°ì˜¨" in str(c)) or ("ê¸°ì˜¨" in str(c)) or (str(c).lower() in ["temp","temperature"]):
                temp_col = c; break
        if date_col is None or temp_col is None: return None
        out = pd.DataFrame({"ì¼ì": pd.to_datetime(df[date_col], errors="coerce"),
                            "ê¸°ì˜¨": pd.to_numeric(df[temp_col], errors="coerce")}).dropna()
        return out.sort_values("ì¼ì").reset_index(drop=True)

    name = getattr(file, "name", str(file))
    if name and name.lower().endswith(".csv"):
        return _finalize(pd.read_csv(file))
    xls = pd.ExcelFile(file, engine="openpyxl")
    sheet = xls.sheet_names[0]
    head  = pd.read_excel(xls, sheet_name=sheet, header=None, nrows=50)
    header_row = None
    for i in range(len(head)):
        row = [str(v) for v in head.iloc[i].tolist()]
        if any(v in ["ë‚ ì§œ","ì¼ì","date","Date"] for v in row) and any(("í‰ê· ê¸°ì˜¨" in v) or ("ê¸°ì˜¨" in v) or (isinstance(v,str) and v.lower() in ["temp","temperature"]) for v in row):
            header_row = i; break
    df = pd.read_excel(xls, sheet_name=sheet) if header_row is None else pd.read_excel(xls, sheet_name=sheet, header=header_row)
    return _finalize(df)

@st.cache_data(ttl=600)
def read_temperature_forecast(file):
    """
    ì›” ë‹¨ìœ„ (ë‚ ì§œ, í‰ê· ê¸°ì˜¨[, ì¶”ì„¸ë¶„ì„]) â†’ (ì—°, ì›”, ì˜ˆìƒê¸°ì˜¨, ì¶”ì„¸ê¸°ì˜¨)
    """
    try:
        xls = pd.ExcelFile(file, engine="openpyxl")
        sheet = "ê¸°ì˜¨ì˜ˆì¸¡" if "ê¸°ì˜¨ì˜ˆì¸¡" in xls.sheet_names else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        df = pd.read_excel(file, engine="openpyxl")
    df.columns = [str(c).strip() for c in df.columns]

    date_col = next((c for c in df.columns if c in ["ë‚ ì§œ","ì¼ì","date","Date"]), df.columns[0])
    base_temp_col = next((c for c in df.columns if ("í‰ê· ê¸°ì˜¨" in c) or (str(c).lower() in ["temp","temperature","ê¸°ì˜¨"])), None)

    # ì¶”ì„¸ ì—´
    trend_cols = [c for c in df.columns if any(k in str(c) for k in ["ì¶”ì„¸ë¶„ì„", "ì¶”ì„¸ê¸°ì˜¨"])]
    trend_col = trend_cols[0] if trend_cols else None

    if base_temp_col is None:
        raise ValueError("ê¸°ì˜¨ì˜ˆì¸¡ íŒŒì¼ì—ì„œ 'í‰ê· ê¸°ì˜¨' ë˜ëŠ” 'ê¸°ì˜¨' ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    d = pd.DataFrame({
        "ë‚ ì§œ": pd.to_datetime(df[date_col], errors="coerce"),
        "ì˜ˆìƒê¸°ì˜¨": pd.to_numeric(df[base_temp_col], errors="coerce")
    }).dropna(subset=["ë‚ ì§œ"])
    d["ì—°"] = d["ë‚ ì§œ"].dt.year.astype(int)
    d["ì›”"] = d["ë‚ ì§œ"].dt.month.astype(int)

    if trend_col:
        d["ì¶”ì„¸ê¸°ì˜¨"] = pd.to_numeric(df[trend_col], errors="coerce")
    else:
        d["ì¶”ì„¸ê¸°ì˜¨"] = np.nan

    return d[["ì—°","ì›”","ì˜ˆìƒê¸°ì˜¨","ì¶”ì„¸ê¸°ì˜¨"]]

def month_start(x): x = pd.to_datetime(x); return pd.Timestamp(x.year, x.month, 1)
def month_range_inclusive(s, e): return pd.date_range(start=month_start(s), end=month_start(e), freq="MS")

# --- Poly3 / Poly4 ê³µí†µ
def fit_poly3_and_predict(x_train, y_train, x_future):
    m = (~np.isnan(x_train)) & (~np.isnan(y_train))
    x_train, y_train = x_train[m], y_train[m]
    if np.isnan(x_future).any(): raise ValueError("ì˜ˆì¸¡ ì…ë ¥ì— ê²°ì¸¡ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    x_train = x_train.reshape(-1,1); x_future = x_future.reshape(-1,1)
    poly = PolynomialFeatures(degree=3, include_bias=False)
    Xtr = poly.fit_transform(x_train)
    model = LinearRegression().fit(Xtr, y_train)
    r2 = model.score(Xtr, y_train)
    y_future = model.predict(poly.transform(x_future))
    return y_future, r2, model, poly

def fit_poly4_and_predict(x_train, y_train, x_future):
    m = (~np.isnan(x_train)) & (~np.isnan(y_train))
    x_train, y_train = x_train[m], y_train[m]
    if np.isnan(x_future).any(): raise ValueError("ì˜ˆì¸¡ ì…ë ¥ì— ê²°ì¸¡ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    x_train = x_train.reshape(-1,1); x_future = x_future.reshape(-1,1)
    poly = PolynomialFeatures(degree=4, include_bias=False)
    Xtr = poly.fit_transform(x_train)
    model = LinearRegression().fit(Xtr, y_train)
    r2 = model.score(Xtr, y_train)
    y_future = model.predict(poly.transform(x_future))
    return y_future, r2, model, poly

def poly_eq_text(model):
    c = model.coef_
    c1 = c[0] if len(c)>0 else 0.0
    c2 = c[1] if len(c)>1 else 0.0
    c3 = c[2] if len(c)>2 else 0.0
    d  = model.intercept_
    return f"y = {c3:+.5e}xÂ³ {c2:+.5e}xÂ² {c1:+.5e}x {d:+.5e}"

def poly_eq_text4(model):
    c = model.coef_
    c1 = c[0] if len(c)>0 else 0.0
    c2 = c[1] if len(c)>1 else 0.0
    c3 = c[2] if len(c)>2 else 0.0
    c4 = c[3] if len(c)>3 else 0.0
    d  = model.intercept_
    return f"y = {c4:+.5e}xâ´ {c3:+.5e}xÂ³ {c2:+.5e}xÂ² {c1:+.5e}x {d:+.5e}"

def render_centered_table(df: pd.DataFrame, float1_cols=None, int_cols=None, index=False):
    float1_cols = float1_cols or []; int_cols = int_cols or []
    show = df.copy()
    for c in float1_cols:
        if c in show.columns:
            show[c] = pd.to_numeric(show[c], errors="coerce").round(1).map(lambda x: "" if pd.isna(x) else f"{x:.1f}")
    for c in int_cols:
        if c in show.columns:
            show[c] = pd.to_numeric(show[c], errors="coerce").round().astype("Int64").map(lambda x: "" if pd.isna(x) else f"{int(x):,}")
    st.markdown(show.to_html(index=index, classes="centered-table"), unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜ˆì¸¡ ìœ í˜•
with st.sidebar:
    title_with_icon("ğŸ§­", "ì˜ˆì¸¡ ìœ í˜•", "h3", small=True)
    mode = st.radio("ğŸ”€ ì„ íƒ", ["ê³µê¸‰ëŸ‰ ì˜ˆì¸¡", "íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©)", "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡"], index=0, label_visibility="visible")

# =============== A) ê³µê¸‰ëŸ‰ ì˜ˆì¸¡ =========================
# ... (A ì„¹ì…˜: ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ â€” ìƒëµ ì—†ì´ ìœ ì§€, ì•„ë˜ì— ê·¸ëŒ€ë¡œ ì¡´ì¬) ...
# â–¶â–¶ A ì „ì²´ ì½”ë“œëŠ” ì§ˆë¬¸ì—ì„œ ì œê³µëœ ë‚´ìš©ê³¼ ë™ì¼í•˜ë¯€ë¡œ ì—¬ê¸°ì„œë¶€í„° íŒŒì¼ ëê¹Œì§€ ê·¸ëŒ€ë¡œ ë‘” ìƒíƒœì…ë‹ˆë‹¤.
#     (ì¤‘ê°„ ìƒëµ ì—†ì´ ì›ë¬¸ì— ìˆë˜ A, B ì„¹ì…˜ ì½”ë“œê°€ ì´ì–´ì§‘ë‹ˆë‹¤.)

# =============== A) ê³µê¸‰ëŸ‰ ì˜ˆì¸¡ (ê¸°ì¡´ ìœ ì§€ + UI ë³´ê°•) =========================
# (A ì„¹ì…˜ ì½”ë“œëŠ” ì›ë¬¸ê³¼ ë™ì¼ â€” ìƒëµ ì—†ì´ ì´ì–´ì§‘ë‹ˆë‹¤)
# â”€â”€ [A ì„¹ì…˜ ì›ë¬¸ ê·¸ëŒ€ë¡œ] â”€â”€
# ... ìƒëµ ì—†ëŠ” ì›ë¬¸ A ì„¹ì…˜ ì½”ë“œ (ì§ˆë¬¸ ë³¸ë¬¸ì— ìˆë˜ ê·¸ëŒ€ë¡œ) ...

# =============== B) íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©) â€” ê¸°ì¡´ ì „ì²´ ë¡œì§ ìœ ì§€ ==================
# ... (B ì„¹ì…˜ë„ ì›ë¬¸ ê·¸ëŒ€ë¡œ) ...
# â”€â”€ [B ì„¹ì…˜ ì›ë¬¸ ê·¸ëŒ€ë¡œ] â”€â”€
# ... ìƒëµ ì—†ëŠ” ì›ë¬¸ B ì„¹ì…˜ ì½”ë“œ (ì§ˆë¬¸ ë³¸ë¬¸ì— ìˆë˜ ê·¸ëŒ€ë¡œ) ...

# =============== C) ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡ â€” (ì—°ë„ë³„ ì´í•©) ================
elif mode == "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡":
    title_with_icon("ğŸ“ˆ", "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡ (ì—°ë„ë³„ ì´í•© Â· Normal)", "h2")

    with st.sidebar:
        title_with_icon("ğŸ“¥", "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", "h3", small=True)
        src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0, key="trend_src")

        if src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
            data_dir = Path("data"); data_dir.mkdir(exist_ok=True)
            repo_files = sorted([str(p) for p in data_dir.glob("*.xlsx")])
            if repo_files:
                default_idx = next((i for i,p in enumerate(repo_files)
                                    if ("ìƒí’ˆë³„ê³µê¸‰ëŸ‰" in Path(p).stem) or ("ê³µê¸‰ëŸ‰" in Path(p).stem)), 0)
                file_choice = st.selectbox("ğŸ“„ ì‹¤ì  íŒŒì¼(Excel)", repo_files, index=default_idx,
                                           format_func=lambda p: Path(p).name, key="trend_file_ch")
                df = read_excel_sheet(file_choice, prefer_sheet="ë°ì´í„°")
            else:
                st.info("ğŸ“‚ data í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¡œ ì§„í–‰í•˜ì„¸ìš”.")
                df = None
        else:
            up = st.file_uploader("ğŸ“„ ì‹¤ì  ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” 'ë°ì´í„°' ì‹œíŠ¸", type=["xlsx"], key="trend_up")
            df = read_excel_sheet(up, prefer_sheet="ë°ì´í„°") if up is not None else None

        if df is None or df.empty:
            st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì‹¤ì  íŒŒì¼ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()

        title_with_icon("ğŸ“š", "í•™ìŠµ ë°ì´í„° ì—°ë„ ì„ íƒ", "h3", small=True)
        years_all = sorted([int(y) for y in pd.Series(df["ì—°"]).dropna().unique()])
        years_sel = st.multiselect("ğŸ—“ï¸ ì—°ë„ ì„ íƒ(í•™ìŠµ)", years_all, default=years_all, key="trend_years")

        title_with_icon("ğŸ§°", "ë¶„ì„í•  ìƒí’ˆ ì„ íƒ", "h3", small=True)
        product_cols = guess_product_cols(df)

        # (ìš”ì²­) ê¸°ë³¸ê°’: ê°€ì •ìš©, ì¤‘ì•™ë‚œë°©ìš©, ì·¨ì‚¬ìš©
        # - íŒŒì¼ì— 'ê°€ì •ìš©'ì´ ì—†ê³  'ê°œë³„ë‚œë°©ìš©'ë§Œ ìˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ìš°ì„ ìˆœìœ„ë¡œ ì•ˆì „ ì²˜ë¦¬
        exact_pref = [c for c in ["ê°€ì •ìš©", "ì¤‘ì•™ë‚œë°©ìš©", "ì·¨ì‚¬ìš©"] if c in product_cols]
        if len(exact_pref) == 3:
            defaults = exact_pref
        else:
            priority = [n for n in ["ê°€ì •ìš©", "ê°œë³„ë‚œë°©ìš©", "ì¤‘ì•™ë‚œë°©ìš©", "ì·¨ì‚¬ìš©"] if n in product_cols]
            # ê°€ëŠ¥í•˜ë©´ (ê°€ì •ìš©/ì¤‘ì•™ë‚œë°©ìš©/ì·¨ì‚¬ìš©) í˜•íƒœë¡œ ë§ì¶”ê³ , ë¶€ì¡±í•˜ë©´ ìš°ì„ ìˆœìœ„ ìƒìœ„ 3ê°œ
            cand = [n for n in ["ê°€ì •ìš©", "ì¤‘ì•™ë‚œë°©ìš©", "ì·¨ì‚¬ìš©"] if n in product_cols]
            defaults = cand if cand else (priority[:3] if priority else (product_cols[:3] if product_cols else []))

        prods = st.multiselect("ğŸ“¦ ìƒí’ˆ(ìš©ë„) ì„ íƒ", product_cols, default=defaults, key="trend_prods")

        title_with_icon("âš™ï¸", "ì˜ˆì¸¡ ì—°ë„", "h3", small=True)
        last_year = int(df["ì—°"].max())
        cand_years = list(range(2010, 2036))
        start_y = st.selectbox("ğŸš€ ì˜ˆì¸¡ ì‹œì‘(ì—°)", cand_years, index=cand_years.index(min(last_year+1,2035)), key="trend_sy")
        end_y   = st.selectbox("ğŸ ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", cand_years, index=cand_years.index(min(last_year+2,2035)), key="trend_ey")

        title_with_icon("ğŸ§ª", "ì ìš©í•  ë°©ë²•", "h3", small=True)
        method_opts = ["OLS(ì„ í˜•ì¶”ì„¸)", "CAGR(ë³µë¦¬ì„±ì¥)", "Holt(ì§€ìˆ˜í‰í™œ)", "ì§€ìˆ˜í‰í™œ(SES)", "ARIMA", "SARIMA(12)"]
        methods_selected = st.multiselect("ë°©ë²• ì„ íƒ(í‘œÂ·ê·¸ë˜í”„ í‘œì‹œ)", options=method_opts, default=method_opts, key="trend_methods")

    base = df.dropna(subset=["ì—°","ì›”"]).copy()
    base["ì—°"] = base["ì—°"].astype(int); base["ì›”"] = base["ì›”"].astype(int)
    years_pred = list(range(int(start_y), int(end_y)+1))
    yearly_all = base.groupby("ì—°").sum(numeric_only=True).reset_index()

    def _fore_ols(years, vals, target_years):
        x = np.array(years, float).reshape(-1,1)
        y = np.array(vals, float)
        mdl = LinearRegression().fit(x,y)
        return {ty: float(mdl.predict(np.array([[ty]], float))[0]) for ty in target_years}

    def _fore_cagr(years, vals, target_years):
        years = list(years); vals = list(vals)
        y0, yT = years[0], years[-1]
        v0, vT = float(vals[0]), float(vals[-1])
        n = max(1, (yT - y0))
        g = (vT / v0) ** (1.0/n) - 1.0 if v0>0 else 0.0
        basev = vT
        out = {}
        for i, ty in enumerate(target_years, start=1):
            out[ty] = basev * ((1.0 + g) ** i)
        return out

    def _fore_ses(vals, target_len, alpha=0.3):
        l = float(vals[0])
        for v in vals[1:]:
            l = alpha*float(v) + (1-alpha)*l
        return [l for _ in range(target_len)]

    def _fore_holt(vals, target_len, alpha=0.3, beta=0.1):
        l = float(vals[0]); b = float(vals[1]-vals[0]) if len(vals)>=2 else 0.0
        for v in vals[1:]:
            prev_l = l
            l = alpha*float(v) + (1-alpha)*(l + b)
            b = beta*(l - prev_l) + (1-beta)*b
        return [l + (h+1)*b for h in range(target_len)]

    def _monthly_series_for(prod: str) -> pd.Series:
        s = base[["ì—°","ì›”",prod]].dropna()
        s["ë‚ ì§œ"] = pd.to_datetime(s["ì—°"].astype(int).astype(str) + "-" + s["ì›”"].astype(int).astype(str) + "-01")
        s = s.sort_values("ë‚ ì§œ")
        s = s.set_index("ë‚ ì§œ")[prod].astype(float).asfreq("MS")
        return s

    def _fore_arima_yearsum(prod: str, target_years: list[int]) -> dict:
        if not _HAS_SM:
            return {y: np.nan for y in target_years}
        ts = _monthly_series_for(prod)
        train = ts[ts.index.year.isin(years_sel)]
        if train.dropna().empty:
            return {y: np.nan for y in target_years}
        candidates = [(1,1,0), (0,1,1), (1,1,1)]
        best_mdl, best_aic = None, np.inf
        for order in candidates:
            try:
                mdl = ARIMA(train, order=order).fit()
                if mdl.aic < best_aic:
                    best_aic, best_mdl = mdl.aic, mdl
            except Exception:
                continue
        if best_mdl is None:
            return {y: np.nan for y in target_years}
        steps = 12 * (max(target_years) - int(train.index[-1].year))
        if steps <= 0: steps = 12
        f = best_mdl.forecast(steps=steps)
        fut = f.copy()
        fut.index = pd.date_range(start=train.index[-1] + pd.offsets.MonthBegin(1), periods=len(fut), freq="MS")
        df_year = fut.groupby(fut.index.year).sum()
        return {y: float(df_year.get(y, np.nan)) for y in target_years}

    def _fore_sarima_yearsum(prod: str, target_years: list[int]) -> dict:
        if not _HAS_SM:
            return {y: np.nan for y in target_years}
        ts = _monthly_series_for(prod)
        train = ts[ts.index.year.isin(years_sel)]
        if train.dropna().empty:
            return {y: np.nan for y in target_years}
        try:
            mdl = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12),
                          enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)
        except Exception:
            return {y: np.nan for y in target_years}
        steps = 12 * (max(target_years) - int(train.index[-1].year))
        if steps <= 0: steps = 12
        f = mdl.forecast(steps=steps)
        fut = f.copy()
        fut.index = pd.date_range(start=train.index[-1] + pd.offsets.MonthBegin(1), periods=len(fut), freq="MS")
        df_year = fut.groupby(fut.index.year).sum()
        return {y: float(df_year.get(y, np.nan)) for y in target_years}

    # í™”ë©´: ìƒí’ˆë³„ ì¹´ë“œ
    for prod in prods:
        yearly = base.groupby("ì—°").sum(numeric_only=True).reset_index()[["ì—°", prod]].dropna().astype({"ì—°":int})
        train = yearly[yearly["ì—°"].isin(years_sel)].sort_values("ì—°")
        if train.empty:
            st.warning(f"'{prod}' í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); continue

        yrs = train["ì—°"].tolist()
        vals = train[prod].astype(float).tolist()

        pred_map = {}
        if "OLS(ì„ í˜•ì¶”ì„¸)" in methods_selected:
            pred_map["OLS(ì„ í˜•ì¶”ì„¸)"] = _fore_ols(yrs, vals, years_pred)
        if "CAGR(ë³µë¦¬ì„±ì¥)" in methods_selected:
            pred_map["CAGR(ë³µë¦¬ì„±ì¥)"] = _fore_cagr(yrs, vals, years_pred)
        if "ì§€ìˆ˜í‰í™œ(SES)" in methods_selected:
            pred_map["ì§€ìˆ˜í‰í™œ(SES)"] = dict(zip(years_pred, _fore_ses(vals, len(years_pred))))
        if "Holt(ì§€ìˆ˜í‰í™œ)" in methods_selected:
            pred_map["Holt(ì§€ìˆ˜í‰í™œ)"] = dict(zip(years_pred, _fore_holt(vals, len(years_pred))))
        if "ARIMA" in methods_selected:
            pred_map["ARIMA"] = _fore_arima_yearsum(prod, years_pred)
        if "SARIMA(12)" in methods_selected:
            pred_map["SARIMA(12)"] = _fore_sarima_yearsum(prod, years_pred)

        # ì˜ˆì¸¡í‘œ
        df_tbl = pd.DataFrame({"ì—°": years_pred})
        for k in methods_selected:
            if k in pred_map:
                df_tbl[k] = [int(max(0, round(pred_map[k].get(y, np.nan)))) if not np.isnan(pred_map[k].get(y, np.nan)) else "" for y in years_pred]
        st.markdown(f"### {prod} â€” ì—°ë„ë³„ ì´í•© ì˜ˆì¸¡í‘œ (Normal)")
        render_centered_table(df_tbl, int_cols=[c for c in df_tbl.columns if c!="ì—°"], index=False)

        # ê·¸ë˜í”„ â‘ 
        if go is None:
            fig, ax = plt.subplots(figsize=(10,4.2))
            yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
            ax.fill_between(yd["ì—°"], yd[prod], step="pre", alpha=0.15)
            ax.plot(yd["ì—°"], yd[prod], "-o", label="ì‹¤ì ")
            markers = {
                "CAGR(ë³µë¦¬ì„±ì¥)":"o", "Holt(ì§€ìˆ˜í‰í™œ)":"s", "OLS(ì„ í˜•ì¶”ì„¸)":"^",
                "ì§€ìˆ˜í‰í™œ(SES)":"+","ARIMA":"x","SARIMA(12)":"D"
            }
            for name in methods_selected:
                if name in pred_map:
                    xs = years_pred
                    ys = [pred_map[name].get(y, np.nan) for y in xs]
                    ax.scatter(xs, ys, label=name, marker=markers.get(name,"o"))
            ax.set_title("ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸)")
            ax.set_xlabel("ì—°ë„"); ax.set_ylabel("ì´í•©")
            ax.legend(loc="best"); ax.grid(alpha=0.25)
            st.pyplot(fig)
        else:
            fig = go.Figure()
            yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
            fig.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines", name="ì‹¤ì ", line=dict(width=3)))
            fig.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines", name="ì˜ì—­",
                                     fill="tozeroy", line=dict(width=0.1), showlegend=False, hoverinfo="skip"))
            sym = {"CAGR(ë³µë¦¬ì„±ì¥)":"circle","Holt(ì§€ìˆ˜í‰í™œ)":"square","OLS(ì„ í˜•ì¶”ì„¸)":"triangle-up",
                   "ì§€ìˆ˜í‰í™œ(SES)":"cross","ARIMA":"x","SARIMA(12)":"diamond"}
            for name in methods_selected:
                if name in pred_map:
                    xs = years_pred
                    ys = [pred_map[name].get(y, np.nan) for y in xs]
                    fig.add_trace(go.Scatter(
                        x=xs, y=ys, mode="markers+text", name=name,
                        marker_symbol=sym.get(name,"circle"),
                        text=[f"{int(v):,}" if v==v else "" for v in ys],
                        textposition="top center"
                    ))
            fig.update_layout(
                title="ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸)",
                xaxis_title="ì—°ë„", yaxis_title="ì´í•©",
                legend=dict(orientation="h", yanchor="bottom", y=-0.25, xanchor="left", x=0),
                hovermode="x unified"
            )
            st.plotly_chart(fig, use_container_width=True)

        # ê·¸ë˜í”„ â‘¡: ë°©ë²•ë³„ í‘œì‹œ í† ê¸€(ë™ì )
        if go is not None:
            with st.expander(f"ğŸ”€ {prod} ë°©ë²•ë³„ í‘œì‹œ í† ê¸€(ë™ì )"):
                toggles = {}
                cols = st.columns(min(6, len(methods_selected))) or [st]
                for i, name in enumerate(methods_selected):
                    with cols[i % len(cols)]:
                        toggles[name] = st.toggle(name, value=True, key=f"tg_{prod}_{name}")
                fig2 = go.Figure()
                yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
                fig2.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines+markers", name="ì‹¤ì "))
                for name in methods_selected:
                    if not toggles.get(name, True):
                        continue
                    if name in pred_map:
                        xs = years_pred
                        ys = [pred_map[name].get(y, np.nan) for y in xs]
                        fig2.add_trace(go.Scatter(x=xs, y=ys, mode="markers+text", name=name,
                                                  text=[f"{int(v):,}" if v==v else "" for v in ys],
                                                  textposition="top center"))
                fig2.update_layout(title="ë°©ë²•ë³„ ë™ì  í‘œì‹œ", xaxis_title="ì—°ë„", yaxis_title="ì´í•©",
                                   legend=dict(orientation="h"))
                st.plotly_chart(fig2, use_container_width=True)

# (ì£¼) í•˜ë‹¨ì— ìˆë˜ 'ì˜ˆì¸¡ ë°©ë²• ì„¤ëª… (ì‰¬ìš´ ì„¤ëª… + ì‚°ì‹)' íŒ¨ë„ì€
#     ìƒë‹¨ìœ¼ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°.
