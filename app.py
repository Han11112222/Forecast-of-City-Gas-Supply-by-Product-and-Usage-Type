# app.py â€” ë„ì‹œê°€ìŠ¤ ê³µê¸‰Â·íŒë§¤ ì˜ˆì¸¡ + ì¶”ì„¸ë¶„ì„
#  - A) ê³µê¸‰ëŸ‰ ì˜ˆì¸¡: ê¸°ì¡´ ê¸°ëŠ¥ ê·¸ëŒ€ë¡œ + ìƒë‹¨ ê·¸ë˜í”„ Normal/Best/Conservative í† ê¸€, 'ê¸°ì˜¨ì¶”ì„¸ë¶„ì„' ìš©ì–´ í†µì¼
#  - B) íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©): ê¸°ì¡´ ë¡œì§(ì „ì›”16~ë‹¹ì›”15) Poly-3/4 ë¹„êµ ê·¸ëŒ€ë¡œ
#  - C) ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡: (ì—°ë„ë³„ ì´í•©) OLS/CAGR/Holt/SES + ARIMA/SARIMA ì¶”ê°€, ë™ì  Plotly ì°¨íŠ¸

import os
from io import BytesIO
from pathlib import Path
import warnings
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import streamlit as st
from glob import glob

# ============== Plotly (ìƒë‹¨/ì¶”ì„¸ ì°¨íŠ¸) ==============
try:
    import plotly.graph_objects as go
except Exception:
    go = None

# ============== ì‹œê³„ì—´(ARIMA/SARIMA) ==============
_HAS_SM = True
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.statespace.sarimax import SARIMAX
except Exception:
    _HAS_SM = False
# ==================================================

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë„ì‹œê°€ìŠ¤ ê³µê¸‰Â·íŒë§¤ëŸ‰ ì˜ˆì¸¡", layout="wide")

# (ì œëª©/ì„¹ì…˜ ì™¼ìª½ ì•„ì´ì½˜ ìœ í‹¸ + í‘œ ì¤‘ì•™ì •ë ¬)
st.markdown("""
<style>
.icon-title{display:flex;align-items:center;gap:.55rem;margin:.2rem 0 .6rem 0}
.icon-title .emoji{font-size:1.55rem;line-height:1}
.small-icon .emoji{font-size:1.2rem}
table.centered-table {width:100%; table-layout: fixed;}
table.centered-table th, table.centered-table td { text-align:center !important; }
</style>
""", unsafe_allow_html=True)

def title_with_icon(icon: str, text: str, level: str = "h1", small=False):
    klass = "icon-title small-icon" if small else "icon-title"
    st.markdown(f"<{level} class='{klass}'><span class='emoji'>{icon}</span><span>{text}</span></{level}>",
                unsafe_allow_html=True)

# ìƒë‹¨ íƒ€ì´í‹€(ìš”ì²­: Poly-3 ë¬¸êµ¬ ì œê±°)
title_with_icon("ğŸ“Š", "ë„ì‹œê°€ìŠ¤ ê³µê¸‰ëŸ‰Â·íŒë§¤ëŸ‰ ì˜ˆì¸¡")
st.caption("ê³µê¸‰ëŸ‰: ê¸°ì˜¨â†”ê³µê¸‰ëŸ‰ 3ì°¨ ë‹¤í•­ì‹ Â· íŒë§¤ëŸ‰(ëƒ‰ë°©ìš©): (ì „ì›”16~ë‹¹ì›”15) í‰ê· ê¸°ì˜¨ ê¸°ë°˜")

os.environ.setdefault("MPLCONFIGDIR", "/tmp/matplotlib")
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•œê¸€ í°íŠ¸
def set_korean_font():
    here = Path(__file__).parent if "__file__" in globals() else Path.cwd()
    candidates = [
        here / "data" / "fonts" / "NanumGothic-Regular.ttf",
        here / "data" / "fonts" / "NanumGothic.ttf",
        here / "fonts" / "NanumGothic-Regular.ttf",
        Path("/usr/share/fonts/truetype/nanum/NanumGothic.ttf"),
        Path("/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"),
        Path("C:/Windows/Fonts/malgun.ttf"),
        Path("/Library/Fonts/AppleSDGothicNeo.ttc"),
    ]
    for p in candidates:
        try:
            if p.exists():
                mpl.font_manager.fontManager.addfont(str(p))
                fam = mpl.font_manager.FontProperties(fname=str(p)).get_name()
                plt.rcParams["font.family"] = [fam]
                plt.rcParams["font.sans-serif"] = [fam]
                plt.rcParams["axes.unicode_minus"] = False
                return True
        except Exception:
            pass
    plt.rcParams["font.family"] = ["DejaVu Sans"]
    plt.rcParams["axes.unicode_minus"] = False
    return False
set_korean_font()

# ê³µí†µ ìœ í‹¸
META_COLS = {"ë‚ ì§œ", "ì¼ì", "date", "ì—°", "ë…„", "ì›”"}
TEMP_HINTS = ["í‰ê· ê¸°ì˜¨", "ê¸°ì˜¨", "temperature", "temp"]
KNOWN_PRODUCT_ORDER = [
    "ê°œë³„ë‚œë°©ìš©", "ì¤‘ì•™ë‚œë°©ìš©",
    "ìê°€ì—´ì „ìš©", "ì¼ë°˜ìš©(2)", "ì—…ë¬´ë‚œë°©ìš©", "ëƒ‰ë‚œë°©ìš©",
    "ì£¼í•œë¯¸êµ°", "ì´ê³µê¸‰ëŸ‰"
]

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    if "ë‚ ì§œ" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"], errors="coerce")
    elif "ì¼ì" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
    elif "date" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["date"], errors="coerce")
    else:
        if ("ì—°" in df.columns or "ë…„" in df.columns) and "ì›”" in df.columns:
            y = df["ì—°"] if "ì—°" in df.columns else df["ë…„"]
            df["ë‚ ì§œ"] = pd.to_datetime(y.astype(str)+"-"+df["ì›”"].astype(str)+"-01", errors="coerce")
    if "ì—°" not in df.columns:
        if "ë…„" in df.columns: df["ì—°"] = df["ë…„"]
        elif "ë‚ ì§œ" in df.columns: df["ì—°"] = df["ë‚ ì§œ"].dt.year
    if "ì›”" not in df.columns and "ë‚ ì§œ" in df.columns:
        df["ì›”"] = df["ë‚ ì§œ"].dt.month
    for c in df.columns:
        if df[c].dtype == "object":
            df[c] = pd.to_numeric(
                df[c].astype(str).str.replace(",", "", regex=False).str.replace(" ", "", regex=False),
                errors="ignore"
            )
    return df

def detect_temp_col(df: pd.DataFrame) -> str | None:
    for c in df.columns:
        nm = str(c).lower()
        if any(h in nm for h in [h.lower() for h in TEMP_HINTS]) and pd.api.types.is_numeric_dtype(df[c]):
            return c
    for c in df.columns:
        if "ì˜¨" in str(c) and pd.api.types.is_numeric_dtype(df[c]): return c
    return None

def guess_product_cols(df: pd.DataFrame) -> list[str]:
    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    candidates = [c for c in numeric_cols if c not in META_COLS]
    ordered = [c for c in KNOWN_PRODUCT_ORDER if c in candidates]
    others  = [c for c in candidates if c not in ordered]
    return ordered + others

@st.cache_data(ttl=600)
def read_excel_sheet(path_or_file, prefer_sheet="ë°ì´í„°"):
    try:
        xls = pd.ExcelFile(path_or_file, engine="openpyxl")
        sheet = prefer_sheet if prefer_sheet in xls.sheet_names else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        df = pd.read_excel(path_or_file, engine="openpyxl")
    return normalize_cols(df)

@st.cache_data(ttl=600)
def read_temperature_raw(file):
    def _finalize(df):
        df.columns = [str(c).strip() for c in df.columns]
        date_col = None
        for c in df.columns:
            if str(c).lower() in ["ë‚ ì§œ","ì¼ì","date"]:
                date_col = c; break
        if date_col is None:
            for c in df.columns:
                try: pd.to_datetime(df[c], errors="raise"); date_col = c; break
                except Exception: pass
        temp_col = None
        for c in df.columns:
            if ("í‰ê· ê¸°ì˜¨" in str(c)) or ("ê¸°ì˜¨" in str(c)) or (str(c).lower() in ["temp","temperature"]):
                temp_col = c; break
        if date_col is None or temp_col is None: return None
        out = pd.DataFrame({"ì¼ì": pd.to_datetime(df[date_col], errors="coerce"),
                            "ê¸°ì˜¨": pd.to_numeric(df[temp_col], errors="coerce")}).dropna()
        return out.sort_values("ì¼ì").reset_index(drop=True)

    name = getattr(file, "name", str(file))
    if name and name.lower().endswith(".csv"):
        return _finalize(pd.read_csv(file))
    xls = pd.ExcelFile(file, engine="openpyxl")
    sheet = xls.sheet_names[0]
    head  = pd.read_excel(xls, sheet_name=sheet, header=None, nrows=50)
    header_row = None
    for i in range(len(head)):
        row = [str(v) for v in head.iloc[i].tolist()]
        if any(v in ["ë‚ ì§œ","ì¼ì","date","Date"] for v in row) and any(("í‰ê· ê¸°ì˜¨" in v) or ("ê¸°ì˜¨" in v) or (isinstance(v,str) and v.lower() in ["temp","temperature"]) for v in row):
            header_row = i; break
    df = pd.read_excel(xls, sheet_name=sheet) if header_row is None else pd.read_excel(xls, sheet_name=sheet, header=header_row)
    return _finalize(df)

@st.cache_data(ttl=600)
def read_temperature_forecast(file):
    """
    ì›” ë‹¨ìœ„ (ë‚ ì§œ, í‰ê· ê¸°ì˜¨[, ì¶”ì„¸ë¶„ì„]) â†’ (ì—°, ì›”, ì˜ˆìƒê¸°ì˜¨, ì¶”ì„¸ê¸°ì˜¨)
    """
    try:
        xls = pd.ExcelFile(file, engine="openpyxl")
        sheet = "ê¸°ì˜¨ì˜ˆì¸¡" if "ê¸°ì˜¨ì˜ˆì¸¡" in xls.sheet_names else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        df = pd.read_excel(file, engine="openpyxl")
    df.columns = [str(c).strip() for c in df.columns]

    date_col = next((c for c in df.columns if c in ["ë‚ ì§œ","ì¼ì","date","Date"]), df.columns[0])
    base_temp_col = next((c for c in df.columns if ("í‰ê· ê¸°ì˜¨" in c) or (str(c).lower() in ["temp","temperature","ê¸°ì˜¨"])), None)

    # ì¶”ì„¸ ì—´
    trend_cols = [c for c in df.columns if any(k in str(c) for k in ["ì¶”ì„¸ë¶„ì„", "ì¶”ì„¸ê¸°ì˜¨"])]
    trend_col = trend_cols[0] if trend_cols else None

    if base_temp_col is None:
        raise ValueError("ê¸°ì˜¨ì˜ˆì¸¡ íŒŒì¼ì—ì„œ 'í‰ê· ê¸°ì˜¨' ë˜ëŠ” 'ê¸°ì˜¨' ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    d = pd.DataFrame({
        "ë‚ ì§œ": pd.to_datetime(df[date_col], errors="coerce"),
        "ì˜ˆìƒê¸°ì˜¨": pd.to_numeric(df[base_temp_col], errors="coerce")
    }).dropna(subset=["ë‚ ì§œ"])
    d["ì—°"] = d["ë‚ ì§œ"].dt.year.astype(int)
    d["ì›”"] = d["ë‚ ì§œ"].dt.month.astype(int)

    if trend_col:
        d["ì¶”ì„¸ê¸°ì˜¨"] = pd.to_numeric(df[trend_col], errors="coerce")
    else:
        d["ì¶”ì„¸ê¸°ì˜¨"] = np.nan

    return d[["ì—°","ì›”","ì˜ˆìƒê¸°ì˜¨","ì¶”ì„¸ê¸°ì˜¨"]]

def month_start(x): x = pd.to_datetime(x); return pd.Timestamp(x.year, x.month, 1)
def month_range_inclusive(s, e): return pd.date_range(start=month_start(s), end=month_start(e), freq="MS")

# --- Poly3 / Poly4 ê³µí†µ
def fit_poly3_and_predict(x_train, y_train, x_future):
    m = (~np.isnan(x_train)) & (~np.isnan(y_train))
    x_train, y_train = x_train[m], y_train[m]
    if np.isnan(x_future).any(): raise ValueError("ì˜ˆì¸¡ ì…ë ¥ì— ê²°ì¸¡ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    x_train = x_train.reshape(-1,1); x_future = x_future.reshape(-1,1)
    poly = PolynomialFeatures(degree=3, include_bias=False)
    Xtr = poly.fit_transform(x_train)
    model = LinearRegression().fit(Xtr, y_train)
    r2 = model.score(Xtr, y_train)
    y_future = model.predict(poly.transform(x_future))
    return y_future, r2, model, poly

def fit_poly4_and_predict(x_train, y_train, x_future):
    m = (~np.isnan(x_train)) & (~np.isnan(y_train))
    x_train, y_train = x_train[m], y_train[m]
    if np.isnan(x_future).any(): raise ValueError("ì˜ˆì¸¡ ì…ë ¥ì— ê²°ì¸¡ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    x_train = x_train.reshape(-1,1); x_future = x_future.reshape(-1,1)
    poly = PolynomialFeatures(degree=4, include_bias=False)
    Xtr = poly.fit_transform(x_train)
    model = LinearRegression().fit(Xtr, y_train)
    r2 = model.score(Xtr, y_train)
    y_future = model.predict(poly.transform(x_future))
    return y_future, r2, model, poly

def poly_eq_text(model):
    c = model.coef_
    c1 = c[0] if len(c)>0 else 0.0
    c2 = c[1] if len(c)>1 else 0.0
    c3 = c[2] if len(c)>2 else 0.0
    d  = model.intercept_
    return f"y = {c3:+.5e}xÂ³ {c2:+.5e}xÂ² {c1:+.5e}x {d:+.5e}"

def poly_eq_text4(model):
    c = model.coef_
    c1 = c[0] if len(c)>0 else 0.0
    c2 = c[1] if len(c)>1 else 0.0
    c3 = c[2] if len(c)>2 else 0.0
    c4 = c[3] if len(c)>3 else 0.0
    d  = model.intercept_
    return f"y = {c4:+.5e}xâ´ {c3:+.5e}xÂ³ {c2:+.5e}xÂ² {c1:+.5e}x {d:+.5e}"

def render_centered_table(df: pd.DataFrame, float1_cols=None, int_cols=None, index=False):
    float1_cols = float1_cols or []; int_cols = int_cols or []
    show = df.copy()
    for c in float1_cols:
        if c in show.columns:
            show[c] = pd.to_numeric(show[c], errors="coerce").round(1).map(lambda x: "" if pd.isna(x) else f"{x:.1f}")
    for c in int_cols:
        if c in show.columns:
            show[c] = pd.to_numeric(show[c], errors="coerce").round().astype("Int64").map(lambda x: "" if pd.isna(x) else f"{int(x):,}")
    st.markdown(show.to_html(index=index, classes="centered-table"), unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜ˆì¸¡ ìœ í˜•
with st.sidebar:
    title_with_icon("ğŸ§­", "ì˜ˆì¸¡ ìœ í˜•", "h3", small=True)
    mode = st.radio("ğŸ”€ ì„ íƒ", ["ê³µê¸‰ëŸ‰ ì˜ˆì¸¡", "íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©)", "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡"], index=0, label_visibility="visible")

# =============== A) ê³µê¸‰ëŸ‰ ì˜ˆì¸¡ (ê¸°ì¡´ ìœ ì§€ + UI ë³´ê°•) =========================
if mode == "ê³µê¸‰ëŸ‰ ì˜ˆì¸¡":
    with st.sidebar:
        title_with_icon("ğŸ“¥", "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", "h3", small=True)
        src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0)

        df = None
        forecast_df = None

        if src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
            data_dir = Path("data"); data_dir.mkdir(exist_ok=True)
            repo_files = sorted([str(p) for p in data_dir.glob("*.xlsx")])

            if repo_files:
                default_idx = next((i for i,p in enumerate(repo_files)
                                    if ("ìƒí’ˆë³„ê³µê¸‰ëŸ‰" in Path(p).stem) or ("ê³µê¸‰ëŸ‰" in Path(p).stem)), 0)
                file_choice = st.selectbox("ğŸ“„ ì‹¤ì  íŒŒì¼(Excel)", repo_files, index=default_idx,
                                           format_func=lambda p: Path(p).name)
                df = read_excel_sheet(file_choice, prefer_sheet="ë°ì´í„°")
            else:
                st.info("ğŸ“‚ data í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¡œ ì§„í–‰í•˜ì„¸ìš”.")

            fc_candidates = [data_dir / "ê¸°ì˜¨ì˜ˆì¸¡.xlsx", *[Path(p) for p in glob(str(data_dir / "*ê¸°ì˜¨ì˜ˆì¸¡*.xlsx"))]]
            if any(p.exists() for p in fc_candidates):
                fc_path = next(p for p in fc_candidates if p.exists())
                st.success(f"ğŸŒ¡ï¸ ì˜ˆìƒê¸°ì˜¨ íŒŒì¼ ì‚¬ìš©: {fc_path.name}")
                forecast_df = read_temperature_forecast(fc_path)
            else:
                up_fc = st.file_uploader("ğŸŒ¡ï¸ ì˜ˆìƒê¸°ì˜¨ ì—…ë¡œë“œ(xlsx) â€” (ë‚ ì§œ, í‰ê· ê¸°ì˜¨[, ì¶”ì„¸ë¶„ì„])", type=["xlsx"], key="up_fc_repo")
                if up_fc is not None:
                    forecast_df = read_temperature_forecast(up_fc)

        else:
            up = st.file_uploader("ğŸ“„ ì‹¤ì  ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” 'ë°ì´í„°' ì‹œíŠ¸", type=["xlsx"])
            if up is not None:
                df = read_excel_sheet(up, prefer_sheet="ë°ì´í„°")
            up_fc = st.file_uploader("ğŸŒ¡ï¸ ì˜ˆìƒê¸°ì˜¨ ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” (ë‚ ì§œ, í‰ê· ê¸°ì˜¨[, ì¶”ì„¸ë¶„ì„])", type=["xlsx"])
            if up_fc is not None:
                forecast_df = read_temperature_forecast(up_fc)

        if df is None or len(df)==0:
            st.info("ğŸ§© ì¢Œì¸¡ì—ì„œ ì‹¤ì  ì—‘ì…€ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()
        if forecast_df is None or forecast_df.empty:
            st.info("ğŸŒ¡ï¸ ì¢Œì¸¡ì—ì„œ ì˜ˆìƒê¸°ì˜¨ ì—‘ì…€ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()

        title_with_icon("ğŸ“š", "í•™ìŠµ ë°ì´í„° ì—°ë„ ì„ íƒ", "h3", small=True)
        years_all = sorted([int(y) for y in pd.Series(df["ì—°"]).dropna().unique()])
        years_sel = st.multiselect("ğŸ—“ï¸ ì—°ë„ ì„ íƒ", years_all, default=years_all)

        temp_col = detect_temp_col(df)
        if temp_col is None:
            st.error("ğŸŒ¡ï¸ ê¸°ì˜¨ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì—´ ì´ë¦„ì— 'í‰ê· ê¸°ì˜¨' ë˜ëŠ” 'ê¸°ì˜¨' í¬í•¨ í•„ìš”."); st.stop()

        title_with_icon("ğŸ§°", "ì˜ˆì¸¡í•  ìƒí’ˆ ì„ íƒ", "h3", small=True)
        product_cols = guess_product_cols(df)
        default_products = [c for c in KNOWN_PRODUCT_ORDER if c in product_cols] or product_cols[:6]
        prods = st.multiselect("ğŸ“¦ ìƒí’ˆ(ìš©ë„) ì„ íƒ", product_cols, default=default_products)

        # =========== ì˜ˆì¸¡ ì„¤ì • ===========
        title_with_icon("âš™ï¸", "ì˜ˆì¸¡ ì„¤ì •", "h3", small=True)
        last_year = int(df["ì—°"].max())
        years = list(range(2010, 2036))

        col_sy, col_sm = st.columns(2)
        with col_sy:
            start_y = st.selectbox("ğŸš€ ì˜ˆì¸¡ ì‹œì‘(ì—°)", years, index=years.index(last_year))
        with col_sm:
            start_m = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì‹œì‘(ì›”)", list(range(1,13)), index=0)

        col_ey, col_em = st.columns(2)
        with col_ey:
            end_y = st.selectbox("ğŸ ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", years, index=years.index(last_year))
        with col_em:
            end_m = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì¢…ë£Œ(ì›”)", list(range(1,13)), index=11)

        run_btn = st.button("ğŸ§® ì˜ˆì¸¡ ì‹œì‘", type="primary")

    if run_btn:
        base = df.dropna(subset=["ë‚ ì§œ"]).sort_values("ë‚ ì§œ").reset_index(drop=True)
        train_df = base[base["ì—°"].isin(years_sel)].copy()

        f_start = pd.Timestamp(year=int(start_y), month=int(start_m), day=1)
        f_end   = pd.Timestamp(year=int(end_y),   month=int(end_m),   day=1)
        if f_end < f_start: st.error("â›” ì˜ˆì¸¡ ì¢…ë£Œê°€ ì‹œì‘ë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤."); st.stop()
        fut_idx = month_range_inclusive(f_start, f_end)
        fut_base = pd.DataFrame({"ì—°": fut_idx.year.astype(int), "ì›”": fut_idx.month.astype(int)})

        # ì˜ˆìƒê¸°ì˜¨/ì¶”ì„¸ê¸°ì˜¨ ë³‘í•©
        fut_base = fut_base.merge(forecast_df, on=["ì—°","ì›”"], how="left")  # 'ì˜ˆìƒê¸°ì˜¨','ì¶”ì„¸ê¸°ì˜¨'

        # ë¹ˆ ì›” ë³´ê°•
        monthly_avg_temp = train_df.groupby("ì›”")[temp_col].mean().rename("ì›”í‰ê· ").reset_index()
        miss1 = fut_base["ì˜ˆìƒê¸°ì˜¨"].isna()
        if miss1.any():
            fut_base = fut_base.merge(monthly_avg_temp, on="ì›”", how="left")
            fut_base.loc[miss1, "ì˜ˆìƒê¸°ì˜¨"] = fut_base.loc[miss1, "ì›”í‰ê· "]
        miss2 = fut_base["ì¶”ì„¸ê¸°ì˜¨"].isna()
        if miss2.any():
            fut_base.loc[miss2, "ì¶”ì„¸ê¸°ì˜¨"] = fut_base.loc[miss2, "ì˜ˆìƒê¸°ì˜¨"]
        fut_base.drop(columns=[c for c in ["ì›”í‰ê· "] if c in fut_base.columns], inplace=True)

        x_train_base = train_df[temp_col].astype(float).values

        st.session_state["supply_materials"] = dict(
            base_df=base, train_df=train_df, prods=prods, x_train=x_train_base,
            fut_base=fut_base, start_ts=f_start, end_ts=f_end, temp_col=temp_col,
            default_pred_years=list(range(int(start_y), int(end_y)+1))
        )
        st.success("âœ… ê³µê¸‰ëŸ‰ ì˜ˆì¸¡(ë² ì´ìŠ¤) ì¤€ë¹„ ì™„ë£Œ! ì•„ë˜ì—ì„œ **ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C**ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.")

    if "supply_materials" not in st.session_state:
        st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì„¤ì • í›„ **ì˜ˆì¸¡ ì‹œì‘**ì„ ëˆŒëŸ¬ ì‹¤í–‰í•˜ì„¸ìš”.")
        st.stop()

    mats = st.session_state["supply_materials"]
    base, train_df, prods = mats["base_df"], mats["train_df"], mats["prods"]
    x_train, fut_base = mats["x_train"], mats["fut_base"]
    temp_col = mats["temp_col"]
    months = list(range(1,13))

    # â”€â”€â”€ ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C â”€â”€â”€
    title_with_icon("ğŸŒ¡ï¸", "ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C (í‰ê· ê¸°ì˜¨ ë³´ì •)", "h3", small=True)
    c1, c2, c3 = st.columns(3)
    with c1:
        d_norm = st.number_input("Normal Î”Â°C", value=0.0, step=0.5, format="%.1f", key="s_norm")
    with c2:
        d_best = st.number_input("Best Î”Â°C", value=-1.0, step=0.5, format="%.1f", key="s_best")
    with c3:
        d_cons = st.number_input("Conservative Î”Â°C", value=1.0, step=0.5, format="%.1f", key="s_cons")

    # ê³µí†µ ì˜ˆì¸¡ í…Œì´ë¸” ë¹Œë”
    def _forecast_table(delta: float) -> pd.DataFrame:
        x_future = (fut_base["ì˜ˆìƒê¸°ì˜¨"] + float(delta)).astype(float).values
        pred_rows = []
        for col in prods:
            y_train = train_df[col].astype(float).values
            y_future, _, _, _ = fit_poly3_and_predict(x_train, y_train, x_future)
            tmp = fut_base[["ì—°","ì›”"]].copy()
            tmp["ì›”í‰ê· ê¸°ì˜¨"] = x_future
            tmp["ìƒí’ˆ"] = col
            tmp["ì˜ˆì¸¡"] = np.clip(np.rint(y_future).astype(np.int64), a_min=0, a_max=None)
            pred_rows.append(tmp)
        pred_all = pd.concat(pred_rows, ignore_index=True)
        pivot = pred_all.pivot_table(index=["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨"], columns="ìƒí’ˆ", values="ì˜ˆì¸¡").reset_index()
        ordered = [c for c in KNOWN_PRODUCT_ORDER if c in pivot.columns]
        others = [c for c in pivot.columns if c not in (["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨"] + ordered)]
        pivot = pivot[["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨"] + ordered + others]
        return pivot.sort_values(["ì—°","ì›”"]).reset_index(drop=True)

    def _forecast_table_trend() -> pd.DataFrame:
        x_future = fut_base["ì¶”ì„¸ê¸°ì˜¨"].astype(float).values
        if np.isnan(x_future).any():
            back = train_df.groupby("ì›”")[temp_col].mean().reindex(fut_base["ì›”"]).values
            x_future = np.where(np.isnan(x_future), back, x_future)

        pred_rows = []
        for col in prods:
            y_train = train_df[col].astype(float).values
            y_future, _, _, _ = fit_poly3_and_predict(x_train, y_train, x_future)
            tmp = fut_base[["ì—°","ì›”"]].copy()
            tmp["ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"] = x_future
            tmp["ìƒí’ˆ"] = col
            tmp["ì˜ˆì¸¡"] = np.clip(np.rint(y_future).astype(np.int64), a_min=0, a_max=None)
            pred_rows.append(tmp)
        pred_all = pd.concat(pred_rows, ignore_index=True)
        pivot = pred_all.pivot_table(index=["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"], columns="ìƒí’ˆ", values="ì˜ˆì¸¡").reset_index()
        ordered = [c for c in KNOWN_PRODUCT_ORDER if c in pivot.columns]
        others = [c for c in pivot.columns if c not in (["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"] + ordered)]
        pivot = pivot[["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"] + ordered + others]
        return pivot.sort_values(["ì—°","ì›”"]).reset_index(drop=True)

    # â”€â”€â”€ í‘œ 4ì¢… (ì›”ë³„í‘œ + ì—°ë„ë³„ ì´ê³„í‘œ) â”€â”€â”€
    def _render_with_year_sums(title, table, temp_col_name):
        st.markdown(f"### {title}")
        render_centered_table(
            table,
            float1_cols=[temp_col_name],
            int_cols=[c for c in table.columns if c not in ["ì—°","ì›”",temp_col_name]],
            index=False
        )
        sums = table.groupby("ì—°").sum(numeric_only=True).reset_index()
        if "ì›”" in sums.columns: sums["ì›”"] = "1~12ì›”"
        if "ì›”í‰ê· ê¸°ì˜¨" in sums.columns: sums["ì›”í‰ê· ê¸°ì˜¨"] = ""
        if "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)" in sums.columns: sums["ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"] = ""
        cols_int = [c for c in sums.columns if c not in ["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨","ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"]]
        st.markdown("#### ì—°ë„ë³„ ì´ê³„")
        render_centered_table(sums, int_cols=cols_int, index=False)
        return sums

    tbl_n   = _forecast_table(d_norm)
    tbl_b   = _forecast_table(d_best)
    tbl_c   = _forecast_table(d_cons)
    tbl_trd = _forecast_table_trend()

    sum_n   = _render_with_year_sums("ğŸ¯ Normal",        tbl_n,   "ì›”í‰ê· ê¸°ì˜¨")
    sum_b   = _render_with_year_sums("ğŸ’ Best",          tbl_b,   "ì›”í‰ê· ê¸°ì˜¨")
    sum_c   = _render_with_year_sums("ğŸ›¡ï¸ Conservative", tbl_c,   "ì›”í‰ê· ê¸°ì˜¨")
    sum_t   = _render_with_year_sums("ğŸ“ˆ ê¸°ì˜¨ì¶”ì„¸ë¶„ì„",    tbl_trd, "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)")

    # â”€â”€â”€ ë‹¤ìš´ë¡œë“œ â”€â”€â”€
    def _pack_for_download(df_list, names, temp_names):
        outs = []
        for df, nm, tnm in zip(df_list, names, temp_names):
            d = df.copy()
            d.insert(0, "ì‹œë‚˜ë¦¬ì˜¤", nm)
            if tnm in d.columns and tnm != "ì›”í‰ê· ê¸°ì˜¨":
                d.rename(columns={tnm: "ì›”í‰ê· ê¸°ì˜¨"}, inplace=True)
            outs.append(d)
        return pd.concat(outs, ignore_index=True)

    to_dl = _pack_for_download(
        [tbl_n, tbl_b, tbl_c, tbl_trd],
        ["Normal", "Best", "Conservative", "ê¸°ì˜¨ì¶”ì„¸ë¶„ì„"],
        ["ì›”í‰ê· ê¸°ì˜¨", "ì›”í‰ê· ê¸°ì˜¨", "ì›”í‰ê· ê¸°ì˜¨", "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"]
    )

    excel_bytes = None
    try:
        buf = BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as writer:
            to_dl.to_excel(writer, index=False, sheet_name="Forecast")
            sum_n.to_excel(writer, index=False, sheet_name="YearSum_Normal")
            sum_b.to_excel(writer, index=False, sheet_name="YearSum_Best")
            sum_c.to_excel(writer, index=False, sheet_name="YearSum_Cons")
            sum_t.to_excel(writer, index=False, sheet_name="YearSum_TrendTemp")
        buf.seek(0); excel_bytes = buf.read()
    except Exception:
        excel_bytes = None

    if excel_bytes:
        st.download_button(
            "â¬‡ï¸ ì˜ˆì¸¡ ê²°ê³¼ XLSX ë‹¤ìš´ë¡œë“œ (Normal/Best/Cons/ê¸°ì˜¨ì¶”ì„¸ë¶„ì„)",
            data=excel_bytes,
            file_name="citygas_supply_forecast.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.download_button(
            "â¬‡ï¸ ì˜ˆì¸¡ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ (Normal/Best/Cons/ê¸°ì˜¨ì¶”ì„¸ë¶„ì„)",
            data=to_dl.to_csv(index=False).encode("utf-8-sig"),
            file_name="citygas_supply_forecast.csv",
            mime="text/csv"
        )

    # â”€â”€â”€ ìƒë‹¨ ê·¸ë˜í”„ (Plotly) â€” ì œëª©Â·í† ê¸€ â”€â”€â”€
    title_with_icon("ğŸ“ˆ", "ê·¸ë˜í”„(ì‹¤ì  + ì˜ˆì¸¡ + ê¸°ì˜¨ì¶”ì„¸ë¶„ì„)", "h3", small=True)

    cc1, cc2 = st.columns([1,2])
    with cc1:
        show_best = st.toggle("Best í‘œì‹œ", value=False, key="show_best_top")
        show_cons = st.toggle("Conservative í‘œì‹œ", value=False, key="show_cons_top")

    years_all_for_plot = sorted([int(v) for v in base["ì—°"].dropna().unique()])
    default_years = years_all_for_plot[-2:] if len(years_all_for_plot)>=2 else years_all_for_plot
    c_y1, c_y2, c_y3 = st.columns(3)
    with c_y1:
        years_view = st.multiselect("ğŸ‘€ ì‹¤ì ì—°ë„", options=years_all_for_plot, default=default_years, key="supply_years_view")
    pred_default = mats.get("default_pred_years", [])
    with c_y2:
        years_pred = st.multiselect("ğŸ“ˆ ì˜ˆì¸¡ì—°ë„", options=sorted(list(set(fut_base["ì—°"].tolist()))),
                                    default=[y for y in pred_default if y in fut_base["ì—°"].unique()], key="years_pred")
    with c_y3:
        years_trnd = st.multiselect("ğŸ“Š ê¸°ì˜¨ì¶”ì„¸ë¶„ì„ì—°ë„", options=sorted(list(set(fut_base["ì—°"].tolist()))),
                                    default=[y for y in pred_default if y in fut_base["ì—°"].unique()], key="years_trnd")

    months_txt = [f"{m}ì›”" for m in months]

    def _pred_series(delta):
        return (fut_base["ì˜ˆìƒê¸°ì˜¨"] + float(delta)).astype(float).values

    x_future_norm = _pred_series(d_norm)
    x_future_best = _pred_series(d_best)
    x_future_cons = _pred_series(d_cons)
    x_future_trend = fut_base["ì¶”ì„¸ê¸°ì˜¨"].astype(float).values
    if np.isnan(x_future_trend).any():
        back = train_df.groupby("ì›”")[temp_col].mean().reindex(fut_base["ì›”"]).values
        x_future_trend = np.where(np.isnan(x_future_trend), back, x_future_trend)

    for prod in prods:
        y_train_prod = train_df[prod].astype(float).values

        y_future_norm, r2_train, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_norm)
        P_norm = fut_base[["ì—°","ì›”"]].copy(); P_norm["pred"] = np.clip(np.rint(y_future_norm).astype(np.int64), a_min=0, a_max=None)

        y_future_best, _, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_best)
        P_best = fut_base[["ì—°","ì›”"]].copy(); P_best["pred"] = np.clip(np.rint(y_future_best).astype(np.int64), a_min=0, a_max=None)

        y_future_cons, _, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_cons)
        P_cons = fut_base[["ì—°","ì›”"]].copy(); P_cons["pred"] = np.clip(np.rint(y_future_cons).astype(np.int64), a_min=0, a_max=None)

        y_future_trd, _, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_trend)
        P_trend = fut_base[["ì—°","ì›”"]].copy(); P_trend["pred"] = np.clip(np.rint(y_future_trd).astype(np.int64), a_min=0, a_max=None)

        if go is None:
            fig = plt.figure(figsize=(9,3.6)); ax = plt.gca()
            for y in sorted([int(v) for v in years_view]):
                s = (base.loc[base["ì—°"]==y, ["ì›”", prod]].set_index("ì›”")[prod]).reindex(months)
                ax.plot(months, s.values, label=f"{y} ì‹¤ì ")
            for y in years_pred:
                pred_vals = P_norm[P_norm["ì—°"]==int(y)].sort_values("ì›”")["pred"].reindex(range(1,13)).values
                ax.plot(months, pred_vals, linestyle="--", label=f"ì˜ˆì¸¡(Normal) {y}")
                if show_best:
                    pv = P_best[P_best["ì—°"]==int(y)].sort_values("ì›”")["pred"].reindex(range(1,13)).values
                    ax.plot(months, pv, linestyle="--", label=f"ì˜ˆì¸¡(Best) {y}")
                if show_cons:
                    pv = P_cons[P_cons["ì—°"]==int(y)].sort_values("ì›”")["pred"].reindex(range(1,13)).values
                    ax.plot(months, pv, linestyle="--", label=f"ì˜ˆì¸¡(Conservative) {y}")
            for y in years_trnd:
                pred_vals = P_trend[P_trend["ì—°"]==int(y)].sort_values("ì›”")["pred"].reindex(range(1,13)).values
                ax.plot(months, pred_vals, linestyle=":", label=f"ê¸°ì˜¨ì¶”ì„¸ë¶„ì„ {y}")
            ax.set_xlim(1,12); ax.set_xticks(months); ax.set_xticklabels(months_txt)
            ax.set_xlabel("ì›”"); ax.set_ylabel("ê³µê¸‰ëŸ‰ (MJ)")
            ax.set_title(f"{prod} â€” Poly-3 (Train RÂ²={r2_train:.3f})"); ax.legend(loc="best"); st.pyplot(fig, clear_figure=True)
        else:
            fig = go.Figure()
            for y in sorted([int(v) for v in years_view]):
                one = base[base["ì—°"]==y][["ì›”", prod]].dropna().sort_values("ì›”")
                fig.add_trace(go.Scatter(
                    x=[f"{int(m)}ì›”" for m in one["ì›”"]], y=one[prod], mode="lines+markers",
                    name=f"{y} ì‹¤ì ", hovertemplate="%{x} %{y:,}"
                ))
            for y in years_pred:
                row = P_norm[P_norm["ì—°"]==int(y)].sort_values("ì›”")
                fig.add_trace(go.Scatter(
                    x=[f"{int(m)}ì›”" for m in row["ì›”"]], y=row["pred"], mode="lines",
                    name=f"ì˜ˆì¸¡(Normal) {y}", line=dict(dash="dash"), hovertemplate="%{x} %{y:,}"
                ))
                if show_best:
                    rb = P_best[P_best["ì—°"]==int(y)].sort_values("ì›”")
                    fig.add_trace(go.Scatter(
                        x=[f"{int(m)}ì›”" for m in rb["ì›”"]], y=rb["pred"], mode="lines",
                        name=f"ì˜ˆì¸¡(Best) {y}", line=dict(dash="dash"), hovertemplate="%{x} %{y:,}"
                    ))
                if show_cons:
                    rc = P_cons[P_cons["ì—°"]==int(y)].sort_values("ì›”")
                    fig.add_trace(go.Scatter(
                        x=[f"{int(m)}ì›”" for m in rc["ì›”"]], y=rc["pred"], mode="lines",
                        name=f"ì˜ˆì¸¡(Conservative) {y}", line=dict(dash="dash"), hovertemplate="%{x} %{y:,}"
                    ))
            for y in years_trnd:
                row = P_trend[P_trend["ì—°"]==int(y)].sort_values("ì›”")
                fig.add_trace(go.Scatter(
                    x=[f"{int(m)}ì›”" for m in row["ì›”"]], y=row["pred"], mode="lines",
                    name=f"ê¸°ì˜¨ì¶”ì„¸ë¶„ì„ {y}", line=dict(dash="dot"), hovertemplate="%{x} %{y:,}"
                ))
            fig.update_layout(
                title=f"{prod} â€” Poly-3 (Train RÂ²={r2_train:.3f})",
                xaxis=dict(title="ì›”"),
                yaxis=dict(title="ê³µê¸‰ëŸ‰ (MJ)", rangemode="tozero"),
                legend=dict(orientation="h", yanchor="bottom", y=-0.2, xanchor="left", x=0)
            )
            config = dict(scrollZoom=True, doubleClick=False, displaylogo=False, displayModeBar=True)
            fig.update_layout(dragmode="pan")
            st.plotly_chart(fig, use_container_width=True, config=config)

        # í•˜ë‹¨ ìƒê´€ë„
        title_with_icon("ğŸ”", f"{prod} â€” ê¸°ì˜¨Â·ê³µê¸‰ëŸ‰ ìƒê´€(Train, RÂ²={r2_train:.3f})", "h3", small=True)
        figc, axc = plt.subplots(figsize=(10,5.2))
        x_tr = train_df[temp_col].astype(float).values
        y_tr = y_train_prod
        axc.scatter(x_tr, y_tr, alpha=0.65, label="í•™ìŠµ ìƒ˜í”Œ")
        xx = np.linspace(np.nanmin(x_tr)-1, np.nanmax(x_tr)+1, 200)
        yhat, _, model_s, _ = fit_poly3_and_predict(x_tr, y_tr, xx)
        axc.plot(xx, yhat, lw=2.8, color="#1f77b4", label="Poly-3")
        pred_train, _, _, _ = fit_poly3_and_predict(x_tr, y_tr, x_tr)
        resid = y_tr - pred_train; s = np.nanstd(resid)
        axc.fill_between(xx, yhat-1.96*s, yhat+1.96*s, color="#ff7f0e", alpha=0.25, label="95% ì‹ ë¢°êµ¬ê°„")
        bins = np.linspace(np.nanmin(x_tr), np.nanmax(x_tr), 15)
        gb = pd.DataFrame({"bin": pd.cut(x_tr, bins), "y": y_tr}).groupby("bin")["y"].median().reset_index()
        gb["x"] = [b.mid for b in gb["bin"]]
        axc.scatter(gb["x"], gb["y"], label="ì˜¨ë„ë³„ ì¤‘ì•™ê°’", s=65, color="#ff7f0e")
        axc.set_xlabel("ê¸°ì˜¨ (â„ƒ)"); axc.set_ylabel("ê³µê¸‰ëŸ‰ (MJ)")
        axc.grid(alpha=0.25); axc.legend(loc="best")
        xmin, xmax = axc.get_xlim(); ymin, ymax = axc.get_ylim()
        axc.text(xmin + 0.02*(xmax-xmin), ymin + 0.04*(ymax-ymin),
                 f"Poly-3: {poly_eq_text(model_s)}",
                 fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(figc)

    st.caption("â„¹ï¸ **95% ì‹ ë¢°êµ¬ê°„**: ì”ì°¨ í‘œì¤€í¸ì°¨ ê¸°ì¤€ ê·¼ì‚¬ ì˜ˆì¸¡êµ¬ê°„ìœ¼ë¡œ, ìƒˆë¡œìš´ ê´€ì¸¡ì´ ì•½ 95% í™•ë¥ ë¡œ ì´ ìŒì˜ ì•ˆì— ë“¤ì–´ì˜µë‹ˆë‹¤.")

# =============== B) íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©) â€” ê¸°ì¡´ ì „ì²´ ë¡œì§ ìœ ì§€ ==================
elif mode == "íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©)":
    title_with_icon("ğŸ§Š", "íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©) â€” ì „ì›” 16ì¼ ~ ë‹¹ì›” 15ì¼ í‰ê· ê¸°ì˜¨ ê¸°ì¤€", "h2")
    st.write("ğŸ—‚ï¸ ëƒ‰ë°©ìš© **íŒë§¤ ì‹¤ì  ì—‘ì…€**ê³¼ **ê¸°ì˜¨ RAW(ì¼ë³„)**ì„ ì¤€ë¹„í•˜ì„¸ìš”.")

    with st.sidebar:
        title_with_icon("ğŸ“¥", "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", "h3", small=True)
        sales_src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0)

    def _find_repo_sales_and_temp():
        here = Path(__file__).parent if "__file__" in globals() else Path.cwd()
        data_dir = here / "data"
        sales_candidates = [data_dir / "ìƒí’ˆë³„íŒë§¤ëŸ‰.xlsx", *[Path(p) for p in glob(str(data_dir / "*íŒë§¤*.xlsx"))]]
        temp_candidates  = [data_dir / "ê¸°ì˜¨.xlsx", *[Path(p) for p in glob(str(data_dir / "*ê¸°ì˜¨*.xlsx"))],
                            *[Path(p) for p in glob(str(data_dir / "*temp*.csv"))]]
        sales_path = next((p for p in sales_candidates if p.exists()), None)
        temp_path  = next((p for p in temp_candidates  if p.exists()), None)
        return sales_path, temp_path

    c1, c2 = st.columns(2)
    if sales_src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
        repo_sales_path, repo_temp_path = _find_repo_sales_and_temp()
        if not repo_sales_path or not repo_temp_path:
            with c1: sales_file = st.file_uploader("ğŸ“„ ëƒ‰ë°©ìš© **íŒë§¤ ì‹¤ì  ì—‘ì…€(xlsx)**", type=["xlsx"])
            with c2: temp_raw_file = st.file_uploader("ğŸŒ¡ï¸ **ê¸°ì˜¨ RAW(ì¼ë³„)** (xlsx/csv)", type=["xlsx","csv"])
        else:
            with c1: st.info(f"ğŸ“„ ë ˆí¬ íŒŒì¼: {repo_sales_path.name}")
            with c2: st.info(f"ğŸŒ¡ï¸ ë ˆí¬ íŒŒì¼: {repo_temp_path.name}")
            sales_file = open(repo_sales_path, "rb")
            temp_raw_file = open(repo_temp_path, "rb")
    else:
        with c1: sales_file = st.file_uploader("ğŸ“„ ëƒ‰ë°©ìš© **íŒë§¤ ì‹¤ì  ì—‘ì…€(xlsx)**", type=["xlsx"])
        with c2: temp_raw_file = st.file_uploader("ğŸŒ¡ï¸ **ê¸°ì˜¨ RAW(ì¼ë³„)** (xlsx/csv)", type=["xlsx","csv"])

    if 'sales_file' not in locals() or sales_file is None or temp_raw_file is None:
        st.info("ğŸ‘ˆ ë‘ íŒŒì¼ì„ ëª¨ë‘ ì¤€ë¹„í•˜ì„¸ìš”."); st.stop()

    try:
        xls = pd.ExcelFile(sales_file, engine="openpyxl")
        sheet = "ì‹¤ì _ì›”í•©" if "ì‹¤ì _ì›”í•©" in xls.sheet_names else ("ëƒ‰ë°©ìš©" if "ëƒ‰ë°©ìš©" in xls.sheet_names else xls.sheet_names[0])
        raw_sales = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        raw_sales = pd.read_excel(sales_file, engine="openpyxl")
    sales_df = normalize_cols(raw_sales)

    date_candidates = [c for c in ["íŒë§¤ì›”","ë‚ ì§œ","ì¼ì","date"] if c in sales_df.columns]
    if date_candidates: date_col = date_candidates[0]
    else:
        score = {}
        for c in sales_df.columns:
            try: score[c] = pd.to_datetime(sales_df[c], errors="coerce").notna().mean()
            except Exception: pass
        date_col = max(score, key=score.get) if score else None
    cool_cols = [c for c in sales_df.columns if ("ëƒ‰ë°©" in str(c)) and pd.api.types.is_numeric_dtype(sales_df[c])]
    value_col = None
    for c in cool_cols:
        if "ëƒ‰ë°©ìš©" in str(c): value_col = c; break
    value_col = value_col or (cool_cols[0] if cool_cols else None)
    if date_col is None or value_col is None:
        st.error("â›” ë‚ ì§œ ì—´ ë˜ëŠ” 'ëƒ‰ë°©' ìˆ˜ì¹˜ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()

    sales_df["íŒë§¤ì›”"] = pd.to_datetime(sales_df[date_col], errors="coerce").dt.to_period("M").dt.to_timestamp()
    sales_df["íŒë§¤ëŸ‰"] = pd.to_numeric(sales_df[value_col], errors="coerce")
    sales_df = sales_df.dropna(subset=["íŒë§¤ì›”","íŒë§¤ëŸ‰"]).copy()
    sales_df["ì—°"] = sales_df["íŒë§¤ì›”"].dt.year.astype(int); sales_df["ì›”"] = sales_df["íŒë§¤ì›”"].dt.month.astype(int)

    temp_raw = read_temperature_raw(temp_raw_file)
    if temp_raw is None or temp_raw.empty:
        st.error("â›” ê¸°ì˜¨ RAWì—ì„œ ë‚ ì§œ/ê¸°ì˜¨ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()

    with st.sidebar:
        title_with_icon("ğŸ“š", "í•™ìŠµ ë°ì´í„° ì—°ë„ ì„ íƒ", "h3", small=True)
        years_all = sorted(sales_df["ì—°"].unique().tolist())
        years_sel = st.multiselect("ğŸ—“ï¸ ì—°ë„ ì„ íƒ", options=years_all, default=years_all)

        title_with_icon("âš™ï¸", "ì˜ˆì¸¡ ì„¤ì •", "h3", small=True)
        years = list(range(2010,2036))
        last_year = int(sales_df["ì—°"].max())
        col_sy, col_sm = st.columns(2)
        with col_sy:
            start_y = st.selectbox("ğŸš€ ì˜ˆì¸¡ ì‹œì‘(ì—°)", years, index=years.index(last_year))
        with col_sm:
            start_m = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì‹œì‘(ì›”)", list(range(1,13)), index=0)
        col_ey, col_em = st.columns(2)
        with col_ey:
            end_y   = st.selectbox("ğŸ ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", years, index=years.index(last_year))
        with col_em:
            end_m   = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì¢…ë£Œ(ì›”)", list(range(1,13)), index=11)
        run_btn = st.button("ğŸ§® ì˜ˆì¸¡ ì‹œì‘", type="primary")

    if run_btn:
        temp_raw["ì—°"] = temp_raw["ì¼ì"].dt.year; temp_raw["ì›”"] = temp_raw["ì¼ì"].dt.month
        monthly_cal = temp_raw.groupby(["ì—°","ì›”"])["ê¸°ì˜¨"].mean().reset_index()
        fallback_by_M = temp_raw.groupby("ì›”")["ê¸°ì˜¨"].mean()

        def period_avg(label_m: pd.Timestamp) -> float:
            m = month_start(label_m)
            s = (m - pd.offsets.MonthBegin(1)) + pd.DateOffset(days=15)  # ì „ì›”16
            e = m + pd.DateOffset(days=14)                                # ë‹¹ì›”15
            mask = (temp_raw["ì¼ì"]>=s)&(temp_raw["ì¼ì"]<=e)
            return temp_raw.loc[mask,"ê¸°ì˜¨"].mean()

        train_sales = sales_df[sales_df["ì—°"].isin(years_sel)].copy()
        rows = [{"íŒë§¤ì›”":m, "ê¸°ê°„í‰ê· ê¸°ì˜¨": period_avg(m)} for m in train_sales["íŒë§¤ì›”"].unique()]
        sj = pd.merge(train_sales[["íŒë§¤ì›”","íŒë§¤ëŸ‰"]], pd.DataFrame(rows), on="íŒë§¤ì›”", how="left")
        miss = sj["ê¸°ê°„í‰ê· ê¸°ì˜¨"].isna()
        if miss.any(): sj.loc[miss,"ê¸°ê°„í‰ê· ê¸°ì˜¨"] = sj.loc[miss,"íŒë§¤ì›”"].dt.month.map(fallback_by_M)
        sj = sj.dropna(subset=["ê¸°ê°„í‰ê· ê¸°ì˜¨","íŒë§¤ëŸ‰"])

        x_train = sj["ê¸°ê°„í‰ê· ê¸°ì˜¨"].astype(float).values
        y_train = sj["íŒë§¤ëŸ‰"].astype(float).values
        _, r2_fit, model_fit, _ = fit_poly3_and_predict(x_train, y_train, x_train)
        _, r2_fit4, model_fit4, _ = fit_poly4_and_predict(x_train, y_train, x_train)

        f_start = pd.Timestamp(year=int(start_y), month=int(start_m), day=1)
        f_end   = pd.Timestamp(year=int(end_y),   month=int(end_m),   day=1)
        if f_end < f_start: st.error("â›” ì˜ˆì¸¡ ì¢…ë£Œê°€ ì‹œì‘ë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤."); st.stop()

        months_rng = month_range_inclusive(f_start, f_end)
        rows = []
        for m in months_rng:
            s = (m - pd.offsets.MonthBegin(1)) + pd.DateOffset(days=15)
            e = m + pd.DateOffset(days=14)
            mask = (temp_raw["ì¼ì"]>=s)&(temp_raw["ì¼ì"]<=e)
            avg_period = temp_raw.loc[mask,"ê¸°ì˜¨"].mean()
            avg_month  = monthly_cal.loc[(monthly_cal["ì—°"]==m.year)&(monthly_cal["ì›”"]==m.month),"ê¸°ì˜¨"].mean()
            rows.append({"ì—°":int(m.year),"ì›”":int(m.month),"ê¸°ê°„í‰ê· ê¸°ì˜¨":avg_period,"ë‹¹ì›”í‰ê· ê¸°ì˜¨":avg_month})
        pred_base = pd.DataFrame(rows)
        for c in ["ê¸°ê°„í‰ê· ê¸°ì˜¨","ë‹¹ì›”í‰ê· ê¸°ì˜¨"]:
            miss = pred_base[c].isna()
            if miss.any(): pred_base.loc[miss,c] = pred_base.loc[miss,"ì›”"].map(fallback_by_M)

        st.session_state["sales_materials"] = dict(
            sales_df=sales_df, temp_raw=temp_raw, years_all=years_all,
            train_xy=(x_train, y_train),
            r2_fit=r2_fit, model_fit=model_fit,
            r2_fit4=r2_fit4, model_fit4=model_fit4,
            pred_base=pred_base, f_start=f_start, f_end=f_end
        )
        st.success("âœ… ëƒ‰ë°©ìš© íŒë§¤ëŸ‰ ì˜ˆì¸¡(ë² ì´ìŠ¤) ì¤€ë¹„ ì™„ë£Œ! ì•„ë˜ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ Î”Â°Cë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.")

    if "sales_materials" not in st.session_state:
        st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì„¤ì • í›„ **ì˜ˆì¸¡ ì‹œì‘**ì„ ëˆŒëŸ¬ ì‹¤í–‰í•˜ì„¸ìš”.")
        st.stop()

    sm = st.session_state["sales_materials"]
    sales_df, pred_base = sm["sales_df"], sm["pred_base"]
    x_train, y_train = sm["train_xy"]
    r2_fit, r2_fit4 = sm["r2_fit"], sm["r2_fit4"]
    years_all = sm["years_all"]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‹¤í•­ì‹ ë³´ê¸° ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("#### ë‹¤í•­ì‹ ë³´ê¸° ì„ íƒ")
    view_choice = st.radio("ë‹¤í•­ì‹", options=["3ì°¨(Poly-3)", "4ì°¨(Poly-4)", "ë‘˜ ë‹¤"], index=2, horizontal=True, key="poly_view_choice")
    show_poly3 = view_choice in ["3ì°¨(Poly-3)", "ë‘˜ ë‹¤"]
    show_poly4 = view_choice in ["4ì°¨(Poly-4)", "ë‘˜ ë‹¤"]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Poly-3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if show_poly3:
        st.subheader("ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C (í‰ê· ê¸°ì˜¨ ë³´ì •) â€” Poly-3")
        c1, c2, c3 = st.columns(3)
        with c1:
            d_norm = st.number_input("Normal Î”Â°C", value=0.0, step=0.5, format="%.1f", key="c_norm")
        with c2:
            d_best = st.number_input("Best Î”Â°C", value=-1.0, step=0.5, format="%.1f", key="c_best")
        with c3:
            d_cons = st.number_input("Conservative Î”Â°C", value=1.0, step=0.5, format="%.1f", key="c_cons")

        def forecast_sales_table(delta: float) -> pd.DataFrame:
            base = pred_base.copy()
            base["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)"] = base["ë‹¹ì›”í‰ê· ê¸°ì˜¨"] + delta
            base["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"] = base["ê¸°ê°„í‰ê· ê¸°ì˜¨"] + delta
            y_future, _, _, _ = fit_poly3_and_predict(x_train, y_train, base["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"].values.astype(float))
            base["ì˜ˆì¸¡íŒë§¤ëŸ‰"] = np.clip(np.rint(y_future).astype(np.int64), a_min=0, a_max=None)
            out = base[["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)","ì˜ˆì¸¡íŒë§¤ëŸ‰"]].copy()
            out.loc[len(out)] = ["", "ì¢…ê³„", "", "", int(out["ì˜ˆì¸¡íŒë§¤ëŸ‰"].sum())]
            return out

        st.markdown("### Normal")
        sale_n = forecast_sales_table(d_norm)
        render_centered_table(sale_n, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)

        st.markdown("### Best")
        sale_b = forecast_sales_table(d_best)
        render_centered_table(sale_b, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)

        st.markdown("### Conservative")
        sale_c = forecast_sales_table(d_cons)
        render_centered_table(sale_c, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)

        st.download_button(
            "íŒë§¤ëŸ‰ ì˜ˆì¸¡ CSV ë‹¤ìš´ë¡œë“œ (Poly-3 Â· Normal)",
            data=sale_n.to_csv(index=False).encode("utf-8-sig"),
            file_name="cooling_sales_forecast_poly3_normal.csv", mime="text/csv"
        )

        # ê²€ì¦ í…Œì´ë¸”
        st.subheader("íŒë§¤ëŸ‰ ì˜ˆì¸¡ ê²€ì¦ â€” Poly-3")
        valid_pred = sale_n[sale_n["ì›”"]!="ì¢…ê³„"].copy()
        valid_pred["ì—°"] = pd.to_numeric(valid_pred["ì—°"], errors="coerce").astype("Int64")
        valid_pred["ì›”"] = pd.to_numeric(valid_pred["ì›”"], errors="coerce").astype("Int64")
        comp = pd.merge(
            valid_pred[["ì—°","ì›”","ì˜ˆì¸¡íŒë§¤ëŸ‰"]],
            sales_df[["ì—°","ì›”","íŒë§¤ëŸ‰"]].rename(columns={"íŒë§¤ëŸ‰":"ì‹¤ì œíŒë§¤ëŸ‰"}),
            on=["ì—°","ì›”"], how="left"
        ).sort_values(["ì—°","ì›”"])
        comp["ì˜¤ì°¨"] = (comp["ì˜ˆì¸¡íŒë§¤ëŸ‰"] - comp["ì‹¤ì œíŒë§¤ëŸ‰"]).astype("Int64")
        comp["ì˜¤ì°¨ìœ¨(%)"] = ((comp["ì˜¤ì°¨"] / comp["ì‹¤ì œíŒë§¤ëŸ‰"]) * 100).round(1).astype("Float64")
        render_centered_table(comp[["ì—°","ì›”","ì‹¤ì œíŒë§¤ëŸ‰","ì˜ˆì¸¡íŒë§¤ëŸ‰","ì˜¤ì°¨","ì˜¤ì°¨ìœ¨(%)"]],
                              int_cols=["ì‹¤ì œíŒë§¤ëŸ‰","ì˜ˆì¸¡íŒë§¤ëŸ‰","ì˜¤ì°¨"], index=False)

        # ê·¸ë˜í”„ (Normal ê¸°ì¤€)
        st.subheader("ê·¸ë˜í”„ (Normal ê¸°ì¤€) â€” Poly-3")
        years_default = years_all[-5:] if len(years_all)>=5 else years_all
        years_view = st.multiselect("í‘œì‹œí•  ì‹¤ì  ì—°ë„", options=years_all,
                                    default=st.session_state.get("sales_years_view", years_default),
                                    key="sales_years_view")
        base_plot = pred_base.copy()
        base_plot["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"] = base_plot["ê¸°ê°„í‰ê· ê¸°ì˜¨"] + d_norm
        y_pred_norm, r2_line, model_line, _ = fit_poly3_and_predict(
            x_train, y_train, base_plot["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"].values.astype(float)
        )
        base_plot["pred"] = np.clip(np.rint(y_pred_norm).astype(np.int64), 0, None)
        months = list(range(1,13))
        fig2, ax2 = plt.subplots(figsize=(10,4.2))
        for y in years_view:
            one = sales_df[sales_df["ì—°"]==y][["ì›”","íŒë§¤ëŸ‰"]].dropna()
            if not one.empty:
                ax2.plot(one["ì›”"], one["íŒë§¤ëŸ‰"], label=f"{y} ì‹¤ì ", alpha=0.95)
        pred_vals = []
        y, m = int(sm["f_start"].year), int(sm["f_start"].month)
        P2 = base_plot[["ì—°","ì›”","pred"]].astype(int)
        for _ in range(12):
            row = P2[(P2["ì—°"]==y)&(P2["ì›”"]==m)]
            pred_vals.append(row.iloc[0]["pred"] if len(row) else np.nan)
            if m==12: y+=1; m=1
            else: m+=1
        ax2.plot(months, pred_vals, "--", lw=2.5, label="ì˜ˆì¸¡(Normal)")
        ax2.set_xlim(1,12); ax2.set_xticks(months); ax2.set_xticklabels([f"{mm}ì›”" for mm in months])
        ax2.set_xlabel("ì›”"); ax2.set_ylabel("íŒë§¤ëŸ‰ (MJ)")
        ax2.set_title(f"ëƒ‰ë°©ìš© â€” Poly-3 (Train RÂ²={r2_line:.3f})")
        ax2.legend(loc="best"); ax2.grid(alpha=0.25)
        ax2.text(0.02, 0.96, f"Poly-3: {poly_eq_text(model_line)}",
                 transform=ax2.transAxes, ha="left", va="top", fontsize=9,
                 color="#1f77b4", bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(fig2)

        # ì‚°ì  + Poly3 + 95% ì‹ ë¢°êµ¬ê°„
        st.subheader(f"ê¸°ì˜¨-ëƒ‰ë°©ìš© ì‹¤ì  ìƒê´€ê´€ê³„ (Train, RÂ²={r2_fit:.3f}) â€” Poly-3")
        fig3, ax3 = plt.subplots(figsize=(10,5.2))
        ax3.scatter(x_train, y_train, alpha=0.65, label="í•™ìŠµ ìƒ˜í”Œ")
        xx = np.linspace(np.nanmin(x_train)-1, np.nanmax(x_train)+1, 200)
        yhat, _, model_s, _ = fit_poly3_and_predict(x_train, y_train, xx)
        ax3.plot(xx, yhat, lw=2.6, color="#1f77b4", label="Poly-3")
        pred_train, _, _, _ = fit_poly3_and_predict(x_train, y_train, x_train)
        resid = y_train - pred_train; s = np.nanstd(resid)
        ax3.fill_between(xx, yhat-1.96*s, yhat+1.96*s, color="#1f77b4", alpha=0.14, label="95% ì‹ ë¢°êµ¬ê°„")
        bins = np.linspace(np.nanmin(x_train), np.nanmax(x_train), 15)
        gb = pd.DataFrame({"bin": pd.cut(x_train, bins), "y": y_train}).groupby("bin")["y"].median().reset_index()
        gb["x"] = [b.mid for b in gb["bin"]]
        ax3.scatter(gb["x"], gb["y"], label="ì˜¨ë„ë³„ ì¤‘ì•™ê°’", s=65)
        ax3.set_xlabel("ê¸°ê°„í‰ê· ê¸°ì˜¨ (â„ƒ)"); ax3.set_ylabel("íŒë§¤ëŸ‰ (MJ)")
        ax3.grid(alpha=0.25); ax3.legend(loc="best")
        xmin, xmax = ax3.get_xlim(); ymin, ymax = ax3.get_ylim()
        ax3.text(xmin + 0.02*(xmax-xmin), ymin + 0.06*(ymax-ymin),
                 f"Poly-3: {poly_eq_text(model_s)}",
                 fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(fig3)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Poly-4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if show_poly4:
        st.markdown("---")
        title_with_icon("ğŸ§®", "Poly-4 ë¹„êµ (ë™ì¼ ì‹œë‚˜ë¦¬ì˜¤ UI)", "h2")
        st.subheader("ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C (í‰ê· ê¸°ì˜¨ ë³´ì •) â€” Poly-4")
        c41, c42, c43 = st.columns(3)
        with c41:
            d4_norm = st.number_input("Normal Î”Â°C", value=0.0, step=0.5, format="%.1f", key="c4_norm")
        with c42:
            d4_best = st.number_input("Best Î”Â°C", value=-1.0, step=0.5, format="%.1f", key="c4_best")
        with c43:
            d4_cons = st.number_input("Conservative Î”Â°C", value=1.0, step=0.5, format="%.1f", key="c4_cons")

        def forecast_sales_table_poly4(delta: float) -> pd.DataFrame:
            base = pred_base.copy()
            base["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)"] = base["ë‹¹ì›”í‰ê· ê¸°ì˜¨"] + delta
            base["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"] = base["ê¸°ê°„í‰ê· ê¸°ì˜¨"] + delta
            y_future, _, _, _ = fit_poly4_and_predict(x_train, y_train, base["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"].values.astype(float))
            base["ì˜ˆì¸¡íŒë§¤ëŸ‰"] = np.clip(np.rint(y_future).astype(np.int64), a_min=0, a_max=None)
            out = base[["ì—°","ì›”","ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)","ì˜ˆì¸¡íŒë§¤ëŸ‰"]].copy()
            out.loc[len(out)] = ["", "ì¢…ê³„", "", "", int(out["ì˜ˆì¸¡íŒë§¤ëŸ‰"].sum())]
            return out

        st.markdown("### Normal (Poly-4)")
        sale4_n = forecast_sales_table_poly4(d4_norm)
        render_centered_table(sale4_n, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)

        st.markdown("### Best (Poly-4)")
        sale4_b = forecast_sales_table_poly4(d4_best)
        render_centered_table(sale4_b, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)

        st.markdown("### Conservative (Poly-4)")
        sale4_c = forecast_sales_table_poly4(d4_cons)
        render_centered_table(sale4_c, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)","ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)

        st.download_button(
            "íŒë§¤ëŸ‰ ì˜ˆì¸¡ CSV ë‹¤ìš´ë¡œë“œ (Poly-4 Â· Normal)",
            data=sale4_n.to_csv(index=False).encode("utf-8-sig"),
            file_name="cooling_sales_forecast_poly4_normal.csv", mime="text/csv"
        )

        st.subheader("íŒë§¤ëŸ‰ ì˜ˆì¸¡ ê²€ì¦ â€” Poly-4")
        valid_pred4 = sale4_n[sale4_n["ì›”"]!="ì¢…ê³„"].copy()
        valid_pred4["ì—°"] = pd.to_numeric(valid_pred4["ì—°"], errors="coerce").astype("Int64")
        valid_pred4["ì›”"] = pd.to_numeric(valid_pred4["ì›”"], errors="coerce").astype("Int64")
        comp4 = pd.merge(
            valid_pred4[["ì—°","ì›”","ì˜ˆì¸¡íŒë§¤ëŸ‰"]],
            sales_df[["ì—°","ì›”","íŒë§¤ëŸ‰"]].rename(columns={"íŒë§¤ëŸ‰":"ì‹¤ì œíŒë§¤ëŸ‰"}),
            on=["ì—°","ì›”"], how="left"
        ).sort_values(["ì—°","ì›”"])
        comp4["ì˜¤ì°¨"] = (comp4["ì˜ˆì¸¡íŒë§¤ëŸ‰"] - comp4["ì‹¤ì œíŒë§¤ëŸ‰"]).astype("Int64")
        comp4["ì˜¤ì°¨ìœ¨(%)"] = ((comp4["ì˜¤ì°¨"] / comp4["ì‹¤ì œíŒë§¤ëŸ‰"]) * 100).round(1).astype("Float64")
        render_centered_table(comp4[["ì—°","ì›”","ì‹¤ì œíŒë§¤ëŸ‰","ì˜ˆì¸¡íŒë§¤ëŸ‰","ì˜¤ì°¨","ì˜¤ì°¨ìœ¨(%)"]],
                              int_cols=["ì‹¤ì œíŒë§¤ëŸ‰","ì˜ˆì¸¡íŒë§¤ëŸ‰","ì˜¤ì°¨"], index=False)

        st.subheader("ê·¸ë˜í”„ (Normal ê¸°ì¤€) â€” Poly-4")
        years_default4 = years_all[-5:] if len(years_all)>=5 else years_all
        years_view4 = st.multiselect("í‘œì‹œí•  ì‹¤ì  ì—°ë„", options=years_all,
                                     default=st.session_state.get("sales_years_view4", years_default4),
                                     key="sales_years_view4")
        base_plot4 = pred_base.copy()
        base_plot4["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"] = base_plot4["ê¸°ê°„í‰ê· ê¸°ì˜¨"] + d4_norm
        y_pred_norm4, r2_line4, model_line4, _ = fit_poly4_and_predict(
            x_train, y_train, base_plot4["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"].values.astype(float)
        )
        base_plot4["pred"] = np.clip(np.rint(y_pred_norm4).astype(np.int64), 0, None)

        months = list(range(1,13))
        fig24, ax24 = plt.subplots(figsize=(10,4.2))
        for yv in years_view4:
            one = sales_df[sales_df["ì—°"]==yv][["ì›”","íŒë§¤ëŸ‰"]].dropna()
            if not one.empty:
                ax24.plot(one["ì›”"], one["íŒë§¤ëŸ‰"], label=f"{yv} ì‹¤ì ", alpha=0.95)
        pred_vals4 = []
        yv, mv = int(sm["f_start"].year), int(sm["f_start"].month)
        P24 = base_plot4[["ì—°","ì›”","pred"]].astype(int)
        for _ in range(12):
            row = P24[(P24["ì—°"]==yv)&(P24["ì›”"]==mv)]
            pred_vals4.append(row.iloc[0]["pred"] if len(row) else np.nan)
            if mv==12: yv+=1; mv=1
            else: mv+=1
        ax24.plot(months, pred_vals4, "--", lw=2.5, label="ì˜ˆì¸¡(Normal)")
        ax24.set_xlim(1,12); ax24.set_xticks(months); ax24.set_xticklabels([f"{mm}ì›”" for mm in months])
        ax24.set_xlabel("ì›”"); ax24.set_ylabel("íŒë§¤ëŸ‰ (MJ)")
        ax24.set_title(f"ëƒ‰ë°©ìš© â€” Poly-4 (Train RÂ²={r2_line4:.3f})")
        ax24.legend(loc="best"); ax24.grid(alpha=0.25)
        ax24.text(0.02, 0.96, f"Poly-4: {poly_eq_text4(model_line4)}",
                  transform=ax24.transAxes, ha="left", va="top", fontsize=9,
                  bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(fig24)

        st.subheader(f"ê¸°ì˜¨-ëƒ‰ë°©ìš© ì‹¤ì  ìƒê´€ê´€ê³„ (Train, RÂ²={r2_fit4:.3f}) â€” Poly-4")
        fig34, ax34 = plt.subplots(figsize=(10,5.2))
        ax34.scatter(x_train, y_train, alpha=0.65, label="í•™ìŠµ ìƒ˜í”Œ")
        xx4 = np.linspace(np.nanmin(x_train)-1, np.nanmax(x_train)+1, 200)
        yhat4, _, model_s4, _ = fit_poly4_and_predict(x_train, y_train, xx4)
        ax34.plot(xx4, yhat4, lw=2.6, label="Poly-4")
        pred_train4, _, _, _ = fit_poly4_and_predict(x_train, y_train, x_train)
        resid4 = y_train - pred_train4; s4 = np.nanstd(resid4)
        ax34.fill_between(xx4, yhat4-1.96*s4, yhat4+1.96*s4, alpha=0.14, label="95% ì‹ ë¢°êµ¬ê°„")
        bins4 = np.linspace(np.nanmin(x_train), np.nanmax(x_train), 15)
        gb4 = pd.DataFrame({"bin": pd.cut(x_train, bins4), "y": y_train}).groupby("bin")["y"].median().reset_index()
        gb4["x"] = [b.mid for b in gb4["bin"]]
        ax34.scatter(gb4["x"], gb4["y"], s=65, label="ì˜¨ë„ë³„ ì¤‘ì•™ê°’")
        ax34.set_xlabel("ê¸°ê°„í‰ê· ê¸°ì˜¨ (â„ƒ)"); ax34.set_ylabel("íŒë§¤ëŸ‰ (MJ)")
        ax34.grid(alpha=0.25); ax34.legend(loc="best")
        xmin4, xmax4 = ax34.get_xlim(); ymin4, ymax4 = ax34.get_ylim()
        ax34.text(xmin4 + 0.02*(xmax-xmin), ymin4 + 0.06*(ymax-ymin),
                  f"Poly-4: {poly_eq_text4(model_s4)}",
                  fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(fig34)

# =============== C) ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡ â€” (ì—°ë„ë³„ ì´í•©) ê°œì„  ================
elif mode == "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡":
    title_with_icon("ğŸ“ˆ", "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡ (ì—°ë„ë³„ ì´í•© Â· Normal)", "h2")

    with st.sidebar:
        title_with_icon("ğŸ“¥", "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", "h3", small=True)
        src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0, key="trend_src")

        if src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
            data_dir = Path("data"); data_dir.mkdir(exist_ok=True)
            repo_files = sorted([str(p) for p in data_dir.glob("*.xlsx")])
            if repo_files:
                default_idx = next((i for i,p in enumerate(repo_files)
                                    if ("ìƒí’ˆë³„ê³µê¸‰ëŸ‰" in Path(p).stem) or ("ê³µê¸‰ëŸ‰" in Path(p).stem)), 0)
                file_choice = st.selectbox("ğŸ“„ ì‹¤ì  íŒŒì¼(Excel)", repo_files, index=default_idx,
                                           format_func=lambda p: Path(p).name, key="trend_file_ch")
                df = read_excel_sheet(file_choice, prefer_sheet="ë°ì´í„°")
            else:
                st.info("ğŸ“‚ data í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¡œ ì§„í–‰í•˜ì„¸ìš”.")
                df = None
        else:
            up = st.file_uploader("ğŸ“„ ì‹¤ì  ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” 'ë°ì´í„°' ì‹œíŠ¸", type=["xlsx"], key="trend_up")
            df = read_excel_sheet(up, prefer_sheet="ë°ì´í„°") if up is not None else None

        if df is None or df.empty:
            st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì‹¤ì  íŒŒì¼ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()

        title_with_icon("ğŸ“š", "í•™ìŠµ ë°ì´í„° ì—°ë„ ì„ íƒ", "h3", small=True)
        years_all = sorted([int(y) for y in pd.Series(df["ì—°"]).dropna().unique()])
        years_sel = st.multiselect("ğŸ—“ï¸ ì—°ë„ ì„ íƒ(í•™ìŠµ)", years_all, default=years_all, key="trend_years")

        title_with_icon("ğŸ§°", "ë¶„ì„í•  ìƒí’ˆ ì„ íƒ", "h3", small=True)
        product_cols = guess_product_cols(df)
        defaults = [c for c in ["ê°œë³„ë‚œë°©ìš©", "ì¤‘ì•™ë‚œë°©ìš©"] if c in product_cols]
        defaults = defaults or ([c for c in KNOWN_PRODUCT_ORDER if c in product_cols][:2] or product_cols[:2])
        prods = st.multiselect("ğŸ“¦ ìƒí’ˆ(ìš©ë„) ì„ íƒ", product_cols, default=defaults, key="trend_prods")

        title_with_icon("âš™ï¸", "ì˜ˆì¸¡ ì—°ë„", "h3", small=True)
        last_year = int(df["ì—°"].max())
        cand_years = list(range(2010, 2036))
        start_y = st.selectbox("ğŸš€ ì˜ˆì¸¡ ì‹œì‘(ì—°)", cand_years, index=cand_years.index(min(last_year+1,2035)), key="trend_sy")
        end_y   = st.selectbox("ğŸ ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", cand_years, index=cand_years.index(min(last_year+2,2035)), key="trend_ey")

        title_with_icon("ğŸ§ª", "ì ìš©í•  ë°©ë²•", "h3", small=True)
        method_opts = ["OLS(ì„ í˜•ì¶”ì„¸)", "CAGR(ë³µë¦¬ì„±ì¥)", "Holt(ì§€ìˆ˜í‰í™œ)", "ì§€ìˆ˜í‰í™œ(SES)", "ARIMA", "SARIMA(12)"]
        methods_selected = st.multiselect("ë°©ë²• ì„ íƒ(í‘œÂ·ê·¸ë˜í”„ í‘œì‹œ)", options=method_opts, default=method_opts, key="trend_methods")

    base = df.dropna(subset=["ì—°","ì›”"]).copy()
    base["ì—°"] = base["ì—°"].astype(int); base["ì›”"] = base["ì›”"].astype(int)
    years_pred = list(range(int(start_y), int(end_y)+1))
    yearly_all = base.groupby("ì—°").sum(numeric_only=True).reset_index()

    def _fore_ols(years, vals, target_years):
        x = np.array(years, float).reshape(-1,1)
        y = np.array(vals, float)
        mdl = LinearRegression().fit(x,y)
        return {ty: float(mdl.predict(np.array([[ty]], float))[0]) for ty in target_years}

    def _fore_cagr(years, vals, target_years):
        years = list(years); vals = list(vals)
        y0, yT = years[0], years[-1]
        v0, vT = float(vals[0]), float(vals[-1])
        n = max(1, (yT - y0))
        g = (vT / v0) ** (1.0/n) - 1.0 if v0>0 else 0.0
        basev = vT
        out = {}
        for i, ty in enumerate(target_years, start=1):
            out[ty] = basev * ((1.0 + g) ** i)
        return out

    def _fore_ses(vals, target_len, alpha=0.3):
        l = float(vals[0])
        for v in vals[1:]:
            l = alpha*float(v) + (1-alpha)*l
        return [l for _ in range(target_len)]

    def _fore_holt(vals, target_len, alpha=0.3, beta=0.1):
        l = float(vals[0]); b = float(vals[1]-vals[0]) if len(vals)>=2 else 0.0
        for v in vals[1:]:
            prev_l = l
            l = alpha*float(v) + (1-alpha)*(l + b)
            b = beta*(l - prev_l) + (1-beta)*b
        return [l + (h+1)*b for h in range(target_len)]

    def _monthly_series_for(prod: str) -> pd.Series:
        s = base[["ì—°","ì›”",prod]].dropna()
        s["ë‚ ì§œ"] = pd.to_datetime(s["ì—°"].astype(int).astype(str) + "-" + s["ì›”"].astype(int).astype(str) + "-01")
        s = s.sort_values("ë‚ ì§œ")
        s = s.set_index("ë‚ ì§œ")[prod].astype(float).asfreq("MS")
        return s

    def _fore_arima_yearsum(prod: str, target_years: list[int]) -> dict:
        if not _HAS_SM:
            return {y: np.nan for y in target_years}
        ts = _monthly_series_for(prod)
        train = ts[ts.index.year.isin(years_sel)]
        if train.dropna().empty:
            return {y: np.nan for y in target_years}
        candidates = [(1,1,0), (0,1,1), (1,1,1)]
        best_mdl, best_aic = None, np.inf
        for order in candidates:
            try:
                mdl = ARIMA(train, order=order).fit()
                if mdl.aic < best_aic:
                    best_aic, best_mdl = mdl.aic, mdl
            except Exception:
                continue
        if best_mdl is None:
            return {y: np.nan for y in target_years}
        steps = 12 * (max(target_years) - int(train.index[-1].year))
        if steps <= 0: steps = 12
        f = best_mdl.forecast(steps=steps)
        fut = f.copy()
        fut.index = pd.date_range(start=train.index[-1] + pd.offsets.MonthBegin(1), periods=len(fut), freq="MS")
        df_year = fut.groupby(fut.index.year).sum()
        return {y: float(df_year.get(y, np.nan)) for y in target_years}

    def _fore_sarima_yearsum(prod: str, target_years: list[int]) -> dict:
        if not _HAS_SM:
            return {y: np.nan for y in target_years}
        ts = _monthly_series_for(prod)
        train = ts[ts.index.year.isin(years_sel)]
        if train.dropna().empty:
            return {y: np.nan for y in target_years}
        try:
            mdl = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12),
                          enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)
        except Exception:
            return {y: np.nan for y in target_years}
        steps = 12 * (max(target_years) - int(train.index[-1].year))
        if steps <= 0: steps = 12
        f = mdl.forecast(steps=steps)
        fut = f.copy()
        fut.index = pd.date_range(start=train.index[-1] + pd.offsets.MonthBegin(1), periods=len(fut), freq="MS")
        df_year = fut.groupby(fut.index.year).sum()
        return {y: float(df_year.get(y, np.nan)) for y in target_years}

    # í™”ë©´: ìƒí’ˆë³„ ì¹´ë“œ
    for prod in prods:
        yearly = base.groupby("ì—°").sum(numeric_only=True).reset_index()[["ì—°", prod]].dropna().astype({"ì—°":int})
        train = yearly[yearly["ì—°"].isin(years_sel)].sort_values("ì—°")
        if train.empty:
            st.warning(f"'{prod}' í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); continue

        yrs = train["ì—°"].tolist()
        vals = train[prod].astype(float).tolist()

        pred_map = {}
        if "OLS(ì„ í˜•ì¶”ì„¸)" in methods_selected:
            pred_map["OLS(ì„ í˜•ì¶”ì„¸)"] = _fore_ols(yrs, vals, years_pred)
        if "CAGR(ë³µë¦¬ì„±ì¥)" in methods_selected:
            pred_map["CAGR(ë³µë¦¬ì„±ì¥)"] = _fore_cagr(yrs, vals, years_pred)
        if "ì§€ìˆ˜í‰í™œ(SES)" in methods_selected:
            pred_map["ì§€ìˆ˜í‰í™œ(SES)"] = dict(zip(years_pred, _fore_ses(vals, len(years_pred))))
        if "Holt(ì§€ìˆ˜í‰í™œ)" in methods_selected:
            pred_map["Holt(ì§€ìˆ˜í‰í™œ)"] = dict(zip(years_pred, _fore_holt(vals, len(years_pred))))
        if "ARIMA" in methods_selected:
            pred_map["ARIMA"] = _fore_arima_yearsum(prod, years_pred)
        if "SARIMA(12)" in methods_selected:
            pred_map["SARIMA(12)"] = _fore_sarima_yearsum(prod, years_pred)

        # ì˜ˆì¸¡í‘œ
        df_tbl = pd.DataFrame({"ì—°": years_pred})
        for k in methods_selected:
            if k in pred_map:
                df_tbl[k] = [int(max(0, round(pred_map[k].get(y, np.nan)))) if not np.isnan(pred_map[k].get(y, np.nan)) else "" for y in years_pred]
        st.markdown(f"### {prod} â€” ì—°ë„ë³„ ì´í•© ì˜ˆì¸¡í‘œ (Normal)")
        render_centered_table(df_tbl, int_cols=[c for c in df_tbl.columns if c!="ì—°"], index=False)

        # ê·¸ë˜í”„ â‘ : ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸) â€” 1ë²ˆ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼
        if go is None:
            fig, ax = plt.subplots(figsize=(10,4.2))
            yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
            ax.fill_between(yd["ì—°"], yd[prod], step="pre", alpha=0.15)
            ax.plot(yd["ì—°"], yd[prod], "-o", label="ì‹¤ì ")
            markers = {
                "CAGR(ë³µë¦¬ì„±ì¥)":"o", "Holt(ì§€ìˆ˜í‰í™œ)":"s", "OLS(ì„ í˜•ì¶”ì„¸)":"^",
                "ì§€ìˆ˜í‰í™œ(SES)":"+","ARIMA":"x","SARIMA(12)":"D"
            }
            for name in methods_selected:
                if name in pred_map:
                    xs = years_pred
                    ys = [pred_map[name].get(y, np.nan) for y in xs]
                    ax.scatter(xs, ys, label=name, marker=markers.get(name,"o"))
            ax.set_title("ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸)")
            ax.set_xlabel("ì—°ë„"); ax.set_ylabel("ì´í•©")
            ax.legend(loc="best"); ax.grid(alpha=0.25)
            st.pyplot(fig)
        else:
            fig = go.Figure()
            yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
            fig.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines", name="ì‹¤ì ", line=dict(width=3)))
            fig.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines", name="ì˜ì—­",
                                     fill="tozeroy", line=dict(width=0.1), showlegend=False, hoverinfo="skip"))
            sym = {"CAGR(ë³µë¦¬ì„±ì¥)":"circle","Holt(ì§€ìˆ˜í‰í™œ)":"square","OLS(ì„ í˜•ì¶”ì„¸)":"triangle-up",
                   "ì§€ìˆ˜í‰í™œ(SES)":"cross","ARIMA":"x","SARIMA(12)":"diamond"}
            for name in methods_selected:
                if name in pred_map:
                    xs = years_pred
                    ys = [pred_map[name].get(y, np.nan) for y in xs]
                    fig.add_trace(go.Scatter(
                        x=xs, y=ys, mode="markers+text", name=name,
                        marker_symbol=sym.get(name,"circle"),
                        text=[f"{int(v):,}" if v==v else "" for v in ys],
                        textposition="top center"
                    ))
            fig.update_layout(
                title="ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸)",
                xaxis_title="ì—°ë„", yaxis_title="ì´í•©",
                legend=dict(orientation="h", yanchor="bottom", y=-0.25, xanchor="left", x=0),
                hovermode="x unified"
            )
            st.plotly_chart(fig, use_container_width=True)

        # ê·¸ë˜í”„ â‘¡: ë°©ë²•ë³„ í‘œì‹œ í† ê¸€(ë™ì )
        if go is not None:
            with st.expander(f"ğŸ”€ {prod} ë°©ë²•ë³„ í‘œì‹œ í† ê¸€(ë™ì )"):
                toggles = {}
                cols = st.columns(min(6, len(methods_selected))) or [st]
                for i, name in enumerate(methods_selected):
                    with cols[i % len(cols)]:
                        toggles[name] = st.toggle(name, value=True, key=f"tg_{prod}_{name}")
                fig2 = go.Figure()
                yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
                fig2.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines+markers", name="ì‹¤ì "))
                for name in methods_selected:
                    if not toggles.get(name, True): 
                        continue
                    if name in pred_map:
                        xs = years_pred
                        ys = [pred_map[name].get(y, np.nan) for y in xs]
                        fig2.add_trace(go.Scatter(x=xs, y=ys, mode="markers+text", name=name,
                                                  text=[f"{int(v):,}" if v==v else "" for v in ys],
                                                  textposition="top center"))
                fig2.update_layout(title="ë°©ë²•ë³„ ë™ì  í‘œì‹œ", xaxis_title="ì—°ë„", yaxis_title="ì´í•©",
                                   legend=dict(orientation="h"))
                st.plotly_chart(fig2, use_container_width=True)

    with st.expander("ì˜ˆì¸¡ ë°©ë²• ì„¤ëª… (ì‰¬ìš´ ì„¤ëª… + ì‚°ì‹)"):
        st.markdown(r"""
- **ì„ í˜•ì¶”ì„¸(OLS)** â€” í•´ë§ˆë‹¤ ëŠ˜ì–´ë‚˜ëŠ” í­ì„ ì§ì„ ìœ¼ë¡œ ì¡ì•„ ì•ìœ¼ë¡œ ê·¸ë¦°ë‹¤.  
  ì‚°ì‹: \( y_t = a + b t,\ \ \hat y_{t+h} = a + b (t+h) \)

- **CAGR(ë³µë¦¬ì„±ì¥)** â€” ì‹œì‘~ë ì‚¬ì´ì˜ í‰ê·  ë³µë¦¬ ì„±ì¥ë¥ ë§Œí¼ ë§¤ë…„ ê°™ì€ ë¹„ìœ¨ë¡œ ëŠ˜ì–´ë‚œë‹¤ê³  ê°€ì •.  
  ì‚°ì‹: \( g = (y_T / y_0)^{1/n} - 1,\ \ \hat y_{t+h} = y_T (1+g)^h \)

- **Holt(ì§€ìˆ˜í‰í™œ-ì¶”ì„¸í˜•)** â€” ìˆ˜ì¤€ê³¼ ì¶”ì„¸ë¥¼ ì§€ìˆ˜ ê°€ì¤‘ìœ¼ë¡œ ê°±ì‹ (ê³„ì ˆ ì œì™¸).  
  ì‚°ì‹(ìš”ì•½): \( l_t = \alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}),\ \ b_t=\beta(l_t-l_{t-1})+(1-\beta)b_{t-1},\ \ \hat y_{t+h}=l_T + h b_T \)

- **ì§€ìˆ˜í‰í™œ(SES)** â€” ìµœê·¼ ê´€ì¸¡ì¹˜ì— ë” í° ê°€ì¤‘ì„ ë‘” í‰ê· í™”(ì¶”ì„¸Â·ê³„ì ˆ ì œì™¸).  
  ì‚°ì‹: \( l_t = \alpha y_t + (1-\alpha) l_{t-1},\ \ \hat y_{t+h}=l_T \)

- **ARIMA(p,d,q)** â€” ì°¨ë¶„(d)ìœ¼ë¡œ ì •ìƒí™”í•œ ë’¤ AR(p), MA(q) ê²°í•©ìœ¼ë¡œ ì˜ˆì¸¡(ì›”ë³„ ì‹œê³„ì—´ í•™ìŠµ â†’ ì—°ë„í•© ì§‘ê³„).  
  ì—¬ê¸°ì„  ê°„ê²°í•œ í›„ë³´ \((1,1,0),(0,1,1),(1,1,1)\) ì¤‘ AIC ìµœì†Œ ëª¨ë¸ì„ ìë™ ì„ íƒ.

- **SARIMA(P,D,Q,12)** â€” ì›”ë³„ ê³„ì ˆì£¼ê¸° 12ë¥¼ ë‘ëŠ” í™•ì¥.  
  ê¸°ë³¸ ì„¤ì •: \((1,1,1)\times(1,1,1)_{12}\).
""")
