# app.py â€” ë„ì‹œê°€ìŠ¤ ê³µê¸‰Â·íŒë§¤ ì˜ˆì¸¡ (3ì„¹ì…˜ ë¶„ë¦¬ + ì¶”ì²œ í•™ìŠµ ë°ì´í„° ê¸°ê°„ íŒ¨ë„)
# A) ê³µê¸‰ëŸ‰ ì˜ˆì¸¡        : Poly-3 ê¸°ë°˜ + Normal/Best/Conservative + ê¸°ì˜¨ì¶”ì„¸ë¶„ì„
# B) íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©) : ì „ì›”16~ë‹¹ì›”15 í‰ê· ê¸°ì˜¨ + Poly-3/4 ë¹„êµ
# C) ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„     : ì—°ë„ë³„ ì´í•© OLS/CAGR/Holt/SES + ARIMA/SARIMA(12)
# ì¶”ì²œ í•™ìŠµ ë°ì´í„° ê¸°ê°„ : ì˜ˆì¸¡ìœ í˜• ë¼ë””ì˜¤ ìœ„ íŒ¨ë„ (RÂ² ìƒìœ„ 2ê°œ êµ¬ê°„, ì†Œìˆ˜ 4ìë¦¬, ë°°ê²½ í•˜ì´ë¼ì´íŠ¸)

import os
from io import BytesIO
from pathlib import Path
import warnings
from glob import glob

import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import streamlit as st

# Plotly (ìˆìœ¼ë©´ ì‚¬ìš©)
try:
    import plotly.graph_objects as go
except Exception:
    go = None

# statsmodels (ARIMA/SARIMA)
_HAS_SM = True
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.statespace.sarimax import SARIMAX
except Exception:
    _HAS_SM = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ ì´ˆê¸°ì„¤ì •/ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë„ì‹œê°€ìŠ¤ ê³µê¸‰Â·íŒë§¤ëŸ‰ ì˜ˆì¸¡", layout="wide")
os.environ.setdefault("MPLCONFIGDIR", "/tmp/matplotlib")
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")

st.markdown("""
<style>
.icon-title{display:flex;align-items:center;gap:.55rem;margin:.2rem 0 .6rem 0}
.icon-title .emoji{font-size:1.55rem;line-height:1}
.small-icon .emoji{font-size:1.2rem}
table.centered-table {width:100%; table-layout: fixed;}
table.centered-table th, table.centered-table td { text-align:center !important; }
</style>
""", unsafe_allow_html=True)

def title_with_icon(icon: str, text: str, level: str = "h1", small=False):
    klass = "icon-title small-icon" if small else "icon-title"
    st.markdown(
        f"<{level} class='{klass}'><span class='emoji'>{icon}</span><span>{text}</span></{level}>",
        unsafe_allow_html=True,
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•œê¸€ í°íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def set_korean_font():
    here = Path(__file__).parent if "__file__" in globals() else Path.cwd()
    candidates = [
        here / "data" / "fonts" / "NanumGothic-Regular.ttf",
        here / "data" / "fonts" / "NanumGothic.ttf",
        here / "fonts" / "NanumGothic-Regular.ttf",
        Path("/usr/share/fonts/truetype/nanum/NanumGothic.ttf"),
        Path("/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"),
        Path("C:/Windows/Fonts/malgun.ttf"),
        Path("/Library/Fonts/AppleSDGothicNeo.ttc"),
    ]
    for p in candidates:
        try:
            if p.exists():
                mpl.font_manager.fontManager.addfont(str(p))
                fam = mpl.font_manager.FontProperties(fname=str(p)).get_name()
                plt.rcParams["font.family"] = [fam]
                plt.rcParams["font.sans-serif"] = [fam]
                plt.rcParams["axes.unicode_minus"] = False
                return
        except Exception:
            pass
    plt.rcParams["font.family"] = ["DejaVu Sans"]
    plt.rcParams["axes.unicode_minus"] = False

set_korean_font()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ ìƒìˆ˜/ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
META_COLS = {"ë‚ ì§œ", "ì¼ì", "date", "ì—°", "ë…„", "ì›”"}
TEMP_HINTS = ["í‰ê· ê¸°ì˜¨", "ê¸°ì˜¨", "temperature", "temp"]
KNOWN_PRODUCT_ORDER = [
    "ê°œë³„ë‚œë°©ìš©", "ì¤‘ì•™ë‚œë°©ìš©",
    "ìê°€ì—´ì „ìš©", "ì¼ë°˜ìš©(2)", "ì—…ë¬´ë‚œë°©ìš©", "ëƒ‰ë‚œë°©ìš©",
    "ì£¼í•œë¯¸êµ°", "ì·¨ì‚¬ìš©", "ì´ê³µê¸‰ëŸ‰",
]

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    if "ë‚ ì§œ" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"], errors="coerce")
    elif "ì¼ì" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
    elif "date" in df.columns:
        df["ë‚ ì§œ"] = pd.to_datetime(df["date"], errors="coerce")
    else:
        if ("ì—°" in df.columns or "ë…„" in df.columns) and "ì›”" in df.columns:
            y = df["ì—°"] if "ì—°" in df.columns else df["ë…„"]
            df["ë‚ ì§œ"] = pd.to_datetime(y.astype(str) + "-" + df["ì›”"].astype(str) + "-01", errors="coerce")
    if "ì—°" not in df.columns:
        if "ë…„" in df.columns:
            df["ì—°"] = df["ë…„"]
        elif "ë‚ ì§œ" in df.columns:
            df["ì—°"] = df["ë‚ ì§œ"].dt.year
    if "ì›”" not in df.columns and "ë‚ ì§œ" in df.columns:
        df["ì›”"] = df["ë‚ ì§œ"].dt.month
    for c in df.columns:
        if df[c].dtype == "object":
            df[c] = pd.to_numeric(
                df[c].astype(str).str.replace(",", "", regex=False).str.replace(" ", "", regex=False),
                errors="ignore",
            )
    return df

def detect_temp_col(df: pd.DataFrame) -> str | None:
    for c in df.columns:
        nm = str(c).lower()
        if any(h in nm for h in [h.lower() for h in TEMP_HINTS]) and pd.api.types.is_numeric_dtype(df[c]):
            return c
    for c in df.columns:
        if "ì˜¨" in str(c) and pd.api.types.is_numeric_dtype(df[c]):
            return c
    return None

def guess_product_cols(df: pd.DataFrame) -> list[str]:
    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    candidates = [c for c in numeric_cols if c not in META_COLS]
    ordered = [c for c in KNOWN_PRODUCT_ORDER if c in candidates]
    others = [c for c in candidates if c not in ordered]
    return ordered + others

@st.cache_data(ttl=600)
def read_excel_sheet(path_or_file, prefer_sheet="ë°ì´í„°"):
    try:
        xls = pd.ExcelFile(path_or_file, engine="openpyxl")
        sheet = prefer_sheet if prefer_sheet in xls.sheet_names else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        df = pd.read_excel(path_or_file, engine="openpyxl")
    return normalize_cols(df)

@st.cache_data(ttl=600)
def read_temperature_raw(file):
    def _finalize(df):
        df.columns = [str(c).strip() for c in df.columns]
        date_col = None
        for c in df.columns:
            if str(c).lower() in ["ë‚ ì§œ", "ì¼ì", "date"]:
                date_col = c
                break
        if date_col is None:
            for c in df.columns:
                try:
                    pd.to_datetime(df[c], errors="raise")
                    date_col = c
                    break
                except Exception:
                    pass
        temp_col = None
        for c in df.columns:
            if ("í‰ê· ê¸°ì˜¨" in str(c)) or ("ê¸°ì˜¨" in str(c)) or (str(c).lower() in ["temp", "temperature"]):
                temp_col = c
                break
        if date_col is None or temp_col is None:
            return None
        out = pd.DataFrame(
            {"ì¼ì": pd.to_datetime(df[date_col], errors="coerce"), "ê¸°ì˜¨": pd.to_numeric(df[temp_col], errors="coerce")}
        ).dropna()
        return out.sort_values("ì¼ì").reset_index(drop=True)

    name = getattr(file, "name", str(file))
    if name and name.lower().endswith(".csv"):
        return _finalize(pd.read_csv(file))
    xls = pd.ExcelFile(file, engine="openpyxl")
    sheet = xls.sheet_names[0]
    head = pd.read_excel(xls, sheet_name=sheet, header=None, nrows=50)
    header_row = None
    for i in range(len(head)):
        row = [str(v) for v in head.iloc[i].tolist()]
        if any(v in ["ë‚ ì§œ", "ì¼ì", "date", "Date"] for v in row) and any(
            ("í‰ê· ê¸°ì˜¨" in v) or ("ê¸°ì˜¨" in v) or (isinstance(v, str) and v.lower() in ["temp", "temperature"])
            for v in row
        ):
            header_row = i
            break
    df = (
        pd.read_excel(xls, sheet_name=sheet)
        if header_row is None
        else pd.read_excel(xls, sheet_name=sheet, header=header_row)
    )
    return _finalize(df)

@st.cache_data(ttl=600)
def read_temperature_forecast(file):
    """ì›” ë‹¨ìœ„ (ë‚ ì§œ, í‰ê· ê¸°ì˜¨[, ì¶”ì„¸ë¶„ì„]) â†’ (ì—°, ì›”, ì˜ˆìƒê¸°ì˜¨, ì¶”ì„¸ê¸°ì˜¨)"""
    try:
        xls = pd.ExcelFile(file, engine="openpyxl")
        sheet = "ê¸°ì˜¨ì˜ˆì¸¡" if "ê¸°ì˜¨ì˜ˆì¸¡" in xls.sheet_names else xls.sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        df = pd.read_excel(file, engine="openpyxl")
    df.columns = [str(c).strip() for c in df.columns]
    date_col = next((c for c in df.columns if c in ["ë‚ ì§œ", "ì¼ì", "date", "Date"]), df.columns[0])
    base_temp_col = next(
        (c for c in df.columns if ("í‰ê· ê¸°ì˜¨" in c) or (str(c).lower() in ["temp", "temperature", "ê¸°ì˜¨"])), None
    )
    trend_cols = [c for c in df.columns if any(k in str(c) for k in ["ì¶”ì„¸ë¶„ì„", "ì¶”ì„¸ê¸°ì˜¨"])]
    trend_col = trend_cols[0] if trend_cols else None
    if base_temp_col is None:
        raise ValueError("ê¸°ì˜¨ì˜ˆì¸¡ íŒŒì¼ì—ì„œ 'í‰ê· ê¸°ì˜¨' ë˜ëŠ” 'ê¸°ì˜¨' ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    d = pd.DataFrame(
        {"ë‚ ì§œ": pd.to_datetime(df[date_col], errors="coerce"), "ì˜ˆìƒê¸°ì˜¨": pd.to_numeric(df[base_temp_col], errors="coerce")}
    ).dropna(subset=["ë‚ ì§œ"])
    d["ì—°"] = d["ë‚ ì§œ"].dt.year.astype(int)
    d["ì›”"] = d["ë‚ ì§œ"].dt.month.astype(int)
    d["ì¶”ì„¸ê¸°ì˜¨"] = pd.to_numeric(df[trend_col], errors="coerce") if trend_col else np.nan
    return d[["ì—°", "ì›”", "ì˜ˆìƒê¸°ì˜¨", "ì¶”ì„¸ê¸°ì˜¨"]]

def month_start(x):
    x = pd.to_datetime(x)
    return pd.Timestamp(x.year, x.month, 1)

def month_range_inclusive(s, e):
    return pd.date_range(start=month_start(s), end=month_start(e), freq="MS")

# Poly-3/4 ê³µí†µ
def fit_poly3_and_predict(x_train, y_train, x_future):
    m = (~np.isnan(x_train)) & (~np.isnan(y_train))
    x_train, y_train = x_train[m], y_train[m]
    if np.isnan(x_future).any():
        raise ValueError("ì˜ˆì¸¡ ì…ë ¥ì— ê²°ì¸¡ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    x_train = x_train.reshape(-1, 1)
    x_future = x_future.reshape(-1, 1)
    poly = PolynomialFeatures(degree=3, include_bias=False)
    Xtr = poly.fit_transform(x_train)
    model = LinearRegression().fit(Xtr, y_train)
    r2 = model.score(Xtr, y_train)
    y_future = model.predict(poly.transform(x_future))
    return y_future, r2, model, poly

def fit_poly4_and_predict(x_train, y_train, x_future):
    m = (~np.isnan(x_train)) & (~np.isnan(y_train))
    x_train, y_train = x_train[m], y_train[m]
    if np.isnan(x_future).any():
        raise ValueError("ì˜ˆì¸¡ ì…ë ¥ì— ê²°ì¸¡ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    x_train = x_train.reshape(-1, 1)
    x_future = x_future.reshape(-1, 1)
    poly = PolynomialFeatures(degree=4, include_bias=False)
    Xtr = poly.fit_transform(x_train)
    model = LinearRegression().fit(Xtr, y_train)
    r2 = model.score(Xtr, y_train)
    y_future = model.predict(poly.transform(x_future))
    return y_future, r2, model, poly

# â–¼ Poly-3 ë°©ì •ì‹ í‘œê¸°(ì†Œìˆ˜ 4ìë¦¬, ì§€ìˆ˜í‘œê¸° ê¸ˆì§€)
def poly_eq_text(model, decimals: int = 4):
    c = model.coef_
    c1 = c[0] if len(c) > 0 else 0.0
    c2 = c[1] if len(c) > 1 else 0.0
    c3 = c[2] if len(c) > 2 else 0.0
    d = model.intercept_
    fmt = lambda v: f"{v:+,.{decimals}f}"
    return f"y = {fmt(c3)}xÂ³ {fmt(c2)}xÂ² {fmt(c1)}x {fmt(d)}"

def poly_eq_text4(model):
    c = model.coef_
    c1 = c[0] if len(c) > 0 else 0.0
    c2 = c[1] if len(c) > 1 else 0.0
    c3 = c[2] if len(c) > 2 else 0.0
    c4 = c[3] if len(c) > 3 else 0.0
    d = model.intercept_
    return f"y = {c4:+.5e}xâ´ {c3:+.5e}xÂ³ {c2:+.5e}xÂ² {c1:+.5e}x {d:+.5e}"

def render_centered_table(df: pd.DataFrame, float1_cols=None, int_cols=None, index=False):
    float1_cols = float1_cols or []
    int_cols = int_cols or []
    show = df.copy()
    for c in float1_cols:
        if c in show.columns:
            show[c] = pd.to_numeric(show[c], errors="coerce").round(4).map(lambda x: "" if pd.isna(x) else f"{x:.4f}")
    for c in int_cols:
        if c in show.columns:
            show[c] = (
                pd.to_numeric(show[c], errors="coerce")
                .round()
                .astype("Int64")
                .map(lambda x: "" if pd.isna(x) else f"{int(x):,}")
            )
    st.markdown(show.to_html(index=index, classes="centered-table"), unsafe_allow_html=True)

# ===========================================================
# ğŸ” ì¶”ì²œ í•™ìŠµ ë°ì´í„° ê¸°ê°„ (ì˜ˆì¸¡ìœ í˜• ë¼ë””ì˜¤ ìœ„ íŒ¨ë„ + ë³¸ë¬¸ ì„¹ì…˜)
# ===========================================================
def _load_repo_supply_file():
    """ë ˆí¬ data í´ë”ì—ì„œ ê¸°ë³¸ ê³µê¸‰ëŸ‰ íŒŒì¼ì„ ì°¾ì•„ ë¡œë“œ."""
    data_dir = Path("data"); data_dir.mkdir(exist_ok=True)
    repo_files = sorted([str(p) for p in data_dir.glob("*.xlsx")])
    if not repo_files:
        return None, None
    default_idx = next((i for i, p in enumerate(repo_files)
                        if ("ìƒí’ˆë³„ê³µê¸‰ëŸ‰" in Path(p).stem) or ("ê³µê¸‰ëŸ‰" in Path(p).stem)), 0)
    file_choice = st.selectbox("ğŸ“„ ì‹¤ì  íŒŒì¼(Excel)", repo_files, index=default_idx,
                               format_func=lambda p: Path(p).name, key="rec_repo_file")
    df = read_excel_sheet(file_choice, prefer_sheet="ë°ì´í„°")
    return df, Path(file_choice).name

def compute_r2_by_start_year(df: pd.DataFrame, product: str):
    """ì¢…ë£Œì—°ë„=ìµœì‹ ì—°ë„ë¡œ ê³ ì •, ì‹œì‘ì—°ë„ 1ë…„ì”© ì´ë™í•˜ë©° RÂ² ê³„ì‚°."""
    df = df.dropna(subset=["ì—°", "ì›”"]).copy()
    df["ì—°"] = df["ì—°"].astype(int)
    temp_col = detect_temp_col(df)
    if temp_col is None:
        raise ValueError("ê¸°ì˜¨ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì—´ ì´ë¦„ì— 'í‰ê· ê¸°ì˜¨' ë˜ëŠ” 'ê¸°ì˜¨' í¬í•¨ í•„ìš”.")
    first_year = int(df["ì—°"].min())
    last_year  = int(df["ì—°"].max())

    rows = []
    for start in range(first_year, last_year + 1):
        part = df[(df["ì—°"] >= start) & (df["ì—°"] <= last_year)].copy()
        x = part[temp_col].astype(float).values
        y = part[product].astype(float).values
        if len(part) < 6 or np.allclose(y, y.mean()):
            r2 = np.nan
        else:
            _, r2, _, _ = fit_poly3_and_predict(x, y, x)
        rows.append({"ì‹œì‘ì—°ë„": start, "ì¢…ë£Œì—°ë„": last_year, "ê¸°ê°„": f"{start}~í˜„ì¬", "R2": r2})
    rec_df = pd.DataFrame(rows).dropna(subset=["R2"])
    if rec_df.empty:
        return None
    rec_df = rec_df.sort_values(["ì‹œì‘ì—°ë„"]).reset_index(drop=True)

    # Top2 ì¶”ì¶œ (ë™ì  ì‹œ ìµœê·¼ ì‹œì‘ì—°ë„ ìš°ì„ )
    top2 = rec_df.sort_values(["R2", "ì‹œì‘ì—°ë„"], ascending=[False, False]).head(2).reset_index(drop=True)
    top2.insert(0, "ì¶”ì²œìˆœìœ„", [1, 2])
    return dict(rec_df=rec_df, top=top2, end=last_year)

def sidebar_recommendation_panel():
    """ì¢Œì¸¡ ìµœìƒë‹¨ íŒ¨ë„ UI (ì˜ˆì¸¡ìœ í˜• ë¼ë””ì˜¤ ìœ„)"""
    with st.sidebar:
        with st.expander("ğŸ¯ ì¶”ì²œ í•™ìŠµ ë°ì´í„° ê¸°ê°„", expanded=True):
            # íŒŒì¼ ì†ŒìŠ¤ ì„ íƒ: ë ˆí¬/ì—…ë¡œë“œ
            src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0, horizontal=True, key="rec_src")

            df, src_name = None, None
            if src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
                df, src_name = _load_repo_supply_file()
                if df is None:
                    st.info("ğŸ“‚ data í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ë‹¤ë¥¸ íƒ­ì—ì„œ ì—…ë¡œë“œí•˜ê³  ë‹¤ì‹œ ì—´ì–´ë³´ì„¸ìš”.")
            else:
                up = st.file_uploader("ğŸ“„ ì‹¤ì  ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” 'ë°ì´í„°' ì‹œíŠ¸", type=["xlsx"], key="rec_up")
                if up is not None:
                    df = read_excel_sheet(up, prefer_sheet="ë°ì´í„°")
                    src_name = getattr(up, "name", "uploaded.xlsx")

            if df is not None and not df.empty:
                product_cols = guess_product_cols(df)
                default_products = [c for c in KNOWN_PRODUCT_ORDER if c in product_cols] or product_cols[:1]
                tgt = st.selectbox("ëŒ€ìƒ ìƒí’ˆ(1ê°œ)", options=product_cols,
                                   index=product_cols.index(default_products[0]) if default_products else 0,
                                   key="rec_target_prod")

                end_year = int(pd.to_numeric(df["ì—°"], errors="coerce").max())
                st.caption(f"ê¸°ì¤€ ì¢…ë£Œì—°ë„: **{end_year}** (ë°ì´í„° ìµœì‹ ì—°ë„)")

                if st.button("ğŸ” ì¶”ì²œ êµ¬ê°„ ê³„ì‚°", key="btn_calc_rec"):
                    rr = compute_r2_by_start_year(df, tgt)
                    if rr is None:
                        st.warning("ê³„ì‚° ê°€ëŠ¥í•œ êµ¬ê°„ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.session_state["rec_result"] = dict(
                            rr=rr, product=tgt, src_name=src_name
                        )
                        st.success("ì¶”ì²œ í•™ìŠµ êµ¬ê°„ ê³„ì‚° ì™„ë£Œ! ì•„ë˜ ë³¸ë¬¸ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            else:
                st.caption("ì‹¤ì  íŒŒì¼ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ë©´ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def body_recommendation_section():
    """ë³¸ë¬¸ ìƒë‹¨ ê²°ê³¼ ì„¹ì…˜ (ê³„ì‚° í›„ ë Œë”ë§)"""
    if "rec_result" not in st.session_state:
        return
    product = st.session_state["rec_result"]["product"]
    rr = st.session_state["rec_result"]["rr"]
    rec_df = rr["rec_df"].copy()
    topk = rr["top"].copy()

    title_with_icon("ğŸ§ ", f"ì¶”ì²œ í•™ìŠµ ë°ì´í„° ê¸°ê°„ â€” {product}", "h2")

    # í‘œ (RÂ² 4ìë¦¬)
    show = topk[["ì¶”ì²œìˆœìœ„", "ê¸°ê°„", "ì‹œì‘ì—°ë„", "ì¢…ë£Œì—°ë„", "R2"]].copy()
    render_centered_table(show, float1_cols=["R2"], index=False)

    # ê·¸ë˜í”„: ì¹´í…Œê³ ë¦¬ ì¶•ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë°”ê¿” ì„¸ë¡œ ë°´ë“œ shape ì‚¬ìš©
    cat_labels = rec_df.sort_values("ì‹œì‘ì—°ë„")["ê¸°ê°„"].tolist()
    r2_vals    = rec_df.sort_values("ì‹œì‘ì—°ë„")["R2"].round(6).tolist()
    xpos = list(range(len(cat_labels)))
    top_periods = topk["ê¸°ê°„"].tolist()
    top_idx = [cat_labels.index(p) for p in top_periods]

    y_min = max(0.0, float(np.nanmin(r2_vals)) - 0.01)
    y_max = min(1.0, float(np.nanmax(r2_vals)) + 0.01)

    if go is not None:
        fig = go.Figure()

        # ì„¸ë¡œ ë°°ê²½ ë°´ë“œ í•˜ì´ë¼ì´íŠ¸ (Top1 ì§„í•˜ê²Œ, Top2 ì—°í•˜ê²Œ)
        for i, idx in enumerate(top_idx):
            band_color = "rgba(46,204,113,0.22)" if i == 0 else "rgba(52,152,219,0.16)"
            fig.add_shape(
                type="rect", xref="x", yref="paper",
                x0=idx - 0.48, x1=idx + 0.48, y0=0.0, y1=1.0,
                line=dict(width=0), fillcolor=band_color, layer="below"
            )
            fig.add_annotation(
                x=idx, y=1.0, xref="x", yref="paper",
                text=f"ì¶”ì²œ {i+1}", showarrow=False, yshift=18,
                font=dict(size=11, color="#666")
            )

        fig.add_trace(go.Scatter(
            x=xpos, y=r2_vals,
            mode="lines+markers",
            line=dict(width=3),
            marker=dict(size=7),
            name="RÂ² (train fit)",
            hovertemplate="%{text}<br>RÂ²=%{y:.4f}<extra></extra>",
            text=cat_labels
        ))
        fig.update_layout(
            title=f"í•™ìŠµ ì‹œì‘ì—°ë„ë³„ RÂ² (ì¢…ë£Œì—°ë„={rr['end']})",
            xaxis=dict(title="í•™ìŠµ ê¸°ê°„(ì‹œì‘ì—°ë„~í˜„ì¬)", tickmode="array", tickvals=xpos, ticktext=cat_labels, tickangle=-25),
            yaxis=dict(title="RÂ² (train fit)", range=[y_min, y_max]),
            margin=dict(t=60, b=80, l=60, r=30),
            hovermode="x unified",
            legend=dict(orientation="h", yanchor="bottom", y=-0.18, xanchor="left", x=0),
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        xs = np.arange(len(cat_labels))
        fig, ax = plt.subplots(figsize=(10.8, 4.0))
        for i, idx in enumerate(top_idx):
            color = (46/255, 204/255, 113/255, 0.22) if i == 0 else (52/255, 152/255, 219/255, 0.16)
            ax.axvspan(idx-0.48, idx+0.48, color=color, zorder=0)
            ax.text(idx, 1.02, f"ì¶”ì²œ {i+1}", transform=ax.get_xaxis_transform(),
                    ha="center", va="bottom", fontsize=10, color="#666")
        ax.plot(xs, r2_vals, "-o", lw=2.8, ms=6, zorder=2)
        ax.set_title(f"í•™ìŠµ ì‹œì‘ì—°ë„ë³„ RÂ² (ì¢…ë£Œì—°ë„={rr['end']})")
        ax.set_ylabel("RÂ² (train fit)")
        ax.set_xticks(xs); ax.set_xticklabels(cat_labels, rotation=25, ha="right")
        ax.set_ylim(y_min, y_max); ax.grid(alpha=0.25)
        st.pyplot(fig, clear_figure=True)

# ===========================================================
# A) ê³µê¸‰ëŸ‰ ì˜ˆì¸¡
# ===========================================================
def render_supply_forecast():
    with st.sidebar:
        title_with_icon("ğŸ“¥", "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", "h3", small=True)
        src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0, key="sup_src")
        df, forecast_df = None, None

        if src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
            data_dir = Path("data"); data_dir.mkdir(exist_ok=True)
            repo_files = sorted([str(p) for p in data_dir.glob("*.xlsx")])
            if repo_files:
                default_idx = next((i for i, p in enumerate(repo_files)
                                    if ("ìƒí’ˆë³„ê³µê¸‰ëŸ‰" in Path(p).stem) or ("ê³µê¸‰ëŸ‰" in Path(p).stem)), 0)
                file_choice = st.selectbox("ğŸ“„ ì‹¤ì  íŒŒì¼(Excel)", repo_files, index=default_idx,
                                           format_func=lambda p: Path(p).name, key="sup_repo_file")
                df = read_excel_sheet(file_choice, prefer_sheet="ë°ì´í„°")
            else:
                st.info("ğŸ“‚ data í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¡œ ì§„í–‰í•˜ì„¸ìš”.")

            fc_candidates = [data_dir / "ê¸°ì˜¨ì˜ˆì¸¡.xlsx", *[Path(p) for p in glob(str(data_dir / "*ê¸°ì˜¨ì˜ˆì¸¡*.xlsx"))]]
            if any(p.exists() for p in fc_candidates):
                fc_path = next(p for p in fc_candidates if p.exists())
                st.success(f"ğŸŒ¡ï¸ ì˜ˆìƒê¸°ì˜¨ íŒŒì¼ ì‚¬ìš©: {fc_path.name}")
                forecast_df = read_temperature_forecast(fc_path)
            else:
                up_fc = st.file_uploader("ğŸŒ¡ï¸ ì˜ˆìƒê¸°ì˜¨ ì—…ë¡œë“œ(xlsx) â€” (ë‚ ì§œ, í‰ê· ê¸°ì˜¨[, ì¶”ì„¸ë¶„ì„])", type=["xlsx"], key="up_fc_repo")
                if up_fc is not None:
                    forecast_df = read_temperature_forecast(up_fc)
        else:
            up = st.file_uploader("ğŸ“„ ì‹¤ì  ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” 'ë°ì´í„°' ì‹œíŠ¸", type=["xlsx"], key="sup_up")
            if up is not None:
                df = read_excel_sheet(up, prefer_sheet="ë°ì´í„°")
            up_fc = st.file_uploader("ğŸŒ¡ï¸ ì˜ˆìƒê¸°ì˜¨ ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” (ë‚ ì§œ, í‰ê· ê¸°ì˜¨[, ì¶”ì„¸ë¶„ì„])", type=["xlsx"], key="sup_up_fc")
            if up_fc is not None:
                forecast_df = read_temperature_forecast(up_fc)

        if df is None or len(df) == 0:
            st.info("ğŸ§© ì¢Œì¸¡ì—ì„œ ì‹¤ì  ì—‘ì…€ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()
        if forecast_df is None or forecast_df.empty:
            st.info("ğŸŒ¡ï¸ ì¢Œì¸¡ì—ì„œ ì˜ˆìƒê¸°ì˜¨ ì—‘ì…€ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()

        title_with_icon("ğŸ“š", "í•™ìŠµ ë°ì´í„° ì—°ë„ ì„ íƒ", "h3", small=True)
        years_all = sorted([int(y) for y in pd.Series(df["ì—°"]).dropna().unique()])
        years_sel = st.multiselect("ğŸ—“ï¸ ì—°ë„ ì„ íƒ", years_all, default=years_all, key="sup_years_sel")

        temp_col = detect_temp_col(df)
        if temp_col is None:
            st.error("ğŸŒ¡ï¸ ê¸°ì˜¨ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì—´ ì´ë¦„ì— 'í‰ê· ê¸°ì˜¨' ë˜ëŠ” 'ê¸°ì˜¨' í¬í•¨ í•„ìš”."); st.stop()

        title_with_icon("ğŸ§°", "ì˜ˆì¸¡í•  ìƒí’ˆ ì„ íƒ", "h3", small=True)
        product_cols = guess_product_cols(df)
        default_products = [c for c in KNOWN_PRODUCT_ORDER if c in product_cols] or product_cols[:6]
        prods = st.multiselect("ğŸ“¦ ìƒí’ˆ(ìš©ë„) ì„ íƒ", product_cols, default=default_products, key="sup_prods")

        title_with_icon("âš™ï¸", "ì˜ˆì¸¡ ì„¤ì •", "h3", small=True)
        last_year = int(df["ì—°"].max())
        years = list(range(2010, 2036))
        col_sy, col_sm = st.columns(2)
        with col_sy:
            start_y = st.selectbox("ğŸš€ ì˜ˆì¸¡ ì‹œì‘(ì—°)", years, index=years.index(last_year), key="sup_sy")
        with col_sm:
            start_m = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì‹œì‘(ì›”)", list(range(1, 13)), index=0, key="sup_sm")
        col_ey, col_em = st.columns(2)
        with col_ey:
            end_y = st.selectbox("ğŸ ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", years, index=years.index(last_year), key="sup_ey")
        with col_em:
            end_m = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì¢…ë£Œ(ì›”)", list(range(1, 13)), index=11, key="sup_em")

        run_btn = st.button("ğŸ§® ì˜ˆì¸¡ ì‹œì‘", type="primary", key="sup_run")

    if run_btn:
        base = df.dropna(subset=["ë‚ ì§œ"]).sort_values("ë‚ ì§œ").reset_index(drop=True)
        train_df = base[base["ì—°"].isin(years_sel)].copy()
        f_start = pd.Timestamp(year=int(start_y), month=int(start_m), day=1)
        f_end   = pd.Timestamp(year=int(end_y),   month=int(end_m),   day=1)
        if f_end < f_start:
            st.error("â›” ì˜ˆì¸¡ ì¢…ë£Œê°€ ì‹œì‘ë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤."); st.stop()
        fut_idx = month_range_inclusive(f_start, f_end)
        fut_base = pd.DataFrame({"ì—°": fut_idx.year.astype(int), "ì›”": fut_idx.month.astype(int)})

        # âœ”ï¸ ë‹¨ìˆœ ë³‘í•©
        fut_base = fut_base.merge(forecast_df, on=["ì—°", "ì›”"], how="left")

        monthly_avg_temp = train_df.groupby("ì›”")[temp_col].mean().rename("ì›”í‰ê· ").reset_index()
        miss1 = fut_base["ì˜ˆìƒê¸°ì˜¨"].isna()
        if miss1.any():
            fut_base = fut_base.merge(monthly_avg_temp, on="ì›”", how="left")
            fut_base.loc[miss1, "ì˜ˆìƒê¸°ì˜¨"] = fut_base.loc[miss1, "ì›”í‰ê· "]
        miss2 = fut_base["ì¶”ì„¸ê¸°ì˜¨"].isna()
        if miss2.any():
            fut_base.loc[miss2, "ì¶”ì„¸ê¸°ì˜¨"] = fut_base.loc[miss2, "ì˜ˆìƒê¸°ì˜¨"]
        fut_base.drop(columns=[c for c in ["ì›”í‰ê· "] if c in fut_base.columns], inplace=True)

        x_train_base = train_df[temp_col].astype(float).values

        st.session_state["supply_materials"] = dict(
            base_df=base, train_df=train_df, prods=prods, x_train=x_train_base,
            fut_base=fut_base, start_ts=f_start, end_ts=f_end, temp_col=temp_col,
            default_pred_years=list(range(int(start_y), int(end_y) + 1)),
            years_sel=years_sel
        )
        st.success("âœ… ê³µê¸‰ëŸ‰ ì˜ˆì¸¡(ë² ì´ìŠ¤) ì¤€ë¹„ ì™„ë£Œ! ì•„ë˜ì—ì„œ **ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C**ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.")

    if "supply_materials" not in st.session_state:
        st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì„¤ì • í›„ **ì˜ˆì¸¡ ì‹œì‘**ì„ ëˆŒëŸ¬ ì‹¤í–‰í•˜ì„¸ìš”."); st.stop()

    mats = st.session_state["supply_materials"]
    base, train_df, prods = mats["base_df"], mats["train_df"], mats["prods"]
    x_train, fut_base = mats["x_train"], mats["fut_base"]
    temp_col = mats["temp_col"]; years_sel = mats["years_sel"]
    months = list(range(1, 13))

    # ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C
    title_with_icon("ğŸŒ¡ï¸", "ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C (í‰ê· ê¸°ì˜¨ ë³´ì •)", "h3", small=True)
    c1, c2, c3 = st.columns(3)
    with c1:
        d_norm = st.number_input("Normal Î”Â°C", value=0.0, step=0.5, format="%.1f", key="s_norm")
    with c2:
        d_best = st.number_input("Best Î”Â°C", value=-1.0, step=0.5, format="%.1f", key="s_best")
    with c3:
        d_cons = st.number_input("Conservative Î”Â°C", value=1.0, step=0.5, format="%.1f", key="s_cons")

    def _forecast_table(delta: float) -> pd.DataFrame:
        x_future = (fut_base["ì˜ˆìƒê¸°ì˜¨"] + float(delta)).astype(float).values
        pred_rows = []
        for col in prods:
            y_train = train_df[col].astype(float).values
            y_future, _, _, _ = fit_poly3_and_predict(x_train, y_train, x_future)
            tmp = fut_base[["ì—°", "ì›”"]].copy()
            tmp["ì›”í‰ê· ê¸°ì˜¨"] = x_future
            tmp["ìƒí’ˆ"] = col
            tmp["ì˜ˆì¸¡"] = np.clip(np.rint(y_future).astype(np.int64), a_min=0, a_max=None)
            pred_rows.append(tmp)
        pred_all = pd.concat(pred_rows, ignore_index=True)
        pivot = pred_all.pivot_table(index=["ì—°", "ì›”", "ì›”í‰ê· ê¸°ì˜¨"], columns="ìƒí’ˆ", values="ì˜ˆì¸¡").reset_index()
        ordered = [c for c in KNOWN_PRODUCT_ORDER if c in pivot.columns]
        others = [c for c in pivot.columns if c not in (["ì—°", "ì›”", "ì›”í‰ê· ê¸°ì˜¨"] + ordered)]
        pivot = pivot[["ì—°", "ì›”", "ì›”í‰ê· ê¸°ì˜¨"] + ordered + others]
        return pivot.sort_values(["ì—°", "ì›”"]).reset_index(drop=True)

    def _forecast_table_trend() -> pd.DataFrame:
        x_future = fut_base["ì¶”ì„¸ê¸°ì˜¨"].astype(float).values
        if np.isnan(x_future).any():
            back = train_df.groupby("ì›”")[temp_col].mean().reindex(fut_base["ì›”"]).values
            x_future = np.where(np.isnan(x_future), back, x_future)
        pred_rows = []
        for col in prods:
            y_train = train_df[col].astype(float).values
            y_future, _, _, _ = fit_poly3_and_predict(x_train, y_train, x_future)
            tmp = fut_base[["ì—°", "ì›”"]].copy()
            tmp["ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"] = x_future
            tmp["ìƒí’ˆ"] = col
            tmp["ì˜ˆì¸¡"] = np.clip(np.rint(y_future).astype(np.int64), a_min=0, a_max=None)
            pred_rows.append(tmp)
        pred_all = pd.concat(pred_rows, ignore_index=True)
        pivot = pred_all.pivot_table(index=["ì—°", "ì›”", "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"], columns="ìƒí’ˆ", values="ì˜ˆì¸¡").reset_index()
        ordered = [c for c in KNOWN_PRODUCT_ORDER if c in pivot.columns]
        others = [c for c in pivot.columns if c not in (["ì—°", "ì›”", "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"] + ordered)]
        pivot = pivot[["ì—°", "ì›”", "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"] + ordered + others]
        return pivot.sort_values(["ì—°", "ì›”"]).reset_index(drop=True)

    # í‘œ + ì—°/ë°˜ê¸° í•©ê³„
    def _render_with_year_sums(title, table, temp_col_name):
        title_with_icon("ğŸ—‚ï¸", title, "h3", small=True)
        render_centered_table(
            table,
            float1_cols=[temp_col_name],
            int_cols=[c for c in table.columns if c not in ["ì—°", "ì›”", temp_col_name]],
            index=False,
        )
        year_sum = table.groupby("ì—°").sum(numeric_only=True).reset_index()
        year_sum_show = year_sum.drop(columns=[c for c in ["ì›”", temp_col_name] if c in year_sum.columns])
        year_sum_show.insert(1, "ê¸°ê°„", "1~12ì›”")
        cols_int = [c for c in year_sum_show.columns if c not in ["ì—°", "ê¸°ê°„"]]
        title_with_icon("ğŸ—“ï¸", "ì—°ë„ë³„ ì´ê³„", "h4", small=True)
        render_centered_table(year_sum_show, int_cols=cols_int, index=False)

        tmp = table.copy()
        tmp["__half"] = np.where(tmp["ì›”"].astype(int) <= 6, "1~6ì›”", "7~12ì›”")
        half = tmp.groupby(["ì—°", "__half"]).sum(numeric_only=True).reset_index().rename(columns={"__half": "ë°˜ê¸°"})
        half_to_show = half.rename(columns={"ë°˜ê¸°": "ê¸°ê°„"}).drop(columns=[c for c in ["ì›”", temp_col_name] if c in half.columns])
        title_with_icon("ğŸ§®", "ë°˜ê¸°ë³„ ì´ê³„ (1~6ì›”, 7~12ì›”)", "h4", small=True)
        render_centered_table(
            half_to_show,
            int_cols=[c for c in half_to_show.columns if c not in ["ì—°", "ê¸°ê°„"]],
            index=False,
        )
        return year_sum_show, half_to_show

    tbl_n = _forecast_table(d_norm)
    tbl_b = _forecast_table(d_best)
    tbl_c = _forecast_table(d_cons)
    tbl_trd = _forecast_table_trend()

    sum_n, half_n = _render_with_year_sums("ğŸ¯ Normal", tbl_n, "ì›”í‰ê· ê¸°ì˜¨")
    sum_b, half_b = _render_with_year_sums("ğŸ’ Best", tbl_b, "ì›”í‰ê· ê¸°ì˜¨")
    sum_c, half_c = _render_with_year_sums("ğŸ›¡ï¸ Conservative", tbl_c, "ì›”í‰ê· ê¸°ì˜¨")
    sum_t, half_t = _render_with_year_sums("ğŸ“ˆ ê¸°ì˜¨ì¶”ì„¸ë¶„ì„", tbl_trd, "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)")

    # ë‹¤ìš´ë¡œë“œ (ë©”íƒ€ í¬í•¨)
    def _pack_for_download(df_list, names, temp_names):
        outs = []
        for df, nm, tnm in zip(df_list, names, temp_names):
            d = df.copy()
            d.insert(0, "ì‹œë‚˜ë¦¬ì˜¤", nm)
            if tnm in d.columns and tnm != "ì›”í‰ê· ê¸°ì˜¨":
                d.rename(columns={tnm: "ì›”í‰ê· ê¸°ì˜¨"}, inplace=True)
            outs.append(d)
        return pd.concat(outs, ignore_index=True)

    to_dl = _pack_for_download(
        [tbl_n, tbl_b, tbl_c, tbl_trd],
        ["Normal", "Best", "Conservative", "ê¸°ì˜¨ì¶”ì„¸ë¶„ì„"],
        ["ì›”í‰ê· ê¸°ì˜¨", "ì›”í‰ê· ê¸°ì˜¨", "ì›”í‰ê· ê¸°ì˜¨", "ì›”í‰ê· ê¸°ì˜¨(ì¶”ì„¸)"],
    )

    learn_years = sorted([int(y) for y in mats["years_sel"]])
    meta_learn  = f"{min(learn_years)}~{max(learn_years)}ë…„" if learn_years else "-"
    all_years = sorted([int(y) for y in base["ì—°"].unique()])
    if learn_years:
        span = list(range(min(learn_years), max(learn_years) + 1))
        exclude_years = [y for y in span if (y in all_years and y not in learn_years)]
    else:
        exclude_years = []
    meta_excl = ", ".join(str(y) for y in exclude_years) if exclude_years else "-"

    try:
        buf = BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as writer:
            startrow = 2
            to_dl.to_excel(writer, index=False, sheet_name="Forecast", startrow=startrow)
            ws = writer.sheets["Forecast"]
            ws.cell(row=1, column=1, value="í•™ìŠµê¸°ê°„"); ws.cell(row=1, column=2, value=meta_learn)
            ws.cell(row=1, column=3, value="ì œì™¸ê¸°ê°„"); ws.cell(row=1, column=4, value=meta_excl)

            def write_yearsum(sheet_name, year_df, half_df):
                ysr = 2
                year_df.to_excel(writer, index=False, sheet_name=sheet_name, startrow=ysr)
                ws2 = writer.sheets[sheet_name]
                ws2.cell(row=1, column=1, value="í•™ìŠµê¸°ê°„"); ws2.cell(row=1, column=2, value=meta_learn)
                ws2.cell(row=1, column=3, value="ì œì™¸ê¸°ê°„"); ws2.cell(row=1, column=4, value=meta_excl)
                start_half = ysr + len(year_df) + 3
                half_df.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_half)

            write_yearsum("YearSum_Normal",    sum_n, half_n)
            write_yearsum("YearSum_Best",      sum_b, half_b)
            write_yearsum("YearSum_Cons",      sum_c, half_c)
            write_yearsum("YearSum_TrendTemp", sum_t, half_t)

        buf.seek(0)
        st.download_button(
            "â¬‡ï¸ ì˜ˆì¸¡ ê²°ê³¼ XLSX ë‹¤ìš´ë¡œë“œ (ì—°í•©/ë°˜ê¸° í¬í•¨ Â· í•™ìŠµÂ·ì œì™¸ê¸°ê°„ í‘œê¸°)",
            data=buf.read(),
            file_name="citygas_supply_forecast.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
    except Exception:
        st.download_button(
            "â¬‡ï¸ ì˜ˆì¸¡ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ (Forecastë§Œ)",
            data=to_dl.to_csv(index=False).encode("utf-8-sig"),
            file_name="citygas_supply_forecast.csv",
            mime="text/csv",
        )

    # ê·¸ë˜í”„
    title_with_icon("ğŸ“ˆ", "ê·¸ë˜í”„(ì‹¤ì  + ì˜ˆì¸¡ + ê¸°ì˜¨ì¶”ì„¸ë¶„ì„)", "h3", small=True)
    cc1, cc2 = st.columns([1, 2])
    with cc1:
        show_best = st.toggle("Best í‘œì‹œ", value=False, key="show_best_top")
        show_cons = st.toggle("Conservative í‘œì‹œ", value=False, key="show_cons_top")

    years_all_for_plot = sorted([int(v) for v in base["ì—°"].dropna().unique()])
    default_years = years_all_for_plot[-2:] if len(years_all_for_plot) >= 2 else years_all_for_plot
    c_y1, c_y2, c_y3 = st.columns(3)
    with c_y1:
        years_view = st.multiselect("ğŸ‘€ ì‹¤ì ì—°ë„", options=years_all_for_plot, default=default_years, key="supply_years_view")
    pred_default = mats.get("default_pred_years", [])
    with c_y2:
        years_pred = st.multiselect(
            "ğŸ“ˆ ì˜ˆì¸¡ì—°ë„",
            options=sorted(list(set(fut_base["ì—°"].tolist()))),
            default=[y for y in pred_default if y in fut_base["ì—°"].unique()],
            key="years_pred",
        )
    with c_y3:
        years_trnd = st.multiselect(
            "ğŸ“Š ê¸°ì˜¨ì¶”ì„¸ë¶„ì„ì—°ë„",
            options=sorted(list(set(fut_base["ì—°"].tolist()))),
            default=[y for y in pred_default if y in fut_base["ì—°"].unique()],
            key="years_trnd",
        )

    months_txt = [f"{m}ì›”" for m in months]
    def _pred_series(delta): return (fut_base["ì˜ˆìƒê¸°ì˜¨"] + float(delta)).astype(float).values
    x_future_norm = _pred_series(d_norm)
    x_future_best = _pred_series(d_best)
    x_future_cons = _pred_series(d_cons)
    x_future_trend = fut_base["ì¶”ì„¸ê¸°ì˜¨"].astype(float).values
    if np.isnan(x_future_trend).any():
        back = train_df.groupby("ì›”")[temp_col].mean().reindex(fut_base["ì›”"]).values
        x_future_trend = np.where(np.isnan(x_future_trend), back, x_future_trend)

    # Plotly Hover ì¤€ë¹„
    fut_with_t = fut_base.copy()
    fut_with_t["T_norm"] = x_future_norm
    fut_with_t["T_best"] = x_future_best
    fut_with_t["T_cons"] = x_future_cons
    fut_with_t["T_trend"] = x_future_trend

    actual_temp = (
        base.groupby(["ì—°", "ì›”"])[temp_col].mean().reset_index().rename(columns={temp_col: "T_actual"})
    )

    for prod in prods:
        y_train_prod = train_df[prod].astype(float).values
        y_norm, r2_train, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_norm)
        P_norm = fut_with_t[["ì—°", "ì›”", "T_norm"]].copy(); P_norm["pred"] = np.clip(np.rint(y_norm).astype(np.int64), 0, None)
        y_best, _, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_best)
        P_best = fut_with_t[["ì—°", "ì›”", "T_best"]].copy(); P_best["pred"] = np.clip(np.rint(y_best).astype(np.int64), 0, None)
        y_cons, _, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_cons)
        P_cons = fut_with_t[["ì—°", "ì›”", "T_cons"]].copy(); P_cons["pred"] = np.clip(np.rint(y_cons).astype(np.int64), 0, None)
        y_trd, _, _, _ = fit_poly3_and_predict(x_train, y_train_prod, x_future_trend)
        P_trend = fut_with_t[["ì—°", "ì›”", "T_trend"]].copy(); P_trend["pred"] = np.clip(np.rint(y_trd).astype(np.int64), 0, None)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê·¸ë˜í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if go is None:
            fig = plt.figure(figsize=(9, 3.6)); ax = plt.gca()
            for y in sorted([int(v) for v in years_view]):
                s = base.loc[base["ì—°"] == y, ["ì›”", prod]].set_index("ì›”")[prod].reindex(months)
                ax.plot(months, s.values, label=f"{y} ì‹¤ì ")
            for y in years_pred:
                pv = P_norm[P_norm["ì—°"] == int(y)].sort_values("ì›”")["pred"].reindex(range(1, 13)).values
                ax.plot(months, pv, "--", label=f"ì˜ˆì¸¡(Normal) {y}")
                if show_best:
                    pv = P_best[P_best["ì—°"] == int(y)].sort_values("ì›”")["pred"].reindex(range(1, 13)).values
                    ax.plot(months, pv, "--", label=f"ì˜ˆì¸¡(Best) {y}")
                if show_cons:
                    pv = P_cons[P_cons["ì—°"] == int(y)].sort_values("ì›”")["pred"].reindex(range(1, 13)).values
                    ax.plot(months, pv, "--", label=f"ì˜ˆì¸¡(Conservative) {y}")
            for y in years_trnd:
                pv = P_trend[P_trend["ì—°"] == int(y)].sort_values("ì›”")["pred"].reindex(range(1, 13)).values
                ax.plot(months, pv, ":", label=f"ê¸°ì˜¨ì¶”ì„¸ë¶„ì„ {y}")
            ax.set_xlim(1, 12); ax.set_xticks(months); ax.set_xticklabels(months_txt)
            ax.set_xlabel("ì›”"); ax.set_ylabel("ê³µê¸‰ëŸ‰ (MJ)")
            ax.set_title(f"{prod} â€” Poly-3 (Train RÂ²={r2_train:.3f})")
            ax.legend(loc="best"); st.pyplot(fig, clear_figure=True)
        else:
            fig = go.Figure()
            # ì‹¤ì 
            for y in sorted([int(v) for v in years_view]):
                one = base[base["ì—°"] == y][["ì›”", prod]].dropna().sort_values("ì›”")
                t_one = actual_temp[actual_temp["ì—°"] == y].sort_values("ì›”")
                one = one.merge(t_one[["ì›”", "T_actual"]], on="ì›”", how="left")
                fig.add_trace(go.Scatter(
                    x=[f"{int(m)}ì›”" for m in one["ì›”"]],
                    y=one[prod],
                    customdata=np.round(one["T_actual"].values.astype(float), 2),
                    mode="lines+markers",
                    name=f"{y} ì‹¤ì ",
                    hovertemplate="%{x} %{y:,}<br>ì›”í‰ê· ê¸°ì˜¨ %{customdata:.2f}â„ƒ"
                ))
            # ì˜ˆì¸¡(Normal/Best/Cons)
            for y in years_pred:
                row = P_norm[P_norm["ì—°"] == int(y)].sort_values("ì›”")
                fig.add_trace(go.Scatter(
                    x=[f"{int(m)}ì›”" for m in row["ì›”"]],
                    y=row["pred"],
                    customdata=np.round(row["T_norm"].values.astype(float), 2),
                    mode="lines",
                    name=f"ì˜ˆì¸¡(Normal) {y}",
                    line=dict(dash="dash"),
                    hovertemplate="%{x} %{y:,}<br>ì›”í‰ê· ê¸°ì˜¨ %{customdata:.2f}â„ƒ"
                ))
                if show_best:
                    rb = P_best[P_best["ì—°"] == int(y)].sort_values("ì›”")
                    fig.add_trace(go.Scatter(
                        x=[f"{int(m)}ì›”" for m in rb["ì›”"]],
                        y=rb["pred"],
                        customdata=np.round(rb["T_best"].values.astype(float), 2),
                        mode="lines",
                        name=f"ì˜ˆì¸¡(Best) {y}",
                        line=dict(dash="dash"),
                        hovertemplate="%{x} %{y:,}<br>ì›”í‰ê· ê¸°ì˜¨ %{customdata:.2f}â„ƒ"
                    ))
                if show_cons:
                    rc = P_cons[P_cons["ì—°"] == int(y)].sort_values("ì›”")
                    fig.add_trace(go.Scatter(
                        x=[f"{int(m)}ì›”" for m in rc["ì›”"]],
                        y=rc["pred"],
                        customdata=np.round(rc["T_cons"].values.astype(float), 2),
                        mode="lines",
                        name=f"ì˜ˆì¸¡(Conservative) {y}",
                        line=dict(dash="dash"),
                        hovertemplate="%{x} %{y:,}<br>ì›”í‰ê· ê¸°ì˜¨ %{customdata:.2f}â„ƒ"
                    ))
            # ê¸°ì˜¨ì¶”ì„¸
            for y in years_trnd:
                row = P_trend[P_trend["ì—°"] == int(y)].sort_values("ì›”")
                fig.add_trace(go.Scatter(
                    x=[f"{int(m)}ì›”" for m in row["ì›”"]],
                    y=row["pred"],
                    customdata=np.round(row["T_trend"].values.astype(float), 2),
                    mode="lines",
                    name=f"ê¸°ì˜¨ì¶”ì„¸ë¶„ì„ {y}",
                    line=dict(dash="dot"),
                    hovertemplate="%{x} %{y:,}<br>ì›”í‰ê· ê¸°ì˜¨ %{customdata:.2f}â„ƒ"
                ))
            fig.update_layout(
                title=f"{prod} â€” Poly-3 (Train RÂ²={r2_train:.3f})",
                xaxis=dict(title="ì›”"),
                yaxis=dict(title="ê³µê¸‰ëŸ‰ (MJ)", rangemode="tozero"),
                legend=dict(orientation="h", yanchor="bottom", y=-0.18, xanchor="left", x=0),
                margin=dict(t=60, b=120, l=40, r=20),
                dragmode="pan",
            )
            st.plotly_chart(fig, use_container_width=True, config=dict(scrollZoom=True, displaylogo=False))

        # ì›”ë³„ í‘œ
        title_with_icon("ğŸ“‘", f"{prod} â€” ì›”ë³„ í‘œ (ì„ íƒ ì—°ë„)", "h3", small=True)
        months_idx = list(range(1, 13))
        table = pd.DataFrame({"ì›”": months_idx})
        for y in sorted([int(v) for v in years_view]):
            s = base.loc[base["ì—°"] == y, ["ì›”", prod]].set_index("ì›”")[prod].astype(float)
            table[f"{y} ì‹¤ì "] = s.reindex(months_idx).values
        for y in years_pred:
            s = P_norm[P_norm["ì—°"] == int(y)][["ì›”", "pred"]].set_index("ì›”")["pred"]
            table[f"ì˜ˆì¸¡(Normal) {y}"] = s.reindex(months_idx).values
        if show_best:
            for y in years_pred:
                s = P_best[P_best["ì—°"] == int(y)][["ì›”", "pred"]].set_index("ì›”")["pred"]
                table[f"ì˜ˆì¸¡(Best) {y}"] = s.reindex(months_idx).values
        if show_cons:
            for y in years_pred:
                s = P_cons[P_cons["ì—°"] == int(y)][["ì›”", "pred"]].set_index("ì›”")["pred"]
                table[f"ì˜ˆì¸¡(Conservative) {y}"] = s.reindex(months_idx).values
        for y in years_trnd:
            s = P_trend[P_trend["ì—°"] == int(y)][["ì›”", "pred"]].set_index("ì›”")["pred"]
            table[f"ê¸°ì˜¨ì¶”ì„¸ {y}"] = s.reindex(months_idx).values
        sum_row = {"ì›”": "í•©ê³„"}
        for c in [col for col in table.columns if col != "ì›”"]:
            sum_row[c] = pd.to_numeric(table[c], errors="coerce").sum()
        table_show = pd.concat([table, pd.DataFrame([sum_row])], ignore_index=True)
        render_centered_table(
            table_show,
            int_cols=[c for c in table_show.columns if c != "ì›”"],
            index=False,
        )

        # ì‚°ì ë„
        title_with_icon("ğŸ”", f"{prod} â€” ê¸°ì˜¨Â·ê³µê¸‰ëŸ‰ ìƒê´€(Train, RÂ²={r2_train:.3f})", "h3", small=True)
        figc, axc = plt.subplots(figsize=(10, 5.2))
        x_tr = train_df[temp_col].astype(float).values
        y_tr = y_train_prod
        axc.scatter(x_tr, y_tr, alpha=0.65, label="í•™ìŠµ ìƒ˜í”Œ")
        xx = np.linspace(np.nanmin(x_tr) - 1, np.nanmax(x_tr) + 1, 200)
        yhat, _, model_s, _ = fit_poly3_and_predict(x_tr, y_tr, xx)
        axc.plot(xx, yhat, lw=2.8, color="#1f77b4", label="Poly-3")
        pred_train, _, _, _ = fit_poly3_and_predict(x_tr, y_tr, x_tr)
        resid = y_tr - pred_train; s = np.nanstd(resid)
        axc.fill_between(xx, yhat - 1.96 * s, yhat + 1.96 * s, color="#ff7f0e", alpha=0.25, label="95% ì‹ ë¢°êµ¬ê°„")
        axc.set_xlabel("ê¸°ì˜¨ (â„ƒ)"); axc.set_ylabel("ê³µê¸‰ëŸ‰ (MJ)")
        axc.grid(alpha=0.25); axc.legend(loc="best")
        axc.text(0.02, 0.04, f"Poly-3: {poly_eq_text(model_s)}", transform=axc.transAxes,
                 fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(figc)

    st.caption("â„¹ï¸ 95% ì‹ ë¢°êµ¬ê°„: ì”ì°¨ í‘œì¤€í¸ì°¨ ê¸°ì¤€ ê·¼ì‚¬ ì˜ˆì¸¡êµ¬ê°„(ì‹ ê·œ ê´€ì¸¡ ì•½ 95% í¬í•¨).")

# ===========================================================
# B) íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©) â€” Poly-3/4
# ===========================================================
def render_cooling_sales_forecast():
    title_with_icon("ğŸ§Š", "íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©) â€” ì „ì›” 16ì¼ ~ ë‹¹ì›” 15ì¼ í‰ê· ê¸°ì˜¨ ê¸°ì¤€", "h2")
    st.write("ğŸ—‚ï¸ ëƒ‰ë°©ìš© **íŒë§¤ ì‹¤ì  ì—‘ì…€**ê³¼ **ê¸°ì˜¨ RAW(ì¼ë³„)**ì„ ì¤€ë¹„í•˜ì„¸ìš”.")

    with st.sidebar:
        title_with_icon("ğŸ“¥", "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", "h3", small=True)
        sales_src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0)

    def _find_repo_sales_and_temp():
        here = Path(__file__).parent if "__file__" in globals() else Path.cwd()
        data_dir = here / "data"
        sales_candidates = [data_dir / "ìƒí’ˆë³„íŒë§¤ëŸ‰.xlsx", *[Path(p) for p in glob(str(data_dir / "*íŒë§¤*.xlsx"))]]
        temp_candidates = [data_dir / "ê¸°ì˜¨.xlsx", *[Path(p) for p in glob(str(data_dir / "*ê¸°ì˜¨*.xlsx"))],
                           *[Path(p) for p in glob(str(data_dir / "*temp*.csv"))]]
        sales_path = next((p for p in sales_candidates if p.exists()), None)
        temp_path = next((p for p in temp_candidates if p.exists()), None)
        return sales_path, temp_path

    c1, c2 = st.columns(2)
    if sales_src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
        repo_sales_path, repo_temp_path = _find_repo_sales_and_temp()
        if not repo_sales_path or not repo_temp_path:
            with c1: sales_file = st.file_uploader("ğŸ“„ ëƒ‰ë°©ìš© **íŒë§¤ ì‹¤ì  ì—‘ì…€(xlsx)**", type=["xlsx"])
            with c2: temp_raw_file = st.file_uploader("ğŸŒ¡ï¸ **ê¸°ì˜¨ RAW(ì¼ë³„)** (xlsx/csv)", type=["xlsx", "csv"])
        else:
            with c1: st.info(f"ğŸ“„ ë ˆí¬ íŒŒì¼: {repo_sales_path.name}")
            with c2: st.info(f"ğŸŒ¡ï¸ ë ˆí¬ íŒŒì¼: {repo_temp_path.name}")
            sales_file = open(repo_sales_path, "rb")
            temp_raw_file = open(repo_temp_path, "rb")
    else:
        with c1: sales_file = st.file_uploader("ğŸ“„ ëƒ‰ë°©ìš© **íŒë§¤ ì‹¤ì  ì—‘ì…€(xlsx)**", type=["xlsx"])
        with c2: temp_raw_file = st.file_uploader("ğŸŒ¡ï¸ **ê¸°ì˜¨ RAW(ì¼ë³„)** (xlsx/csv)", type=["xlsx", "csv"])

    if 'sales_file' not in locals() or sales_file is None or temp_raw_file is None:
        st.info("ğŸ‘ˆ ë‘ íŒŒì¼ì„ ëª¨ë‘ ì¤€ë¹„í•˜ì„¸ìš”."); st.stop()

    try:
        xls = pd.ExcelFile(sales_file, engine="openpyxl")
        sheet = "ì‹¤ì _ì›”í•©" if "ì‹¤ì _ì›”í•©" in xls.sheet_names else ("ëƒ‰ë°©ìš©" if "ëƒ‰ë°©ìš©" in xls.sheet_names else xls.sheet_names[0])
        raw_sales = pd.read_excel(xls, sheet_name=sheet)
    except Exception:
        raw_sales = pd.read_excel(sales_file, engine="openpyxl")
    sales_df = normalize_cols(raw_sales)

    date_candidates = [c for c in ["íŒë§¤ì›”", "ë‚ ì§œ", "ì¼ì", "date"] if c in sales_df.columns]
    if date_candidates: date_col = date_candidates[0]
    else:
        score = {}
        for c in sales_df.columns:
            try: score[c] = pd.to_datetime(sales_df[c], errors="coerce").notna().mean()
            except Exception: pass
        date_col = max(score, key=score.get) if score else None
    cool_cols = [c for c in sales_df.columns if ("ëƒ‰ë°©" in str(c)) and pd.api.types.is_numeric_dtype(sales_df[c])]
    value_col = next((c for c in cool_cols if "ëƒ‰ë°©ìš©" in str(c)), (cool_cols[0] if cool_cols else None))
    if date_col is None or value_col is None:
        st.error("â›” ë‚ ì§œ ì—´ ë˜ëŠ” 'ëƒ‰ë°©' ìˆ˜ì¹˜ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()

    sales_df["íŒë§¤ì›”"] = pd.to_datetime(sales_df[date_col], errors="coerce").dt.to_period("M").dt.to_timestamp()
    sales_df["íŒë§¤ëŸ‰"] = pd.to_numeric(sales_df[value_col], errors="coerce")
    sales_df = sales_df.dropna(subset=["íŒë§¤ì›”", "íŒë§¤ëŸ‰"]).copy()
    sales_df["ì—°"] = sales_df["íŒë§¤ì›”"].dt.year.astype(int)
    sales_df["ì›”"] = sales_df["íŒë§¤ì›”"].dt.month.astype(int)

    temp_raw = read_temperature_raw(temp_raw_file)
    if temp_raw is None or temp_raw.empty:
        st.error("â›” ê¸°ì˜¨ RAWì—ì„œ ë‚ ì§œ/ê¸°ì˜¨ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()

    with st.sidebar:
        title_with_icon("ğŸ“š", "í•™ìŠµ ë°ì´í„° ì—°ë„ ì„ íƒ", "h3", small=True)
        years_all = sorted(sales_df["ì—°"].unique().tolist())
        years_sel = st.multiselect("ğŸ—“ï¸ ì—°ë„ ì„ íƒ", options=years_all, default=years_all)

        title_with_icon("âš™ï¸", "ì˜ˆì¸¡ ì„¤ì •", "h3", small=True)
        years = list(range(2010, 2036))
        last_year = int(sales_df["ì—°"].max())
        col_sy, col_sm = st.columns(2)
        with col_sy:
            start_y = st.selectbox("ğŸš€ ì˜ˆì¸¡ ì‹œì‘(ì—°)", years, index=years.index(last_year))
        with col_sm:
            start_m = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì‹œì‘(ì›”)", list(range(1, 13)), index=0)
        col_ey, col_em = st.columns(2)
        with col_ey:
            end_y = st.selectbox("ğŸ ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", years, index=years.index(last_year))
        with col_em:
            end_m = st.selectbox("ğŸ“… ì˜ˆì¸¡ ì¢…ë£Œ(ì›”)", list(range(1, 13)), index=11)
        run_btn = st.button("ğŸ§® ì˜ˆì¸¡ ì‹œì‘", type="primary")

    if run_btn:
        temp_raw["ì—°"] = temp_raw["ì¼ì"].dt.year; temp_raw["ì›”"] = temp_raw["ì¼ì"].dt.month
        monthly_cal = temp_raw.groupby(["ì—°", "ì›”"])["ê¸°ì˜¨"].mean().reset_index()
        fallback_by_M = temp_raw.groupby("ì›”")["ê¸°ì˜¨"].mean()

        def period_avg(label_m: pd.Timestamp) -> float:
            m = month_start(label_m)
            s = (m - pd.offsets.MonthBegin(1)) + pd.DateOffset(days=15)  # ì „ì›”16
            e = m + pd.DateOffset(days=14)                                # ë‹¹ì›”15
            mask = (temp_raw["ì¼ì"] >= s) & (temp_raw["ì¼ì"] <= e)
            return temp_raw.loc[mask, "ê¸°ì˜¨"].mean()

        train_sales = sales_df[sales_df["ì—°"].isin(years_sel)].copy()
        rows = [{"íŒë§¤ì›”": m, "ê¸°ê°„í‰ê· ê¸°ì˜¨": period_avg(m)} for m in train_sales["íŒë§¤ì›”"].unique()]
        sj = pd.merge(train_sales[["íŒë§¤ì›”", "íŒë§¤ëŸ‰"]], pd.DataFrame(rows), on="íŒë§¤ì›”", how="left")
        miss = sj["ê¸°ê°„í‰ê· ê¸°ì˜¨"].isna()
        if miss.any():
            sj.loc[miss, "ê¸°ê°„í‰ê· ê¸°ì˜¨"] = sj.loc[miss, "íŒë§¤ì›”"].dt.month.map(fallback_by_M)
        sj = sj.dropna(subset=["ê¸°ê°„í‰ê· ê¸°ì˜¨", "íŒë§¤ëŸ‰"])

        x_train = sj["ê¸°ê°„í‰ê· ê¸°ì˜¨"].astype(float).values
        y_train = sj["íŒë§¤ëŸ‰"].astype(float).values
        _, r2_fit, model_fit, _ = fit_poly3_and_predict(x_train, y_train, x_train)
        _, r2_fit4, model_fit4, _ = fit_poly4_and_predict(x_train, y_train, x_train)

        f_start = pd.Timestamp(year=int(start_y), month=int(start_m), day=1)
        f_end   = pd.Timestamp(year=int(end_y),   month=int(end_m),   day=1)
        if f_end < f_start:
            st.error("â›” ì˜ˆì¸¡ ì¢…ë£Œê°€ ì‹œì‘ë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤."); st.stop()

        months_rng = month_range_inclusive(f_start, f_end)
        rows = []
        for m in months_rng:
            s = (m - pd.offsets.MonthBegin(1)) + pd.DateOffset(days=15)
            e = m + pd.DateOffset(days=14)
            mask = (temp_raw["ì¼ì"] >= s) & (temp_raw["ì¼ì"] <= e)
            avg_period = temp_raw.loc[mask, "ê¸°ì˜¨"].mean()
            avg_month = monthly_cal.loc[(monthly_cal["ì—°"] == m.year) & (monthly_cal["ì›”"] == m.month), "ê¸°ì˜¨"].mean()
            rows.append({"ì—°": int(m.year), "ì›”": int(m.month), "ê¸°ê°„í‰ê· ê¸°ì˜¨": avg_period, "ë‹¹ì›”í‰ê· ê¸°ì˜¨": avg_month})
        pred_base = pd.DataFrame(rows)
        for c in ["ê¸°ê°„í‰ê· ê¸°ì˜¨", "ë‹¹ì›”í‰ê· ê¸°ì˜¨"]:
            miss = pred_base[c].isna()
            if miss.any():
                pred_base.loc[miss, c] = pred_base.loc[miss, "ì›”"].map(fallback_by_M)

        st.session_state["sales_materials"] = dict(
            sales_df=sales_df, temp_raw=temp_raw, years_all=years_all,
            train_xy=(x_train, y_train),
            r2_fit=r2_fit, model_fit=model_fit,
            r2_fit4=r2_fit4, model_fit4=model_fit4,
            pred_base=pred_base, f_start=f_start, f_end=f_end,
        )
        st.success("âœ… ëƒ‰ë°©ìš© íŒë§¤ëŸ‰ ì˜ˆì¸¡(ë² ì´ìŠ¤) ì¤€ë¹„ ì™„ë£Œ! ì•„ë˜ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ Î”Â°Cë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.")

    if "sales_materials" not in st.session_state:
        st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì„¤ì • í›„ **ì˜ˆì¸¡ ì‹œì‘**ì„ ëˆŒëŸ¬ ì‹¤í–‰í•˜ì„¸ìš”."); st.stop()

    sm = st.session_state["sales_materials"]
    sales_df, pred_base = sm["sales_df"], sm["pred_base"]
    x_train, y_train = sm["train_xy"]
    r2_fit, r2_fit4 = sm["r2_fit"], sm["r2_fit4"]
    years_all = sm["years_all"]

    st.markdown("#### ë‹¤í•­ì‹ ë³´ê¸° ì„ íƒ")
    view_choice = st.radio("ë‹¤í•­ì‹", options=["3ì°¨(Poly-3)", "4ì°¨(Poly-4)", "ë‘˜ ë‹¤"], index=2, horizontal=True, key="poly_view_choice")
    show_poly3 = view_choice in ["3ì°¨(Poly-3)", "ë‘˜ ë‹¤"]
    show_poly4 = view_choice in ["4ì°¨(Poly-4)", "ë‘˜ ë‹¤"]

    if show_poly3:
        st.subheader("ì‹œë‚˜ë¦¬ì˜¤ Î”Â°C (í‰ê· ê¸°ì˜¨ ë³´ì •) â€” Poly-3")
        c1, c2, c3 = st.columns(3)
        with c1:
            d_norm = st.number_input("Normal Î”Â°C", value=0.0, step=0.5, format="%.1f", key="c_norm")
        with c2:
            d_best = st.number_input("Best Î”Â°C", value=-1.0, step=0.5, format="%.1f", key="c_best")
        with c3:
            d_cons = st.number_input("Conservative Î”Â°C", value=1.0, step=0.5, format="%.1f", key="c_cons")

        def forecast_sales_table(delta: float) -> pd.DataFrame:
            base = pred_base.copy()
            base["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)"] = base["ë‹¹ì›”í‰ê· ê¸°ì˜¨"] + delta
            base["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"] = base["ê¸°ê°„í‰ê· ê¸°ì˜¨"] + delta
            y_future, _, _, _ = fit_poly3_and_predict(x_train, y_train, base["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"].values.astype(float))
            base["ì˜ˆì¸¡íŒë§¤ëŸ‰"] = np.clip(np.rint(y_future).astype(np.int64), a_min=0, a_max=None)
            out = base[["ì—°", "ì›”", "ì›”í‰ê· ê¸°ì˜¨(ì ìš©)", "ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)", "ì˜ˆì¸¡íŒë§¤ëŸ‰"]].copy()
            out.loc[len(out)] = ["", "ì¢…ê³„", "", "", int(out["ì˜ˆì¸¡íŒë§¤ëŸ‰"].sum())]
            return out

        st.markdown("### Normal"); sale_n = forecast_sales_table(d_norm)
        render_centered_table(sale_n, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)", "ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)
        st.markdown("### Best");   sale_b = forecast_sales_table(d_best)
        render_centered_table(sale_b, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)", "ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)
        st.markdown("### Conservative"); sale_c = forecast_sales_table(d_cons)
        render_centered_table(sale_c, float1_cols=["ì›”í‰ê· ê¸°ì˜¨(ì ìš©)", "ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"], int_cols=["ì˜ˆì¸¡íŒë§¤ëŸ‰"], index=False)

        st.download_button(
            "íŒë§¤ëŸ‰ ì˜ˆì¸¡ CSV ë‹¤ìš´ë¡œë“œ (Poly-3 Â· Normal)",
            data=sale_n.to_csv(index=False).encode("utf-8-sig"),
            file_name="cooling_sales_forecast_poly3_normal.csv",
            mime="text/csv",
        )

        # ê²€ì¦
        st.subheader("íŒë§¤ëŸ‰ ì˜ˆì¸¡ ê²€ì¦ â€” Poly-3")
        valid_pred = sale_n[sale_n["ì›”"] != "ì¢…ê³„"].copy()
        valid_pred["ì—°"] = pd.to_numeric(valid_pred["ì—°"], errors="coerce").astype("Int64")
        valid_pred["ì›”"] = pd.to_numeric(valid_pred["ì›”"], errors="coerce").astype("Int64")
        comp = pd.merge(
            valid_pred[["ì—°", "ì›”", "ì˜ˆì¸¡íŒë§¤ëŸ‰"]],
            sales_df[["ì—°", "ì›”", "íŒë§¤ëŸ‰"]].rename(columns={"íŒë§¤ëŸ‰": "ì‹¤ì œíŒë§¤ëŸ‰"}),
            on=["ì—°", "ì›”"],
            how="left",
        ).sort_values(["ì—°", "ì›”"])
        comp["ì˜¤ì°¨"] = (comp["ì˜ˆì¸¡íŒë§¤ëŸ‰"] - comp["ì‹¤ì œíŒë§¤ëŸ‰"]).astype("Int64")
        comp["ì˜¤ì°¨ìœ¨(%)"] = ((comp["ì˜¤ì°¨"] / comp["ì‹¤ì œíŒë§¤ëŸ‰"]) * 100).round(1).astype("Float64")
        render_centered_table(comp[["ì—°", "ì›”", "ì‹¤ì œíŒë§¤ëŸ‰", "ì˜ˆì¸¡íŒë§¤ëŸ‰", "ì˜¤ì°¨", "ì˜¤ì°¨ìœ¨(%)"]],
                              int_cols=["ì‹¤ì œíŒë§¤ëŸ‰", "ì˜ˆì¸¡íŒë§¤ëŸ‰", "ì˜¤ì°¨"], index=False)

        # ê·¸ë˜í”„(Normal)
        st.subheader("ê·¸ë˜í”„ (Normal ê¸°ì¤€) â€” Poly-3")
        years_default = years_all[-5:] if len(years_all) >= 5 else years_all
        years_view = st.multiselect("í‘œì‹œí•  ì‹¤ì  ì—°ë„", options=years_all,
                                    default=st.session_state.get("sales_years_view", years_default),
                                    key="sales_years_view")
        base_plot = pred_base.copy()
        base_plot["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"] = base_plot["ê¸°ê°„í‰ê· ê¸°ì˜¨"] + d_norm
        y_pred_norm, r2_line, model_line, _ = fit_poly3_and_predict(
            x_train, y_train, base_plot["ê¸°ê°„í‰ê· ê¸°ì˜¨(ì ìš©)"].values.astype(float)
        )
        base_plot["pred"] = np.clip(np.rint(y_pred_norm).astype(np.int64), 0, None)
        months = list(range(1, 13))
        fig2, ax2 = plt.subplots(figsize=(10, 4.2))
        for y in years_view:
            one = sales_df[sales_df["ì—°"] == y][["ì›”", "íŒë§¤ëŸ‰"]].dropna()
            if not one.empty:
                ax2.plot(one["ì›”"], one["íŒë§¤ëŸ‰"], label=f"{y} ì‹¤ì ", alpha=0.95)
        pred_vals = []
        y, m = int(sm["f_start"].year), int(sm["f_start"].month)
        P2 = base_plot[["ì—°", "ì›”", "pred"]].astype(int)
        for _ in range(12):
            row = P2[(P2["ì—°"] == y) & (P2["ì›”"] == m)]
            pred_vals.append(row.iloc[0]["pred"] if len(row) else np.nan)
            if m == 12: y += 1; m = 1
            else: m += 1
        ax2.plot(months, pred_vals, "--", lw=2.5, label="ì˜ˆì¸¡(Normal)")
        ax2.set_xlim(1, 12); ax2.set_xlabel("ì›”"); ax2.set_ylabel("íŒë§¤ëŸ‰ (MJ)")
        ax2.set_title(f"ëƒ‰ë°©ìš© â€” Poly-3 (Train RÂ²={r2_line:.3f})")
        ax2.legend(loc="best"); ax2.grid(alpha=0.25)
        ax2.text(0.02, 0.96, f"Poly-3: {poly_eq_text(model_line)}",
                 transform=ax2.transAxes, ha="left", va="top", fontsize=9,
                 bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(fig2)

        # ì‚°ì 
        st.subheader(f"ê¸°ì˜¨-ëƒ‰ë°©ìš© ì‹¤ì  ìƒê´€ê´€ê³„ (Train, RÂ²={r2_fit:.3f}) â€” Poly-3")
        fig3, ax3 = plt.subplots(figsize=(10, 5.2))
        ax3.scatter(x_train, y_train, alpha=0.65, label="í•™ìŠµ ìƒ˜í”Œ")
        xx = np.linspace(np.nanmin(x_train) - 1, np.nanmax(x_train) + 1, 200)
        yhat, _, model_s, _ = fit_poly3_and_predict(x_train, y_train, xx)
        ax3.plot(xx, yhat, lw=2.6, color="#1f77b4", label="Poly-3")
        pred_train, _, _, _ = fit_poly3_and_predict(x_train, y_train, x_train)
        resid = y_train - pred_train; s = np.nanstd(resid)
        ax3.fill_between(xx, yhat - 1.96 * s, yhat + 1.96 * s, color="#1f77b4", alpha=0.14, label="95% ì‹ ë¢°êµ¬ê°„")
        ax3.set_xlabel("ê¸°ê°„í‰ê· ê¸°ì˜¨ (â„ƒ)"); ax3.set_ylabel("íŒë§¤ëŸ‰ (MJ)")
        ax3.grid(alpha=0.25); ax3.legend(loc="best")
        ax3.text(0.02, 0.06, f"Poly-3: {poly_eq_text(model_s)}",
                 transform=ax3.transAxes, fontsize=10,
                 bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.75))
        st.pyplot(fig3)

# ===========================================================
# C) ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡ â€” OLS/CAGR/Holt/SES + ARIMA/SARIMA
# ===========================================================
def render_trend_forecast():
    title_with_icon("ğŸ“ˆ", "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡ (ì—°ë„ë³„ ì´í•© Â· Normal)", "h2")

    with st.sidebar:
        title_with_icon("ğŸ“¥", "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", "h3", small=True)
        src = st.radio("ğŸ“¦ ë°©ì‹", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0, key="trend_src")

        if src == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
            data_dir = Path("data"); data_dir.mkdir(exist_ok=True)
            repo_files = sorted([str(p) for p in data_dir.glob("*.xlsx")])
            if repo_files:
                default_idx = next((i for i, p in enumerate(repo_files)
                                   if ("ìƒí’ˆë³„ê³µê¸‰ëŸ‰" in Path(p).stem) or ("ê³µê¸‰ëŸ‰" in Path(p).stem)), 0)
                file_choice = st.selectbox("ğŸ“„ ì‹¤ì  íŒŒì¼(Excel)", repo_files, index=default_idx,
                                           format_func=lambda p: Path(p).name, key="trend_file_ch")
                df = read_excel_sheet(file_choice, prefer_sheet="ë°ì´í„°")
            else:
                st.info("ğŸ“‚ data í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¡œ ì§„í–‰í•˜ì„¸ìš”.")
                df = None
        else:
            up = st.file_uploader("ğŸ“„ ì‹¤ì  ì—‘ì…€ ì—…ë¡œë“œ(xlsx) â€” 'ë°ì´í„°' ì‹œíŠ¸", type=["xlsx"], key="trend_up")
            df = read_excel_sheet(up, prefer_sheet="ë°ì´í„°") if up is not None else None

        if df is None or df.empty:
            st.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ì‹¤ì  íŒŒì¼ì„ ì„ íƒ/ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()

        title_with_icon("ğŸ“š", "í•™ìŠµ ë°ì´í„° ì—°ë„ ì„ íƒ", "h3", small=True)
        years_all = sorted([int(y) for y in pd.Series(df["ì—°"]).dropna().unique()])
        years_sel = st.multiselect("ğŸ—“ï¸ ì—°ë„ ì„ íƒ(í•™ìŠµ)", years_all, default=years_all, key="trend_years")

        title_with_icon("ğŸ§°", "ë¶„ì„í•  ìƒí’ˆ ì„ íƒ", "h3", small=True)
        product_cols = guess_product_cols(df)
        defaults = [c for c in ["ê°œë³„ë‚œë°©ìš©", "ì¤‘ì•™ë‚œë°©ìš©", "ì·¨ì‚¬ìš©"] if c in product_cols]
        if not defaults:
            defaults = [c for c in KNOWN_PRODUCT_ORDER if c in product_cols][:3] or product_cols[:3]
        prods = st.multiselect("ğŸ“¦ ìƒí’ˆ(ìš©ë„) ì„ íƒ", product_cols, default=defaults, key="trend_prods")

        title_with_icon("âš™ï¸", "ì˜ˆì¸¡ ì—°ë„", "h3", small=True)
        last_year = int(df["ì—°"].max())
        cand_years = list(range(2010, 2036))
        start_y = st.selectbox("ğŸš€ ì˜ˆì¸¡ ì‹œì‘(ì—°)", cand_years, index=cand_years.index(min(last_year + 1, 2035)), key="trend_sy")
        end_y = st.selectbox("ğŸ ì˜ˆì¸¡ ì¢…ë£Œ(ì—°)", cand_years, index=cand_years.index(min(last_year + 2, 2035)), key="trend_ey")

        title_with_icon("ğŸ§ª", "ì ìš©í•  ë°©ë²•", "h3", small=True)
        method_opts = ["OLS(ì„ í˜•ì¶”ì„¸)", "CAGR(ë³µë¦¬ì„±ì¥)", "Holt(ì§€ìˆ˜í‰í™œ)", "ì§€ìˆ˜í‰í™œ(SES)", "ARIMA", "SARIMA(12)"]
        methods_selected = st.multiselect("ë°©ë²• ì„ íƒ(í‘œÂ·ê·¸ë˜í”„ í‘œì‹œ)", options=method_opts, default=method_opts, key="trend_methods")

    base = df.dropna(subset=["ì—°", "ì›”"]).copy()
    base["ì—°"] = base["ì—°"].astype(int); base["ì›”"] = base["ì›”"].astype(int)
    years_pred = list(range(int(start_y), int(end_y) + 1))
    yearly_all = base.groupby("ì—°").sum(numeric_only=True).reset_index()

    def _fore_ols(years, vals, target_years):
        x = np.array(years, float).reshape(-1, 1); y = np.array(vals, float)
        mdl = LinearRegression().fit(x, y)
        return {ty: float(mdl.predict(np.array([[ty]], float))[0]) for ty in target_years}

    def _fore_cagr(years, vals, target_years):
        years = list(years); vals = list(vals)
        y0, yT = years[0], years[-1]; v0, vT = float(vals[0]), float(vals[-1])
        n = max(1, (yT - y0)); g = (vT / v0) ** (1.0 / n) - 1.0 if v0 > 0 else 0.0
        basev = vT; out = {}
        for i, ty in enumerate(target_years, start=1):
            out[ty] = basev * ((1.0 + g) ** i)
        return out

    def _fore_ses(vals, target_len, alpha=0.3):
        l = float(vals[0])
        for v in vals[1:]:
            l = alpha * float(v) + (1 - alpha) * l
        return [l for _ in range(target_len)]

    def _fore_holt(vals, target_len, alpha=0.3, beta=0.1):
        l = float(vals[0]); b = float(vals[1] - vals[0]) if len(vals) >= 2 else 0.0
        for v in vals[1:]:
            prev_l = l
            l = alpha * float(v) + (1 - alpha) * (l + b)
            b = beta * (l - prev_l) + (1 - beta) * b
        return [l + (h + 1) * b for h in range(target_len)]

    def _monthly_series_for(prod: str) -> pd.Series:
        s = base[["ì—°", "ì›”", prod]].dropna()
        s["ë‚ ì§œ"] = pd.to_datetime(s["ì—°"].astype(int).astype(str) + "-" + s["ì›”"].astype(int).astype(str) + "-01")
        s = s.sort_values("ë‚ ì§œ").set_index("ë‚ ì§œ")[prod].astype(float).asfreq("MS")
        return s

    def _prepare_train_series(ts: pd.Series, train_years: list[int]) -> pd.Series:
        ser = ts[ts.index.year.isin(train_years)].copy()
        if ser.empty: return ser
        full_idx = pd.date_range(start=ser.index.min().to_period("M").to_timestamp(),
                                 end=ser.index.max().to_period("M").to_timestamp(), freq="MS")
        ser = ser.reindex(full_idx).interpolate(limit_direction="both").ffill().bfill()
        return ser

    def _yearly_series_for(prod: str) -> pd.Series:
        y = base.groupby("ì—°")[prod].sum(numeric_only=True).sort_index().astype(float)
        full_years = pd.Index(range(int(y.index.min()), int(y.index.max()) + 1), name="ì—°")
        y = y.reindex(full_years).interpolate(limit_direction="both").ffill().bfill().fillna(0.0)
        return y

    def _fit_arima_candidate(series: pd.Series, orders=[(1,1,0),(0,1,1),(1,1,1)]):
        best, aic = None, np.inf
        for od in orders:
            try:
                m = ARIMA(series, order=od).fit()
                if m.aic < aic: best, aic = m, m.aic
            except Exception:
                continue
        return best

    def _fore_arima_yearsum(prod: str, target_years: list[int]) -> dict:
        if not _HAS_SM: return {y: np.nan for y in target_years}
        out = {y: np.nan for y in target_years}
        # 1) ì›”ë³„
        try:
            ts_m = _monthly_series_for(prod)
            train_m = _prepare_train_series(ts_m, years_sel)
            if not train_m.empty:
                last_year = int(train_m.index[-1].year)
                steps = 12 * max(1, (max(target_years) - last_year))
                mdl = _fit_arima_candidate(train_m)
                if mdl is not None:
                    f = mdl.forecast(steps=steps)
                    fut = f.copy()
                    fut.index = pd.date_range(start=train_m.index[-1] + pd.offsets.MonthBegin(1),
                                              periods=len(fut), freq="MS")
                    df_year = fut.groupby(fut.index.year).sum()
                    for y in target_years:
                        if y in df_year.index: out[y] = float(df_year.loc[y])
        except Exception:
            pass
        # 2) í´ë°±: ì—°ë„í•© ì§ì ‘
        if all(np.isnan(list(out.values()))):
            try:
                ys = _yearly_series_for(prod); ys_train = ys[ys.index.isin(years_sel)]
                if len(ys_train) >= 3:
                    mdl = _fit_arima_candidate(ys_train)
                    if mdl is not None:
                        f = mdl.forecast(steps=len(target_years))
                        start_y = int(ys_train.index.max()) + 1
                        idx = pd.Index(range(start_y, start_y + len(f)), name="ì—°"); f.index = idx
                        for y in target_years:
                            if y in f.index: out[y] = float(f.loc[y])
            except Exception:
                pass
        return out

    def _fore_sarima_yearsum(prod: str, target_years: list[int]) -> dict:
        if not _HAS_SM: return {y: np.nan for y in target_years}
        out = {y: np.nan for y in target_years}
        # 1) ì›”ë³„ SARIMA
        try:
            ts = _monthly_series_for(prod); train = _prepare_train_series(ts, years_sel)
            if not train.empty:
                last_year = int(train.index[-1].year)
                steps = 12 * max(1, (max(target_years) - last_year))
                mdl = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12),
                              enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)
                f = mdl.forecast(steps=steps)
                fut = f.copy()
                fut.index = pd.date_range(start=train.index[-1] + pd.offsets.MonthBegin(1),
                                          periods=len(fut), freq="MS")
                df_year = fut.groupby(fut.index.year).sum()
                for y in target_years:
                    if y in df_year.index: out[y] = float(df_year.loc[y])
        except Exception:
            pass
        # 2) í´ë°±: ì—°ë„í•© ARIMA
        if all(np.isnan(list(out.values()))):
            return _fore_arima_yearsum(prod, target_years)
        return out

    if not _HAS_SM:
        st.info("ğŸ”§ ARIMA/SARIMAëŠ” statsmodels ë¯¸ì„¤ì¹˜ í™˜ê²½ì—ì„  ê³„ì‚°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # í™”ë©´: ìƒí’ˆë³„ ì¹´ë“œ
    for prod in prods:
        yearly = base.groupby("ì—°").sum(numeric_only=True).reset_index()[["ì—°", prod]].dropna().astype({"ì—°": int})
        train = yearly[yearly["ì—°"].isin(years_sel)].sort_values("ì—°")
        if train.empty:
            st.warning(f"'{prod}' í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); continue

        yrs = train["ì—°"].tolist()
        vals = train[prod].astype(float).tolist()

        pred_map = {}
        if "OLS(ì„ í˜•ì¶”ì„¸)" in methods_selected:
            pred_map["OLS(ì„ í˜•ì¶”ì„¸)"] = _fore_ols(yrs, vals, years_pred)
        if "CAGR(ë³µë¦¬ì„±ì¥)" in methods_selected:
            pred_map["CAGR(ë³µë¦¬ì„±ì¥)"] = _fore_cagr(yrs, vals, years_pred)
        if "ì§€ìˆ˜í‰í™œ(SES)" in methods_selected:
            pred_map["ì§€ìˆ˜í‰í™œ(SES)"] = dict(zip(years_pred, _fore_ses(vals, len(years_pred))))
        if "Holt(ì§€ìˆ˜í‰í™œ)" in methods_selected:
            pred_map["Holt(ì§€ìˆ˜í‰í™œ)"] = dict(zip(years_pred, _fore_holt(vals, len(years_pred))))
        if "ARIMA" in methods_selected:
            pred_map["ARIMA"] = _fore_arima_yearsum(prod, years_pred)
        if "SARIMA(12)" in methods_selected:
            pred_map["SARIMA(12)"] = _fore_sarima_yearsum(prod, years_pred)

        title_with_icon("ğŸ“‹", f"{prod} â€” ì—°ë„ë³„ ì´í•© ì˜ˆì¸¡í‘œ (Normal)", "h3", small=True)
        df_tbl = pd.DataFrame({"ì—°": years_pred})
        for k in methods_selected:
            if k in pred_map:
                vals_k = []
                for y in years_pred:
                    v = pred_map[k].get(y, np.nan)
                    vals_k.append(int(max(0, round(v))) if v == v else "")
                df_tbl[k] = vals_k
        render_centered_table(df_tbl, int_cols=[c for c in df_tbl.columns if c != "ì—°"], index=False)

        st.markdown("**ë°©ë²•ë³„ í‘œì‹œ í† ê¸€(ìƒë‹¨)**")
        toggles_top = {}
        cols_top = st.columns(min(6, len(methods_selected))) or [st]
        for i, name in enumerate(methods_selected):
            with cols_top[i % len(cols_top)]:
                toggles_top[name] = st.toggle(name, value=True, key=f"tg_top_{prod}_{name}")

        if go is None:
            fig, ax = plt.subplots(figsize=(10, 4.2))
            yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
            ax.fill_between(yd["ì—°"], yd[prod], step="pre", alpha=0.15)
            ax.plot(yd["ì—°"], yd[prod], "-o", label="ì‹¤ì ")
            markers = {"CAGR(ë³µë¦¬ì„±ì¥)": "o", "Holt(ì§€ìˆ˜í‰í™œ)": "s", "OLS(ì„ í˜•ì¶”ì„¸)": "^",
                       "ì§€ìˆ˜í‰í™œ(SES)": "+", "ARIMA": "x", "SARIMA(12)": "D"}
            for name in methods_selected:
                if name in pred_map and toggles_top.get(name, True):
                    xs = years_pred
                    ys = [pred_map[name].get(y, np.nan) for y in xs]
                    ax.scatter(xs, ys, label=name, marker=markers.get(name, "o"))
            ax.set_title("ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸)")
            ax.set_xlabel("ì—°ë„"); ax.set_ylabel("ì´í•©")
            ax.legend(loc="best"); ax.grid(alpha=0.25)
            st.pyplot(fig)
        else:
            fig = go.Figure()
            yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
            fig.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines", name="ì‹¤ì ", line=dict(width=3)))
            fig.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines", name="ì˜ì—­",
                                     fill="tozeroy", line=dict(width=0.1), showlegend=False, hoverinfo="skip"))
            sym = {"CAGR(ë³µë¦¬ì„±ì¥)": "circle", "Holt(ì§€ìˆ˜í‰í™œ)": "square", "OLS(ì„ í˜•ì¶”ì„¸)": "triangle-up",
                   "ì§€ìˆ˜í‰í™œ(SES)": "cross", "ARIMA": "x", "SARIMA(12)": "diamond"}
            for name in methods_selected:
                if name in pred_map and toggles_top.get(name, True):
                    xs = years_pred; ys = [pred_map[name].get(y, np.nan) for y in xs]
                    fig.add_trace(go.Scatter(
                        x=xs, y=ys, mode="markers+text", name=name,
                        marker_symbol=sym.get(name, "circle"),
                        text=[f"{int(v):,}" if v == v else "" for v in ys],
                        textposition="top center"
                    ))
            fig.update_layout(
                title="ì—°ë„ë³„ ì´í•©(ì‹¤ì  ë¼ì¸ + ì˜ˆì¸¡ í¬ì¸íŠ¸)",
                xaxis_title="ì—°ë„", yaxis_title="ì´í•©",
                legend=dict(orientation="h", yanchor="bottom", y=-0.18, xanchor="left", x=0),
                margin=dict(t=60, b=120, l=40, r=20),
                hovermode="x unified",
            )
            st.plotly_chart(fig, use_container_width=True)

        if go is not None:
            with st.expander(f"ğŸ”€ {prod} ë°©ë²•ë³„ í‘œì‹œ í† ê¸€(ë™ì )"):
                toggles = {}
                cols = st.columns(min(6, len(methods_selected))) or [st]
                for i, name in enumerate(methods_selected):
                    with cols[i % len(cols)]:
                        toggles[name] = st.toggle(name, value=True, key=f"tg_{prod}_{name}")
                fig2 = go.Figure()
                yd = yearly_all[["ì—°", prod]].dropna().sort_values("ì—°")
                fig2.add_trace(go.Scatter(x=yd["ì—°"], y=yd[prod], mode="lines+markers", name="ì‹¤ì "))
                for name in methods_selected:
                    if not toggles.get(name, True):
                        continue
                    if name in pred_map:
                        xs = years_pred
                        ys = [pred_map[name].get(y, np.nan) for y in xs]
                        fig2.add_trace(go.Scatter(x=xs, y=ys, mode="markers+text", name=name,
                                                  text=[f"{int(v):,}" if v == v else "" for v in ys],
                                                  textposition="top center"))
                fig2.update_layout(title="ë°©ë²•ë³„ ë™ì  í‘œì‹œ", xaxis_title="ì—°ë„", yaxis_title="ì´í•©",
                                   legend=dict(orientation="h", yanchor="bottom", y=-0.18, x=0),
                                   margin=dict(t=60, b=110, l=40, r=20))
                st.plotly_chart(fig2, use_container_width=True)

    with st.expander("ì˜ˆì¸¡ ë°©ë²• ì„¤ëª… (ì‰¬ìš´ ì„¤ëª… + ì‚°ì‹)"):
        st.markdown(r"""
- **ì„ í˜•ì¶”ì„¸(OLS)** â€” í•´ë§ˆë‹¤ ëŠ˜ì–´ë‚˜ëŠ” í­ì„ ì§ì„ ìœ¼ë¡œ ì¡ì•„ ì•ìœ¼ë¡œ ê·¸ë¦°ë‹¤.  
  \( y_t = a + b t,\ \ \hat y_{t+h} = a + b (t+h) \)

- **CAGR(ë³µë¦¬ì„±ì¥)** â€” ì‹œì‘~ë ì‚¬ì´ì˜ í‰ê·  ë³µë¦¬ ì„±ì¥ë¥ ë§Œí¼ ë§¤ë…„ ê°™ì€ ë¹„ìœ¨ë¡œ ì¦ê°€.  
  \( g = (y_T / y_0)^{1/n} - 1,\ \ \hat y_{t+h} = y_T (1+g)^h \)

- **Holt(ì§€ìˆ˜í‰í™œ)** â€” ìˆ˜ì¤€/ì¶”ì„¸ë¥¼ ì§€ìˆ˜ ê°€ì¤‘ìœ¼ë¡œ ê°±ì‹ .  
  \( l_t = \alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}),\ b_t=\beta(l_t-l_{t-1})+(1-\beta)b_{t-1} \)

- **ì§€ìˆ˜í‰í™œ(SES)** â€” ìµœê·¼ ê´€ì¸¡ì¹˜ ê°€ì¤‘ í‰ê· í™”(ì¶”ì„¸/ê³„ì ˆX).  
  \( l_t = \alpha y_t + (1-\alpha)l_{t-1},\ \hat y_{t+h}=l_T \)

- **ARIMA(p,d,q)** â€” ì°¨ë¶„ìœ¼ë¡œ ì •ìƒí™” í›„ AR/MA ê²°í•©. ì—¬ê¸°ì„  í›„ë³´ \((1,1,0),(0,1,1),(1,1,1)\) ì¤‘ AIC ìµœì†Œ.  

- **SARIMA(P,D,Q,12)** â€” ì›”ë³„ ê³„ì ˆì£¼ê¸° 12 í™•ì¥. ê¸°ë³¸ \((1,1,1)\times(1,1,1)_{12}\).
""")

# ===========================================================
# ë¼ìš°í„°
# ===========================================================
def main():
    title_with_icon("ğŸ“Š", "ë„ì‹œê°€ìŠ¤ ê³µê¸‰ëŸ‰Â·íŒë§¤ëŸ‰ ì˜ˆì¸¡")
    st.caption("ê³µê¸‰ëŸ‰: ê¸°ì˜¨â†”ê³µê¸‰ëŸ‰ 3ì°¨ ë‹¤í•­ì‹ Â· íŒë§¤ëŸ‰(ëƒ‰ë°©ìš©): (ì „ì›”16~ë‹¹ì›”15) í‰ê· ê¸°ì˜¨ ê¸°ë°˜")

    # ì¢Œì¸¡ ìµœìƒë‹¨: ì¶”ì²œ íŒ¨ë„
    sidebar_recommendation_panel()

    # ì˜ˆì¸¡ìœ í˜•
    with st.sidebar:
        title_with_icon("ğŸ§­", "ì˜ˆì¸¡ ìœ í˜•", "h3", small=True)
        mode = st.radio("ğŸ”€ ì„ íƒ",
                        ["ê³µê¸‰ëŸ‰ ì˜ˆì¸¡", "íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©)", "ê³µê¸‰ëŸ‰ ì¶”ì„¸ë¶„ì„ ì˜ˆì¸¡"],
                        index=0, label_visibility="visible")

    # ë³¸ë¬¸ ìƒë‹¨: ì¶”ì²œ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë¨¼ì € ë Œë”
    body_recommendation_section()

    # ë³¸ë¬¸: ê° ê¸°ëŠ¥
    if mode == "ê³µê¸‰ëŸ‰ ì˜ˆì¸¡":
        render_supply_forecast()
    elif mode == "íŒë§¤ëŸ‰ ì˜ˆì¸¡(ëƒ‰ë°©ìš©)":
        render_cooling_sales_forecast()
    else:
        render_trend_forecast()

if __name__ == "__main__":
    main()
